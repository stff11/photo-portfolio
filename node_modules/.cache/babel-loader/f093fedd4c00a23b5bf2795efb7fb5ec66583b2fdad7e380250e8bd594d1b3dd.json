{"ast":null,"code":"import { IcebergRestCatalog } from \"iceberg-js\";\n\n//#region src/lib/common/errors.ts\n/**\n* Base error class for all Storage errors\n* Supports both 'storage' and 'vectors' namespaces\n*/\nvar StorageError = class extends Error {\n  constructor(message, namespace = \"storage\", status, statusCode) {\n    super(message);\n    this.__isStorageError = true;\n    this.namespace = namespace;\n    this.name = namespace === \"vectors\" ? \"StorageVectorsError\" : \"StorageError\";\n    this.status = status;\n    this.statusCode = statusCode;\n  }\n};\n/**\n* Type guard to check if an error is a StorageError\n* @param error - The error to check\n* @returns True if the error is a StorageError\n*/\nfunction isStorageError(error) {\n  return typeof error === \"object\" && error !== null && \"__isStorageError\" in error;\n}\n/**\n* API error returned from Storage service\n* Includes HTTP status code and service-specific error code\n*/\nvar StorageApiError = class extends StorageError {\n  constructor(message, status, statusCode, namespace = \"storage\") {\n    super(message, namespace, status, statusCode);\n    this.name = namespace === \"vectors\" ? \"StorageVectorsApiError\" : \"StorageApiError\";\n    this.status = status;\n    this.statusCode = statusCode;\n  }\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode\n    };\n  }\n};\n/**\n* Unknown error that doesn't match expected error patterns\n* Wraps the original error for debugging\n*/\nvar StorageUnknownError = class extends StorageError {\n  constructor(message, originalError, namespace = \"storage\") {\n    super(message, namespace);\n    this.name = namespace === \"vectors\" ? \"StorageVectorsUnknownError\" : \"StorageUnknownError\";\n    this.originalError = originalError;\n  }\n};\n/**\n* @deprecated Use StorageError with namespace='vectors' instead\n* Alias for backward compatibility with existing vector storage code\n*/\nvar StorageVectorsError = class extends StorageError {\n  constructor(message) {\n    super(message, \"vectors\");\n  }\n};\n/**\n* Type guard to check if an error is a StorageVectorsError\n* @param error - The error to check\n* @returns True if the error is a StorageVectorsError\n*/\nfunction isStorageVectorsError(error) {\n  return isStorageError(error) && error[\"namespace\"] === \"vectors\";\n}\n/**\n* @deprecated Use StorageApiError with namespace='vectors' instead\n* Alias for backward compatibility with existing vector storage code\n*/\nvar StorageVectorsApiError = class extends StorageApiError {\n  constructor(message, status, statusCode) {\n    super(message, status, statusCode, \"vectors\");\n  }\n};\n/**\n* @deprecated Use StorageUnknownError with namespace='vectors' instead\n* Alias for backward compatibility with existing vector storage code\n*/\nvar StorageVectorsUnknownError = class extends StorageUnknownError {\n  constructor(message, originalError) {\n    super(message, originalError, \"vectors\");\n  }\n};\n/**\n* Error codes specific to S3 Vectors API\n* Maps AWS service errors to application-friendly error codes\n*/\nlet StorageVectorsErrorCode = /* @__PURE__ */function (StorageVectorsErrorCode$1) {\n  /** Internal server fault (HTTP 500) */\n  StorageVectorsErrorCode$1[\"InternalError\"] = \"InternalError\";\n  /** Resource already exists / conflict (HTTP 409) */\n  StorageVectorsErrorCode$1[\"S3VectorConflictException\"] = \"S3VectorConflictException\";\n  /** Resource not found (HTTP 404) */\n  StorageVectorsErrorCode$1[\"S3VectorNotFoundException\"] = \"S3VectorNotFoundException\";\n  /** Delete bucket while not empty (HTTP 400) */\n  StorageVectorsErrorCode$1[\"S3VectorBucketNotEmpty\"] = \"S3VectorBucketNotEmpty\";\n  /** Exceeds bucket quota/limit (HTTP 400) */\n  StorageVectorsErrorCode$1[\"S3VectorMaxBucketsExceeded\"] = \"S3VectorMaxBucketsExceeded\";\n  /** Exceeds index quota/limit (HTTP 400) */\n  StorageVectorsErrorCode$1[\"S3VectorMaxIndexesExceeded\"] = \"S3VectorMaxIndexesExceeded\";\n  return StorageVectorsErrorCode$1;\n}({});\n\n//#endregion\n//#region src/lib/common/helpers.ts\n/**\n* Resolves the fetch implementation to use\n* Uses custom fetch if provided, otherwise uses native fetch\n*\n* @param customFetch - Optional custom fetch implementation\n* @returns Resolved fetch function\n*/\nconst resolveFetch = customFetch => {\n  if (customFetch) return (...args) => customFetch(...args);\n  return (...args) => fetch(...args);\n};\n/**\n* Determine if input is a plain object\n* An object is plain if it's created by either {}, new Object(), or Object.create(null)\n*\n* @param value - Value to check\n* @returns True if value is a plain object\n* @source https://github.com/sindresorhus/is-plain-obj\n*/\nconst isPlainObject = value => {\n  if (typeof value !== \"object\" || value === null) return false;\n  const prototype = Object.getPrototypeOf(value);\n  return (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);\n};\n/**\n* Recursively converts object keys from snake_case to camelCase\n* Used for normalizing API responses\n*\n* @param item - Object to convert\n* @returns Converted object with camelCase keys\n*/\nconst recursiveToCamel = item => {\n  if (Array.isArray(item)) return item.map(el => recursiveToCamel(el));else if (typeof item === \"function\" || item !== Object(item)) return item;\n  const result = {};\n  Object.entries(item).forEach(([key, value]) => {\n    const newKey = key.replace(/([-_][a-z])/gi, c => c.toUpperCase().replace(/[-_]/g, \"\"));\n    result[newKey] = recursiveToCamel(value);\n  });\n  return result;\n};\n/**\n* Validates if a given bucket name is valid according to Supabase Storage API rules\n* Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\n*\n* Rules:\n* - Length: 1-100 characters\n* - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\n* - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\n* - Forbidden: path separators (/, \\), path traversal (..), leading/trailing whitespace\n*\n* AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n*\n* @param bucketName - The bucket name to validate\n* @returns true if valid, false otherwise\n*/\nconst isValidBucketName = bucketName => {\n  if (!bucketName || typeof bucketName !== \"string\") return false;\n  if (bucketName.length === 0 || bucketName.length > 100) return false;\n  if (bucketName.trim() !== bucketName) return false;\n  if (bucketName.includes(\"/\") || bucketName.includes(\"\\\\\")) return false;\n  return /^[\\w!.\\*'() &$@=;:+,?-]+$/.test(bucketName);\n};\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/typeof.js\nfunction _typeof(o) {\n  \"@babel/helpers - typeof\";\n\n  return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o$1) {\n    return typeof o$1;\n  } : function (o$1) {\n    return o$1 && \"function\" == typeof Symbol && o$1.constructor === Symbol && o$1 !== Symbol.prototype ? \"symbol\" : typeof o$1;\n  }, _typeof(o);\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/toPrimitive.js\nfunction toPrimitive(t, r) {\n  if (\"object\" != _typeof(t) || !t) return t;\n  var e = t[Symbol.toPrimitive];\n  if (void 0 !== e) {\n    var i = e.call(t, r || \"default\");\n    if (\"object\" != _typeof(i)) return i;\n    throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n  }\n  return (\"string\" === r ? String : Number)(t);\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/toPropertyKey.js\nfunction toPropertyKey(t) {\n  var i = toPrimitive(t, \"string\");\n  return \"symbol\" == _typeof(i) ? i : i + \"\";\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/defineProperty.js\nfunction _defineProperty(e, r, t) {\n  return (r = toPropertyKey(r)) in e ? Object.defineProperty(e, r, {\n    value: t,\n    enumerable: !0,\n    configurable: !0,\n    writable: !0\n  }) : e[r] = t, e;\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/objectSpread2.js\nfunction ownKeys(e, r) {\n  var t = Object.keys(e);\n  if (Object.getOwnPropertySymbols) {\n    var o = Object.getOwnPropertySymbols(e);\n    r && (o = o.filter(function (r$1) {\n      return Object.getOwnPropertyDescriptor(e, r$1).enumerable;\n    })), t.push.apply(t, o);\n  }\n  return t;\n}\nfunction _objectSpread2(e) {\n  for (var r = 1; r < arguments.length; r++) {\n    var t = null != arguments[r] ? arguments[r] : {};\n    r % 2 ? ownKeys(Object(t), !0).forEach(function (r$1) {\n      _defineProperty(e, r$1, t[r$1]);\n    }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r$1) {\n      Object.defineProperty(e, r$1, Object.getOwnPropertyDescriptor(t, r$1));\n    });\n  }\n  return e;\n}\n\n//#endregion\n//#region src/lib/common/fetch.ts\n/**\n* Extracts error message from various error response formats\n* @param err - Error object from API\n* @returns Human-readable error message\n*/\nconst _getErrorMessage = err => {\n  var _err$error;\n  return err.msg || err.message || err.error_description || (typeof err.error === \"string\" ? err.error : (_err$error = err.error) === null || _err$error === void 0 ? void 0 : _err$error.message) || JSON.stringify(err);\n};\n/**\n* Handles fetch errors and converts them to Storage error types\n* @param error - The error caught from fetch\n* @param reject - Promise rejection function\n* @param options - Fetch options that may affect error handling\n* @param namespace - Error namespace ('storage' or 'vectors')\n*/\nconst handleError = async (error, reject, options, namespace) => {\n  if (error && typeof error === \"object\" && \"status\" in error && \"ok\" in error && typeof error.status === \"number\" && !(options === null || options === void 0 ? void 0 : options.noResolveJson)) {\n    const responseError = error;\n    const status = responseError.status || 500;\n    if (typeof responseError.json === \"function\") responseError.json().then(err => {\n      const statusCode = (err === null || err === void 0 ? void 0 : err.statusCode) || (err === null || err === void 0 ? void 0 : err.code) || status + \"\";\n      reject(new StorageApiError(_getErrorMessage(err), status, statusCode, namespace));\n    }).catch(() => {\n      if (namespace === \"vectors\") {\n        const statusCode = status + \"\";\n        reject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\n      } else {\n        const statusCode = status + \"\";\n        reject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\n      }\n    });else {\n      const statusCode = status + \"\";\n      reject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\n    }\n  } else reject(new StorageUnknownError(_getErrorMessage(error), error, namespace));\n};\n/**\n* Builds request parameters for fetch calls\n* @param method - HTTP method\n* @param options - Custom fetch options\n* @param parameters - Additional fetch parameters like AbortSignal\n* @param body - Request body (will be JSON stringified if plain object)\n* @returns Complete fetch request parameters\n*/\nconst _getRequestParams = (method, options, parameters, body) => {\n  const params = {\n    method,\n    headers: (options === null || options === void 0 ? void 0 : options.headers) || {}\n  };\n  if (method === \"GET\" || method === \"HEAD\" || !body) return _objectSpread2(_objectSpread2({}, params), parameters);\n  if (isPlainObject(body)) {\n    params.headers = _objectSpread2({\n      \"Content-Type\": \"application/json\"\n    }, options === null || options === void 0 ? void 0 : options.headers);\n    params.body = JSON.stringify(body);\n  } else params.body = body;\n  if (options === null || options === void 0 ? void 0 : options.duplex) params.duplex = options.duplex;\n  return _objectSpread2(_objectSpread2({}, params), parameters);\n};\n/**\n* Internal request handler that wraps fetch with error handling\n* @param fetcher - Fetch function to use\n* @param method - HTTP method\n* @param url - Request URL\n* @param options - Custom fetch options\n* @param parameters - Additional fetch parameters\n* @param body - Request body\n* @param namespace - Error namespace ('storage' or 'vectors')\n* @returns Promise with parsed response or error\n*/\nasync function _handleRequest(fetcher, method, url, options, parameters, body, namespace) {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body)).then(result => {\n      if (!result.ok) throw result;\n      if (options === null || options === void 0 ? void 0 : options.noResolveJson) return result;\n      if (namespace === \"vectors\") {\n        const contentType = result.headers.get(\"content-type\");\n        if (result.headers.get(\"content-length\") === \"0\" || result.status === 204) return {};\n        if (!contentType || !contentType.includes(\"application/json\")) return {};\n      }\n      return result.json();\n    }).then(data => resolve(data)).catch(error => handleError(error, reject, options, namespace));\n  });\n}\n/**\n* Creates a fetch API with the specified namespace\n* @param namespace - Error namespace ('storage' or 'vectors')\n* @returns Object with HTTP method functions\n*/\nfunction createFetchApi(namespace = \"storage\") {\n  return {\n    get: async (fetcher, url, options, parameters) => {\n      return _handleRequest(fetcher, \"GET\", url, options, parameters, void 0, namespace);\n    },\n    post: async (fetcher, url, body, options, parameters) => {\n      return _handleRequest(fetcher, \"POST\", url, options, parameters, body, namespace);\n    },\n    put: async (fetcher, url, body, options, parameters) => {\n      return _handleRequest(fetcher, \"PUT\", url, options, parameters, body, namespace);\n    },\n    head: async (fetcher, url, options, parameters) => {\n      return _handleRequest(fetcher, \"HEAD\", url, _objectSpread2(_objectSpread2({}, options), {}, {\n        noResolveJson: true\n      }), parameters, void 0, namespace);\n    },\n    remove: async (fetcher, url, body, options, parameters) => {\n      return _handleRequest(fetcher, \"DELETE\", url, options, parameters, body, namespace);\n    }\n  };\n}\nconst defaultApi = createFetchApi(\"storage\");\nconst {\n  get,\n  post,\n  put,\n  head,\n  remove\n} = defaultApi;\nconst vectorsApi = createFetchApi(\"vectors\");\n\n//#endregion\n//#region src/lib/common/BaseApiClient.ts\n/**\n* @ignore\n* Base API client class for all Storage API classes\n* Provides common infrastructure for error handling and configuration\n*\n* @typeParam TError - The error type (StorageError or subclass)\n*/\nvar BaseApiClient = class {\n  /**\n  * Creates a new BaseApiClient instance\n  * @param url - Base URL for API requests\n  * @param headers - Default headers for API requests\n  * @param fetch - Optional custom fetch implementation\n  * @param namespace - Error namespace ('storage' or 'vectors')\n  */\n  constructor(url, headers = {}, fetch$1, namespace = \"storage\") {\n    this.shouldThrowOnError = false;\n    this.url = url;\n    this.headers = headers;\n    this.fetch = resolveFetch(fetch$1);\n    this.namespace = namespace;\n  }\n  /**\n  * Enable throwing errors instead of returning them.\n  * When enabled, errors are thrown instead of returned in { data, error } format.\n  *\n  * @returns this - For method chaining\n  */\n  throwOnError() {\n    this.shouldThrowOnError = true;\n    return this;\n  }\n  /**\n  * Handles API operation with standardized error handling\n  * Eliminates repetitive try-catch blocks across all API methods\n  *\n  * This wrapper:\n  * 1. Executes the operation\n  * 2. Returns { data, error: null } on success\n  * 3. Returns { data: null, error } on failure (if shouldThrowOnError is false)\n  * 4. Throws error on failure (if shouldThrowOnError is true)\n  *\n  * @typeParam T - The expected data type from the operation\n  * @param operation - Async function that performs the API call\n  * @returns Promise with { data, error } tuple\n  *\n  * @example\n  * ```typescript\n  * async listBuckets() {\n  *   return this.handleOperation(async () => {\n  *     return await get(this.fetch, `${this.url}/bucket`, {\n  *       headers: this.headers,\n  *     })\n  *   })\n  * }\n  * ```\n  */\n  async handleOperation(operation) {\n    var _this = this;\n    try {\n      return {\n        data: await operation(),\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n};\n\n//#endregion\n//#region src/packages/StreamDownloadBuilder.ts\nvar StreamDownloadBuilder = class {\n  constructor(downloadFn, shouldThrowOnError) {\n    this.downloadFn = downloadFn;\n    this.shouldThrowOnError = shouldThrowOnError;\n  }\n  then(onfulfilled, onrejected) {\n    return this.execute().then(onfulfilled, onrejected);\n  }\n  async execute() {\n    var _this = this;\n    try {\n      return {\n        data: (await _this.downloadFn()).body,\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n};\n\n//#endregion\n//#region src/packages/BlobDownloadBuilder.ts\nlet _Symbol$toStringTag;\n_Symbol$toStringTag = Symbol.toStringTag;\nvar BlobDownloadBuilder = class {\n  constructor(downloadFn, shouldThrowOnError) {\n    this.downloadFn = downloadFn;\n    this.shouldThrowOnError = shouldThrowOnError;\n    this[_Symbol$toStringTag] = \"BlobDownloadBuilder\";\n    this.promise = null;\n  }\n  asStream() {\n    return new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError);\n  }\n  then(onfulfilled, onrejected) {\n    return this.getPromise().then(onfulfilled, onrejected);\n  }\n  catch(onrejected) {\n    return this.getPromise().catch(onrejected);\n  }\n  finally(onfinally) {\n    return this.getPromise().finally(onfinally);\n  }\n  getPromise() {\n    if (!this.promise) this.promise = this.execute();\n    return this.promise;\n  }\n  async execute() {\n    var _this = this;\n    try {\n      return {\n        data: await (await _this.downloadFn()).blob(),\n        error: null\n      };\n    } catch (error) {\n      if (_this.shouldThrowOnError) throw error;\n      if (isStorageError(error)) return {\n        data: null,\n        error\n      };\n      throw error;\n    }\n  }\n};\n\n//#endregion\n//#region src/packages/StorageFileApi.ts\nconst DEFAULT_SEARCH_OPTIONS = {\n  limit: 100,\n  offset: 0,\n  sortBy: {\n    column: \"name\",\n    order: \"asc\"\n  }\n};\nconst DEFAULT_FILE_OPTIONS = {\n  cacheControl: \"3600\",\n  contentType: \"text/plain;charset=UTF-8\",\n  upsert: false\n};\nvar StorageFileApi = class extends BaseApiClient {\n  constructor(url, headers = {}, bucketId, fetch$1) {\n    super(url, headers, fetch$1, \"storage\");\n    this.bucketId = bucketId;\n  }\n  /**\n  * Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n  *\n  * @param method HTTP method.\n  * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n  * @param fileBody The body of the file to be stored in the bucket.\n  */\n  async uploadOrUpdate(method, path, fileBody, fileOptions) {\n    var _this = this;\n    return _this.handleOperation(async () => {\n      let body;\n      const options = _objectSpread2(_objectSpread2({}, DEFAULT_FILE_OPTIONS), fileOptions);\n      let headers = _objectSpread2(_objectSpread2({}, _this.headers), method === \"POST\" && {\n        \"x-upsert\": String(options.upsert)\n      });\n      const metadata = options.metadata;\n      if (typeof Blob !== \"undefined\" && fileBody instanceof Blob) {\n        body = new FormData();\n        body.append(\"cacheControl\", options.cacheControl);\n        if (metadata) body.append(\"metadata\", _this.encodeMetadata(metadata));\n        body.append(\"\", fileBody);\n      } else if (typeof FormData !== \"undefined\" && fileBody instanceof FormData) {\n        body = fileBody;\n        if (!body.has(\"cacheControl\")) body.append(\"cacheControl\", options.cacheControl);\n        if (metadata && !body.has(\"metadata\")) body.append(\"metadata\", _this.encodeMetadata(metadata));\n      } else {\n        body = fileBody;\n        headers[\"cache-control\"] = `max-age=${options.cacheControl}`;\n        headers[\"content-type\"] = options.contentType;\n        if (metadata) headers[\"x-metadata\"] = _this.toBase64(_this.encodeMetadata(metadata));\n        if ((typeof ReadableStream !== \"undefined\" && body instanceof ReadableStream || body && typeof body === \"object\" && \"pipe\" in body && typeof body.pipe === \"function\") && !options.duplex) options.duplex = \"half\";\n      }\n      if (fileOptions === null || fileOptions === void 0 ? void 0 : fileOptions.headers) headers = _objectSpread2(_objectSpread2({}, headers), fileOptions.headers);\n      const cleanPath = _this._removeEmptyFolders(path);\n      const _path = _this._getFinalPath(cleanPath);\n      const data = await (method == \"PUT\" ? put : post)(_this.fetch, `${_this.url}/object/${_path}`, body, _objectSpread2({\n        headers\n      }, (options === null || options === void 0 ? void 0 : options.duplex) ? {\n        duplex: options.duplex\n      } : {}));\n      return {\n        path: cleanPath,\n        id: data.Id,\n        fullPath: data.Key\n      };\n    });\n  }\n  /**\n  * Uploads a file to an existing bucket.\n  *\n  * @category File Buckets\n  * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n  * @param fileBody The body of the file to be stored in the bucket.\n  * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n  * @returns Promise with response containing file path, id, and fullPath or error\n  *\n  * @example Upload file\n  * ```js\n  * const avatarFile = event.target.files[0]\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .upload('public/avatar1.png', avatarFile, {\n  *     cacheControl: '3600',\n  *     upsert: false\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"path\": \"public/avatar1.png\",\n  *     \"fullPath\": \"avatars/public/avatar1.png\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  *\n  * @example Upload file using `ArrayBuffer` from base64 file data\n  * ```js\n  * import { decode } from 'base64-arraybuffer'\n  *\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .upload('public/avatar1.png', decode('base64FileData'), {\n  *     contentType: 'image/png'\n  *   })\n  * ```\n  */\n  async upload(path, fileBody, fileOptions) {\n    return this.uploadOrUpdate(\"POST\", path, fileBody, fileOptions);\n  }\n  /**\n  * Upload a file with a token generated from `createSignedUploadUrl`.\n  *\n  * @category File Buckets\n  * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n  * @param token The token generated from `createSignedUploadUrl`\n  * @param fileBody The body of the file to be stored in the bucket.\n  * @param fileOptions HTTP headers (cacheControl, contentType, etc.).\n  * **Note:** The `upsert` option has no effect here. To enable upsert behavior,\n  * pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\n  * @returns Promise with response containing file path and fullPath or error\n  *\n  * @example Upload to a signed URL\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"path\": \"folder/cat.jpg\",\n  *     \"fullPath\": \"avatars/folder/cat.jpg\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async uploadToSignedUrl(path, token, fileBody, fileOptions) {\n    var _this3 = this;\n    const cleanPath = _this3._removeEmptyFolders(path);\n    const _path = _this3._getFinalPath(cleanPath);\n    const url = new URL(_this3.url + `/object/upload/sign/${_path}`);\n    url.searchParams.set(\"token\", token);\n    return _this3.handleOperation(async () => {\n      let body;\n      const options = _objectSpread2({\n        upsert: DEFAULT_FILE_OPTIONS.upsert\n      }, fileOptions);\n      const headers = _objectSpread2(_objectSpread2({}, _this3.headers), {\n        \"x-upsert\": String(options.upsert)\n      });\n      if (typeof Blob !== \"undefined\" && fileBody instanceof Blob) {\n        body = new FormData();\n        body.append(\"cacheControl\", options.cacheControl);\n        body.append(\"\", fileBody);\n      } else if (typeof FormData !== \"undefined\" && fileBody instanceof FormData) {\n        body = fileBody;\n        body.append(\"cacheControl\", options.cacheControl);\n      } else {\n        body = fileBody;\n        headers[\"cache-control\"] = `max-age=${options.cacheControl}`;\n        headers[\"content-type\"] = options.contentType;\n      }\n      return {\n        path: cleanPath,\n        fullPath: (await put(_this3.fetch, url.toString(), body, {\n          headers\n        })).Key\n      };\n    });\n  }\n  /**\n  * Creates a signed upload URL.\n  * Signed upload URLs can be used to upload files to the bucket without further authentication.\n  * They are valid for 2 hours.\n  *\n  * @category File Buckets\n  * @param path The file path, including the current file name. For example `folder/image.png`.\n  * @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n  * @returns Promise with response containing signed upload URL, token, and path or error\n  *\n  * @example Create Signed Upload URL\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .createSignedUploadUrl('folder/cat.jpg')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\",\n  *     \"path\": \"folder/cat.jpg\",\n  *     \"token\": \"<TOKEN>\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async createSignedUploadUrl(path, options) {\n    var _this4 = this;\n    return _this4.handleOperation(async () => {\n      let _path = _this4._getFinalPath(path);\n      const headers = _objectSpread2({}, _this4.headers);\n      if (options === null || options === void 0 ? void 0 : options.upsert) headers[\"x-upsert\"] = \"true\";\n      const data = await post(_this4.fetch, `${_this4.url}/object/upload/sign/${_path}`, {}, {\n        headers\n      });\n      const url = new URL(_this4.url + data.url);\n      const token = url.searchParams.get(\"token\");\n      if (!token) throw new StorageError(\"No token returned by API\");\n      return {\n        signedUrl: url.toString(),\n        path,\n        token\n      };\n    });\n  }\n  /**\n  * Replaces an existing file at the specified path with a new one.\n  *\n  * @category File Buckets\n  * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n  * @param fileBody The body of the file to be stored in the bucket.\n  * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n  * @returns Promise with response containing file path, id, and fullPath or error\n  *\n  * @example Update file\n  * ```js\n  * const avatarFile = event.target.files[0]\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .update('public/avatar1.png', avatarFile, {\n  *     cacheControl: '3600',\n  *     upsert: true\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"path\": \"public/avatar1.png\",\n  *     \"fullPath\": \"avatars/public/avatar1.png\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  *\n  * @example Update file using `ArrayBuffer` from base64 file data\n  * ```js\n  * import {decode} from 'base64-arraybuffer'\n  *\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .update('public/avatar1.png', decode('base64FileData'), {\n  *     contentType: 'image/png'\n  *   })\n  * ```\n  */\n  async update(path, fileBody, fileOptions) {\n    return this.uploadOrUpdate(\"PUT\", path, fileBody, fileOptions);\n  }\n  /**\n  * Moves an existing file to a new path in the same bucket.\n  *\n  * @category File Buckets\n  * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n  * @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n  * @param options The destination options.\n  * @returns Promise with response containing success message or error\n  *\n  * @example Move file\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .move('public/avatar1.png', 'private/avatar2.png')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"message\": \"Successfully moved\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async move(fromPath, toPath, options) {\n    var _this6 = this;\n    return _this6.handleOperation(async () => {\n      return await post(_this6.fetch, `${_this6.url}/object/move`, {\n        bucketId: _this6.bucketId,\n        sourceKey: fromPath,\n        destinationKey: toPath,\n        destinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\n      }, {\n        headers: _this6.headers\n      });\n    });\n  }\n  /**\n  * Copies an existing file to a new path in the same bucket.\n  *\n  * @category File Buckets\n  * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n  * @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n  * @param options The destination options.\n  * @returns Promise with response containing copied file path or error\n  *\n  * @example Copy file\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .copy('public/avatar1.png', 'private/avatar2.png')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"path\": \"avatars/private/avatar2.png\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async copy(fromPath, toPath, options) {\n    var _this7 = this;\n    return _this7.handleOperation(async () => {\n      return {\n        path: (await post(_this7.fetch, `${_this7.url}/object/copy`, {\n          bucketId: _this7.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\n        }, {\n          headers: _this7.headers\n        })).Key\n      };\n    });\n  }\n  /**\n  * Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n  *\n  * @category File Buckets\n  * @param path The file path, including the current file name. For example `folder/image.png`.\n  * @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n  * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n  * @param options.transform Transform the asset before serving it to the client.\n  * @returns Promise with response containing signed URL or error\n  *\n  * @example Create Signed URL\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .createSignedUrl('folder/avatar1.png', 60)\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  *\n  * @example Create a signed URL for an asset with transformations\n  * ```js\n  * const { data } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .createSignedUrl('folder/avatar1.png', 60, {\n  *     transform: {\n  *       width: 100,\n  *       height: 100,\n  *     }\n  *   })\n  * ```\n  *\n  * @example Create a signed URL which triggers the download of the asset\n  * ```js\n  * const { data } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .createSignedUrl('folder/avatar1.png', 60, {\n  *     download: true,\n  *   })\n  * ```\n  */\n  async createSignedUrl(path, expiresIn, options) {\n    var _this8 = this;\n    return _this8.handleOperation(async () => {\n      let _path = _this8._getFinalPath(path);\n      let data = await post(_this8.fetch, `${_this8.url}/object/sign/${_path}`, _objectSpread2({\n        expiresIn\n      }, (options === null || options === void 0 ? void 0 : options.transform) ? {\n        transform: options.transform\n      } : {}), {\n        headers: _this8.headers\n      });\n      const downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `&download=${options.download === true ? \"\" : options.download}` : \"\";\n      return {\n        signedUrl: encodeURI(`${_this8.url}${data.signedURL}${downloadQueryParam}`)\n      };\n    });\n  }\n  /**\n  * Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n  *\n  * @category File Buckets\n  * @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n  * @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n  * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n  * @returns Promise with response containing array of objects with signedUrl, path, and error or error\n  *\n  * @example Create Signed URLs\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": [\n  *     {\n  *       \"error\": null,\n  *       \"path\": \"folder/avatar1.png\",\n  *       \"signedURL\": \"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\",\n  *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n  *     },\n  *     {\n  *       \"error\": null,\n  *       \"path\": \"folder/avatar2.png\",\n  *       \"signedURL\": \"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\",\n  *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\"\n  *     }\n  *   ],\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async createSignedUrls(paths, expiresIn, options) {\n    var _this9 = this;\n    return _this9.handleOperation(async () => {\n      const data = await post(_this9.fetch, `${_this9.url}/object/sign/${_this9.bucketId}`, {\n        expiresIn,\n        paths\n      }, {\n        headers: _this9.headers\n      });\n      const downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `&download=${options.download === true ? \"\" : options.download}` : \"\";\n      return data.map(datum => _objectSpread2(_objectSpread2({}, datum), {}, {\n        signedUrl: datum.signedURL ? encodeURI(`${_this9.url}${datum.signedURL}${downloadQueryParam}`) : null\n      }));\n    });\n  }\n  /**\n  * Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n  *\n  * @category File Buckets\n  * @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n  * @param options.transform Transform the asset before serving it to the client.\n  * @param parameters Additional fetch parameters like signal for cancellation. Supports standard fetch options including cache control.\n  * @returns BlobDownloadBuilder instance for downloading the file\n  *\n  * @example Download file\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .download('folder/avatar1.png')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": <BLOB>,\n  *   \"error\": null\n  * }\n  * ```\n  *\n  * @example Download file with transformations\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .download('folder/avatar1.png', {\n  *     transform: {\n  *       width: 100,\n  *       height: 100,\n  *       quality: 80\n  *     }\n  *   })\n  * ```\n  *\n  * @example Download with cache control (useful in Edge Functions)\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .download('folder/avatar1.png', {}, { cache: 'no-store' })\n  * ```\n  *\n  * @example Download with abort signal\n  * ```js\n  * const controller = new AbortController()\n  * setTimeout(() => controller.abort(), 5000)\n  *\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .download('folder/avatar1.png', {}, { signal: controller.signal })\n  * ```\n  */\n  download(path, options, parameters) {\n    const renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \"undefined\" ? \"render/image/authenticated\" : \"object\";\n    const transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n    const queryString = transformationQuery ? `?${transformationQuery}` : \"\";\n    const _path = this._getFinalPath(path);\n    const downloadFn = () => get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\n      headers: this.headers,\n      noResolveJson: true\n    }, parameters);\n    return new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError);\n  }\n  /**\n  * Retrieves the details of an existing file.\n  *\n  * @category File Buckets\n  * @param path The file path, including the file name. For example `folder/image.png`.\n  * @returns Promise with response containing file metadata or error\n  *\n  * @example Get file info\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .info('folder/avatar1.png')\n  * ```\n  */\n  async info(path) {\n    var _this10 = this;\n    const _path = _this10._getFinalPath(path);\n    return _this10.handleOperation(async () => {\n      return recursiveToCamel(await get(_this10.fetch, `${_this10.url}/object/info/${_path}`, {\n        headers: _this10.headers\n      }));\n    });\n  }\n  /**\n  * Checks the existence of a file.\n  *\n  * @category File Buckets\n  * @param path The file path, including the file name. For example `folder/image.png`.\n  * @returns Promise with response containing boolean indicating file existence or error\n  *\n  * @example Check file existence\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .exists('folder/avatar1.png')\n  * ```\n  */\n  async exists(path) {\n    var _this11 = this;\n    const _path = _this11._getFinalPath(path);\n    try {\n      await head(_this11.fetch, `${_this11.url}/object/${_path}`, {\n        headers: _this11.headers\n      });\n      return {\n        data: true,\n        error: null\n      };\n    } catch (error) {\n      if (_this11.shouldThrowOnError) throw error;\n      if (isStorageError(error) && error instanceof StorageUnknownError) {\n        const originalError = error.originalError;\n        if ([400, 404].includes(originalError === null || originalError === void 0 ? void 0 : originalError.status)) return {\n          data: false,\n          error\n        };\n      }\n      throw error;\n    }\n  }\n  /**\n  * A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n  * This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n  *\n  * @category File Buckets\n  * @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n  * @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n  * @param options.transform Transform the asset before serving it to the client.\n  * @returns Object with public URL\n  *\n  * @example Returns the URL for an asset in a public bucket\n  * ```js\n  * const { data } = supabase\n  *   .storage\n  *   .from('public-bucket')\n  *   .getPublicUrl('folder/avatar1.png')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"publicUrl\": \"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\"\n  *   }\n  * }\n  * ```\n  *\n  * @example Returns the URL for an asset in a public bucket with transformations\n  * ```js\n  * const { data } = supabase\n  *   .storage\n  *   .from('public-bucket')\n  *   .getPublicUrl('folder/avatar1.png', {\n  *     transform: {\n  *       width: 100,\n  *       height: 100,\n  *     }\n  *   })\n  * ```\n  *\n  * @example Returns the URL which triggers the download of an asset in a public bucket\n  * ```js\n  * const { data } = supabase\n  *   .storage\n  *   .from('public-bucket')\n  *   .getPublicUrl('folder/avatar1.png', {\n  *     download: true,\n  *   })\n  * ```\n  */\n  getPublicUrl(path, options) {\n    const _path = this._getFinalPath(path);\n    const _queryString = [];\n    const downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `download=${options.download === true ? \"\" : options.download}` : \"\";\n    if (downloadQueryParam !== \"\") _queryString.push(downloadQueryParam);\n    const renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \"undefined\" ? \"render/image\" : \"object\";\n    const transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n    if (transformationQuery !== \"\") _queryString.push(transformationQuery);\n    let queryString = _queryString.join(\"&\");\n    if (queryString !== \"\") queryString = `?${queryString}`;\n    return {\n      data: {\n        publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`)\n      }\n    };\n  }\n  /**\n  * Deletes files within the same bucket\n  *\n  * @category File Buckets\n  * @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n  * @returns Promise with response containing array of deleted file objects or error\n  *\n  * @example Delete file\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .remove(['folder/avatar1.png'])\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": [],\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async remove(paths) {\n    var _this12 = this;\n    return _this12.handleOperation(async () => {\n      return await remove(_this12.fetch, `${_this12.url}/object/${_this12.bucketId}`, {\n        prefixes: paths\n      }, {\n        headers: _this12.headers\n      });\n    });\n  }\n  /**\n  * Get file metadata\n  * @param id the file id to retrieve metadata\n  */\n  /**\n  * Update file metadata\n  * @param id the file id to update metadata\n  * @param meta the new file metadata\n  */\n  /**\n  * Lists all the files and folders within a path of the bucket.\n  *\n  * @category File Buckets\n  * @param path The folder path.\n  * @param options Search options including limit (defaults to 100), offset, sortBy, and search\n  * @param parameters Optional fetch parameters including signal for cancellation\n  * @returns Promise with response containing array of files or error\n  *\n  * @example List files in a bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .list('folder', {\n  *     limit: 100,\n  *     offset: 0,\n  *     sortBy: { column: 'name', order: 'asc' },\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": [\n  *     {\n  *       \"name\": \"avatar1.png\",\n  *       \"id\": \"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\",\n  *       \"updated_at\": \"2024-05-22T23:06:05.580Z\",\n  *       \"created_at\": \"2024-05-22T23:04:34.443Z\",\n  *       \"last_accessed_at\": \"2024-05-22T23:04:34.443Z\",\n  *       \"metadata\": {\n  *         \"eTag\": \"\\\"c5e8c553235d9af30ef4f6e280790b92\\\"\",\n  *         \"size\": 32175,\n  *         \"mimetype\": \"image/png\",\n  *         \"cacheControl\": \"max-age=3600\",\n  *         \"lastModified\": \"2024-05-22T23:06:05.574Z\",\n  *         \"contentLength\": 32175,\n  *         \"httpStatusCode\": 200\n  *       }\n  *     }\n  *   ],\n  *   \"error\": null\n  * }\n  * ```\n  *\n  * @example Search files in a bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .from('avatars')\n  *   .list('folder', {\n  *     limit: 100,\n  *     offset: 0,\n  *     sortBy: { column: 'name', order: 'asc' },\n  *     search: 'jon'\n  *   })\n  * ```\n  */\n  async list(path, options, parameters) {\n    var _this13 = this;\n    return _this13.handleOperation(async () => {\n      const body = _objectSpread2(_objectSpread2(_objectSpread2({}, DEFAULT_SEARCH_OPTIONS), options), {}, {\n        prefix: path || \"\"\n      });\n      return await post(_this13.fetch, `${_this13.url}/object/list/${_this13.bucketId}`, body, {\n        headers: _this13.headers\n      }, parameters);\n    });\n  }\n  /**\n  * @experimental this method signature might change in the future\n  *\n  * @category File Buckets\n  * @param options search options\n  * @param parameters\n  */\n  async listV2(options, parameters) {\n    var _this14 = this;\n    return _this14.handleOperation(async () => {\n      const body = _objectSpread2({}, options);\n      return await post(_this14.fetch, `${_this14.url}/object/list-v2/${_this14.bucketId}`, body, {\n        headers: _this14.headers\n      }, parameters);\n    });\n  }\n  encodeMetadata(metadata) {\n    return JSON.stringify(metadata);\n  }\n  toBase64(data) {\n    if (typeof Buffer !== \"undefined\") return Buffer.from(data).toString(\"base64\");\n    return btoa(data);\n  }\n  _getFinalPath(path) {\n    return `${this.bucketId}/${path.replace(/^\\/+/, \"\")}`;\n  }\n  _removeEmptyFolders(path) {\n    return path.replace(/^\\/|\\/$/g, \"\").replace(/\\/+/g, \"/\");\n  }\n  transformOptsToQueryString(transform) {\n    const params = [];\n    if (transform.width) params.push(`width=${transform.width}`);\n    if (transform.height) params.push(`height=${transform.height}`);\n    if (transform.resize) params.push(`resize=${transform.resize}`);\n    if (transform.format) params.push(`format=${transform.format}`);\n    if (transform.quality) params.push(`quality=${transform.quality}`);\n    return params.join(\"&\");\n  }\n};\n\n//#endregion\n//#region src/lib/version.ts\nconst version = \"2.95.3\";\n\n//#endregion\n//#region src/lib/constants.ts\nconst DEFAULT_HEADERS = {\n  \"X-Client-Info\": `storage-js/${version}`\n};\n\n//#endregion\n//#region src/packages/StorageBucketApi.ts\nvar StorageBucketApi = class extends BaseApiClient {\n  constructor(url, headers = {}, fetch$1, opts) {\n    const baseUrl = new URL(url);\n    if (opts === null || opts === void 0 ? void 0 : opts.useNewHostname) {\n      if (/supabase\\.(co|in|red)$/.test(baseUrl.hostname) && !baseUrl.hostname.includes(\"storage.supabase.\")) baseUrl.hostname = baseUrl.hostname.replace(\"supabase.\", \"storage.supabase.\");\n    }\n    const finalUrl = baseUrl.href.replace(/\\/$/, \"\");\n    const finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n    super(finalUrl, finalHeaders, fetch$1, \"storage\");\n  }\n  /**\n  * Retrieves the details of all Storage buckets within an existing project.\n  *\n  * @category File Buckets\n  * @param options Query parameters for listing buckets\n  * @param options.limit Maximum number of buckets to return\n  * @param options.offset Number of buckets to skip\n  * @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\n  * @param options.sortOrder Sort order ('asc' or 'desc')\n  * @param options.search Search term to filter bucket names\n  * @returns Promise with response containing array of buckets or error\n  *\n  * @example List buckets\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .listBuckets()\n  * ```\n  *\n  * @example List buckets with options\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .listBuckets({\n  *     limit: 10,\n  *     offset: 0,\n  *     sortColumn: 'created_at',\n  *     sortOrder: 'desc',\n  *     search: 'prod'\n  *   })\n  * ```\n  */\n  async listBuckets(options) {\n    var _this = this;\n    return _this.handleOperation(async () => {\n      const queryString = _this.listBucketOptionsToQueryString(options);\n      return await get(_this.fetch, `${_this.url}/bucket${queryString}`, {\n        headers: _this.headers\n      });\n    });\n  }\n  /**\n  * Retrieves the details of an existing Storage bucket.\n  *\n  * @category File Buckets\n  * @param id The unique identifier of the bucket you would like to retrieve.\n  * @returns Promise with response containing bucket details or error\n  *\n  * @example Get bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .getBucket('avatars')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"id\": \"avatars\",\n  *     \"name\": \"avatars\",\n  *     \"owner\": \"\",\n  *     \"public\": false,\n  *     \"file_size_limit\": 1024,\n  *     \"allowed_mime_types\": [\n  *       \"image/png\"\n  *     ],\n  *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n  *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async getBucket(id) {\n    var _this2 = this;\n    return _this2.handleOperation(async () => {\n      return await get(_this2.fetch, `${_this2.url}/bucket/${id}`, {\n        headers: _this2.headers\n      });\n    });\n  }\n  /**\n  * Creates a new Storage bucket\n  *\n  * @category File Buckets\n  * @param id A unique identifier for the bucket you are creating.\n  * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n  * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n  * The global file size limit takes precedence over this value.\n  * The default value is null, which doesn't set a per bucket file size limit.\n  * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n  * The default value is null, which allows files with all mime types to be uploaded.\n  * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n  * @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n  *   - default bucket type is `STANDARD`\n  * @returns Promise with response containing newly created bucket name or error\n  *\n  * @example Create bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .createBucket('avatars', {\n  *     public: false,\n  *     allowedMimeTypes: ['image/png'],\n  *     fileSizeLimit: 1024\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"name\": \"avatars\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async createBucket(id, options = {\n    public: false\n  }) {\n    var _this3 = this;\n    return _this3.handleOperation(async () => {\n      return await post(_this3.fetch, `${_this3.url}/bucket`, {\n        id,\n        name: id,\n        type: options.type,\n        public: options.public,\n        file_size_limit: options.fileSizeLimit,\n        allowed_mime_types: options.allowedMimeTypes\n      }, {\n        headers: _this3.headers\n      });\n    });\n  }\n  /**\n  * Updates a Storage bucket\n  *\n  * @category File Buckets\n  * @param id A unique identifier for the bucket you are updating.\n  * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n  * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n  * The global file size limit takes precedence over this value.\n  * The default value is null, which doesn't set a per bucket file size limit.\n  * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n  * The default value is null, which allows files with all mime types to be uploaded.\n  * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n  * @returns Promise with response containing success message or error\n  *\n  * @example Update bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .updateBucket('avatars', {\n  *     public: false,\n  *     allowedMimeTypes: ['image/png'],\n  *     fileSizeLimit: 1024\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"message\": \"Successfully updated\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async updateBucket(id, options) {\n    var _this4 = this;\n    return _this4.handleOperation(async () => {\n      return await put(_this4.fetch, `${_this4.url}/bucket/${id}`, {\n        id,\n        name: id,\n        public: options.public,\n        file_size_limit: options.fileSizeLimit,\n        allowed_mime_types: options.allowedMimeTypes\n      }, {\n        headers: _this4.headers\n      });\n    });\n  }\n  /**\n  * Removes all objects inside a single bucket.\n  *\n  * @category File Buckets\n  * @param id The unique identifier of the bucket you would like to empty.\n  * @returns Promise with success message or error\n  *\n  * @example Empty bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .emptyBucket('avatars')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"message\": \"Successfully emptied\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async emptyBucket(id) {\n    var _this5 = this;\n    return _this5.handleOperation(async () => {\n      return await post(_this5.fetch, `${_this5.url}/bucket/${id}/empty`, {}, {\n        headers: _this5.headers\n      });\n    });\n  }\n  /**\n  * Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n  * You must first `empty()` the bucket.\n  *\n  * @category File Buckets\n  * @param id The unique identifier of the bucket you would like to delete.\n  * @returns Promise with success message or error\n  *\n  * @example Delete bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .deleteBucket('avatars')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"message\": \"Successfully deleted\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async deleteBucket(id) {\n    var _this6 = this;\n    return _this6.handleOperation(async () => {\n      return await remove(_this6.fetch, `${_this6.url}/bucket/${id}`, {}, {\n        headers: _this6.headers\n      });\n    });\n  }\n  listBucketOptionsToQueryString(options) {\n    const params = {};\n    if (options) {\n      if (\"limit\" in options) params.limit = String(options.limit);\n      if (\"offset\" in options) params.offset = String(options.offset);\n      if (options.search) params.search = options.search;\n      if (options.sortColumn) params.sortColumn = options.sortColumn;\n      if (options.sortOrder) params.sortOrder = options.sortOrder;\n    }\n    return Object.keys(params).length > 0 ? \"?\" + new URLSearchParams(params).toString() : \"\";\n  }\n};\n\n//#endregion\n//#region src/packages/StorageAnalyticsClient.ts\n/**\n* Client class for managing Analytics Buckets using Iceberg tables\n* Provides methods for creating, listing, and deleting analytics buckets\n*/\nvar StorageAnalyticsClient = class extends BaseApiClient {\n  /**\n  * @alpha\n  *\n  * Creates a new StorageAnalyticsClient instance\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @param url - The base URL for the storage API\n  * @param headers - HTTP headers to include in requests\n  * @param fetch - Optional custom fetch implementation\n  *\n  * @example\n  * ```typescript\n  * const client = new StorageAnalyticsClient(url, headers)\n  * ```\n  */\n  constructor(url, headers = {}, fetch$1) {\n    const finalUrl = url.replace(/\\/$/, \"\");\n    const finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n    super(finalUrl, finalHeaders, fetch$1, \"storage\");\n  }\n  /**\n  * @alpha\n  *\n  * Creates a new analytics bucket using Iceberg tables\n  * Analytics buckets are optimized for analytical queries and data processing\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @param name A unique name for the bucket you are creating\n  * @returns Promise with response containing newly created analytics bucket or error\n  *\n  * @example Create analytics bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .analytics\n  *   .createBucket('analytics-data')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"name\": \"analytics-data\",\n  *     \"type\": \"ANALYTICS\",\n  *     \"format\": \"iceberg\",\n  *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n  *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async createBucket(name) {\n    var _this = this;\n    return _this.handleOperation(async () => {\n      return await post(_this.fetch, `${_this.url}/bucket`, {\n        name\n      }, {\n        headers: _this.headers\n      });\n    });\n  }\n  /**\n  * @alpha\n  *\n  * Retrieves the details of all Analytics Storage buckets within an existing project\n  * Only returns buckets of type 'ANALYTICS'\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @param options Query parameters for listing buckets\n  * @param options.limit Maximum number of buckets to return\n  * @param options.offset Number of buckets to skip\n  * @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\n  * @param options.sortOrder Sort order ('asc' or 'desc')\n  * @param options.search Search term to filter bucket names\n  * @returns Promise with response containing array of analytics buckets or error\n  *\n  * @example List analytics buckets\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .analytics\n  *   .listBuckets({\n  *     limit: 10,\n  *     offset: 0,\n  *     sortColumn: 'created_at',\n  *     sortOrder: 'desc'\n  *   })\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": [\n  *     {\n  *       \"name\": \"analytics-data\",\n  *       \"type\": \"ANALYTICS\",\n  *       \"format\": \"iceberg\",\n  *       \"created_at\": \"2024-05-22T22:26:05.100Z\",\n  *       \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n  *     }\n  *   ],\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async listBuckets(options) {\n    var _this2 = this;\n    return _this2.handleOperation(async () => {\n      const queryParams = new URLSearchParams();\n      if ((options === null || options === void 0 ? void 0 : options.limit) !== void 0) queryParams.set(\"limit\", options.limit.toString());\n      if ((options === null || options === void 0 ? void 0 : options.offset) !== void 0) queryParams.set(\"offset\", options.offset.toString());\n      if (options === null || options === void 0 ? void 0 : options.sortColumn) queryParams.set(\"sortColumn\", options.sortColumn);\n      if (options === null || options === void 0 ? void 0 : options.sortOrder) queryParams.set(\"sortOrder\", options.sortOrder);\n      if (options === null || options === void 0 ? void 0 : options.search) queryParams.set(\"search\", options.search);\n      const queryString = queryParams.toString();\n      const url = queryString ? `${_this2.url}/bucket?${queryString}` : `${_this2.url}/bucket`;\n      return await get(_this2.fetch, url, {\n        headers: _this2.headers\n      });\n    });\n  }\n  /**\n  * @alpha\n  *\n  * Deletes an existing analytics bucket\n  * A bucket can't be deleted with existing objects inside it\n  * You must first empty the bucket before deletion\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @param bucketName The unique identifier of the bucket you would like to delete\n  * @returns Promise with response containing success message or error\n  *\n  * @example Delete analytics bucket\n  * ```js\n  * const { data, error } = await supabase\n  *   .storage\n  *   .analytics\n  *   .deleteBucket('analytics-data')\n  * ```\n  *\n  * Response:\n  * ```json\n  * {\n  *   \"data\": {\n  *     \"message\": \"Successfully deleted\"\n  *   },\n  *   \"error\": null\n  * }\n  * ```\n  */\n  async deleteBucket(bucketName) {\n    var _this3 = this;\n    return _this3.handleOperation(async () => {\n      return await remove(_this3.fetch, `${_this3.url}/bucket/${bucketName}`, {}, {\n        headers: _this3.headers\n      });\n    });\n  }\n  /**\n  * @alpha\n  *\n  * Get an Iceberg REST Catalog client configured for a specific analytics bucket\n  * Use this to perform advanced table and namespace operations within the bucket\n  * The returned client provides full access to the Apache Iceberg REST Catalog API\n  * with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @param bucketName - The name of the analytics bucket (warehouse) to connect to\n  * @returns The wrapped Iceberg catalog client\n  * @throws {StorageError} If the bucket name is invalid\n  *\n  * @example Get catalog and create table\n  * ```js\n  * // First, create an analytics bucket\n  * const { data: bucket, error: bucketError } = await supabase\n  *   .storage\n  *   .analytics\n  *   .createBucket('analytics-data')\n  *\n  * // Get the Iceberg catalog for that bucket\n  * const catalog = supabase.storage.analytics.from('analytics-data')\n  *\n  * // Create a namespace\n  * const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\n  *\n  * // Create a table with schema\n  * const { data: tableMetadata, error: tableError } = await catalog.createTable(\n  *   { namespace: ['default'] },\n  *   {\n  *     name: 'events',\n  *     schema: {\n  *       type: 'struct',\n  *       fields: [\n  *         { id: 1, name: 'id', type: 'long', required: true },\n  *         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\n  *         { id: 3, name: 'user_id', type: 'string', required: false }\n  *       ],\n  *       'schema-id': 0,\n  *       'identifier-field-ids': [1]\n  *     },\n  *     'partition-spec': {\n  *       'spec-id': 0,\n  *       fields: []\n  *     },\n  *     'write-order': {\n  *       'order-id': 0,\n  *       fields: []\n  *     },\n  *     properties: {\n  *       'write.format.default': 'parquet'\n  *     }\n  *   }\n  * )\n  * ```\n  *\n  * @example List tables in namespace\n  * ```js\n  * const catalog = supabase.storage.analytics.from('analytics-data')\n  *\n  * // List all tables in the default namespace\n  * const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\n  * if (listError) {\n  *   if (listError.isNotFound()) {\n  *     console.log('Namespace not found')\n  *   }\n  *   return\n  * }\n  * console.log(tables) // [{ namespace: ['default'], name: 'events' }]\n  * ```\n  *\n  * @example Working with namespaces\n  * ```js\n  * const catalog = supabase.storage.analytics.from('analytics-data')\n  *\n  * // List all namespaces\n  * const { data: namespaces } = await catalog.listNamespaces()\n  *\n  * // Create namespace with properties\n  * await catalog.createNamespace(\n  *   { namespace: ['production'] },\n  *   { properties: { owner: 'data-team', env: 'prod' } }\n  * )\n  * ```\n  *\n  * @example Cleanup operations\n  * ```js\n  * const catalog = supabase.storage.analytics.from('analytics-data')\n  *\n  * // Drop table with purge option (removes all data)\n  * const { error: dropError } = await catalog.dropTable(\n  *   { namespace: ['default'], name: 'events' },\n  *   { purge: true }\n  * )\n  *\n  * if (dropError?.isNotFound()) {\n  *   console.log('Table does not exist')\n  * }\n  *\n  * // Drop namespace (must be empty)\n  * await catalog.dropNamespace({ namespace: ['default'] })\n  * ```\n  *\n  * @remarks\n  * This method provides a bridge between Supabase's bucket management and the standard\n  * Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\n  * All authentication and configuration is handled automatically using your Supabase credentials.\n  *\n  * **Error Handling**: Invalid bucket names throw immediately. All catalog\n  * operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\n  * Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\n  * Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\n  *\n  * **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\n  * deletes all table data. Without it, the table is marked as deleted but data remains.\n  *\n  * **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\n  * For complete API documentation and advanced usage, refer to the\n  * [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\n  */\n  from(bucketName) {\n    var _this4 = this;\n    if (!isValidBucketName(bucketName)) throw new StorageError(\"Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines and should avoid the use of any other characters.\");\n    const catalog = new IcebergRestCatalog({\n      baseUrl: this.url,\n      catalogName: bucketName,\n      auth: {\n        type: \"custom\",\n        getHeaders: async () => _this4.headers\n      },\n      fetch: this.fetch\n    });\n    const shouldThrowOnError = this.shouldThrowOnError;\n    return new Proxy(catalog, {\n      get(target, prop) {\n        const value = target[prop];\n        if (typeof value !== \"function\") return value;\n        return async (...args) => {\n          try {\n            return {\n              data: await value.apply(target, args),\n              error: null\n            };\n          } catch (error) {\n            if (shouldThrowOnError) throw error;\n            return {\n              data: null,\n              error\n            };\n          }\n        };\n      }\n    });\n  }\n};\n\n//#endregion\n//#region src/packages/VectorIndexApi.ts\n/**\n* @hidden\n* Base implementation for vector index operations.\n* Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\n*/\nvar VectorIndexApi = class extends BaseApiClient {\n  /** Creates a new VectorIndexApi instance */\n  constructor(url, headers = {}, fetch$1) {\n    const finalUrl = url.replace(/\\/$/, \"\");\n    const finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, {\n      \"Content-Type\": \"application/json\"\n    }, headers);\n    super(finalUrl, finalHeaders, fetch$1, \"vectors\");\n  }\n  /** Creates a new vector index within a bucket */\n  async createIndex(options) {\n    var _this = this;\n    return _this.handleOperation(async () => {\n      return (await vectorsApi.post(_this.fetch, `${_this.url}/CreateIndex`, options, {\n        headers: _this.headers\n      })) || {};\n    });\n  }\n  /** Retrieves metadata for a specific vector index */\n  async getIndex(vectorBucketName, indexName) {\n    var _this2 = this;\n    return _this2.handleOperation(async () => {\n      return await vectorsApi.post(_this2.fetch, `${_this2.url}/GetIndex`, {\n        vectorBucketName,\n        indexName\n      }, {\n        headers: _this2.headers\n      });\n    });\n  }\n  /** Lists vector indexes within a bucket with optional filtering and pagination */\n  async listIndexes(options) {\n    var _this3 = this;\n    return _this3.handleOperation(async () => {\n      return await vectorsApi.post(_this3.fetch, `${_this3.url}/ListIndexes`, options, {\n        headers: _this3.headers\n      });\n    });\n  }\n  /** Deletes a vector index and all its data */\n  async deleteIndex(vectorBucketName, indexName) {\n    var _this4 = this;\n    return _this4.handleOperation(async () => {\n      return (await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteIndex`, {\n        vectorBucketName,\n        indexName\n      }, {\n        headers: _this4.headers\n      })) || {};\n    });\n  }\n};\n\n//#endregion\n//#region src/packages/VectorDataApi.ts\n/**\n* @hidden\n* Base implementation for vector data operations.\n* Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\n*/\nvar VectorDataApi = class extends BaseApiClient {\n  /** Creates a new VectorDataApi instance */\n  constructor(url, headers = {}, fetch$1) {\n    const finalUrl = url.replace(/\\/$/, \"\");\n    const finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, {\n      \"Content-Type\": \"application/json\"\n    }, headers);\n    super(finalUrl, finalHeaders, fetch$1, \"vectors\");\n  }\n  /** Inserts or updates vectors in batch (1-500 per request) */\n  async putVectors(options) {\n    var _this = this;\n    if (options.vectors.length < 1 || options.vectors.length > 500) throw new Error(\"Vector batch size must be between 1 and 500 items\");\n    return _this.handleOperation(async () => {\n      return (await vectorsApi.post(_this.fetch, `${_this.url}/PutVectors`, options, {\n        headers: _this.headers\n      })) || {};\n    });\n  }\n  /** Retrieves vectors by their keys in batch */\n  async getVectors(options) {\n    var _this2 = this;\n    return _this2.handleOperation(async () => {\n      return await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectors`, options, {\n        headers: _this2.headers\n      });\n    });\n  }\n  /** Lists vectors in an index with pagination */\n  async listVectors(options) {\n    var _this3 = this;\n    if (options.segmentCount !== void 0) {\n      if (options.segmentCount < 1 || options.segmentCount > 16) throw new Error(\"segmentCount must be between 1 and 16\");\n      if (options.segmentIndex !== void 0) {\n        if (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`);\n      }\n    }\n    return _this3.handleOperation(async () => {\n      return await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectors`, options, {\n        headers: _this3.headers\n      });\n    });\n  }\n  /** Queries for similar vectors using approximate nearest neighbor search */\n  async queryVectors(options) {\n    var _this4 = this;\n    return _this4.handleOperation(async () => {\n      return await vectorsApi.post(_this4.fetch, `${_this4.url}/QueryVectors`, options, {\n        headers: _this4.headers\n      });\n    });\n  }\n  /** Deletes vectors by their keys in batch (1-500 per request) */\n  async deleteVectors(options) {\n    var _this5 = this;\n    if (options.keys.length < 1 || options.keys.length > 500) throw new Error(\"Keys batch size must be between 1 and 500 items\");\n    return _this5.handleOperation(async () => {\n      return (await vectorsApi.post(_this5.fetch, `${_this5.url}/DeleteVectors`, options, {\n        headers: _this5.headers\n      })) || {};\n    });\n  }\n};\n\n//#endregion\n//#region src/packages/VectorBucketApi.ts\n/**\n* @hidden\n* Base implementation for vector bucket operations.\n* Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\n*/\nvar VectorBucketApi = class extends BaseApiClient {\n  /** Creates a new VectorBucketApi instance */\n  constructor(url, headers = {}, fetch$1) {\n    const finalUrl = url.replace(/\\/$/, \"\");\n    const finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, {\n      \"Content-Type\": \"application/json\"\n    }, headers);\n    super(finalUrl, finalHeaders, fetch$1, \"vectors\");\n  }\n  /** Creates a new vector bucket */\n  async createBucket(vectorBucketName) {\n    var _this = this;\n    return _this.handleOperation(async () => {\n      return (await vectorsApi.post(_this.fetch, `${_this.url}/CreateVectorBucket`, {\n        vectorBucketName\n      }, {\n        headers: _this.headers\n      })) || {};\n    });\n  }\n  /** Retrieves metadata for a specific vector bucket */\n  async getBucket(vectorBucketName) {\n    var _this2 = this;\n    return _this2.handleOperation(async () => {\n      return await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectorBucket`, {\n        vectorBucketName\n      }, {\n        headers: _this2.headers\n      });\n    });\n  }\n  /** Lists vector buckets with optional filtering and pagination */\n  async listBuckets(options = {}) {\n    var _this3 = this;\n    return _this3.handleOperation(async () => {\n      return await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectorBuckets`, options, {\n        headers: _this3.headers\n      });\n    });\n  }\n  /** Deletes a vector bucket (must be empty first) */\n  async deleteBucket(vectorBucketName) {\n    var _this4 = this;\n    return _this4.handleOperation(async () => {\n      return (await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteVectorBucket`, {\n        vectorBucketName\n      }, {\n        headers: _this4.headers\n      })) || {};\n    });\n  }\n};\n\n//#endregion\n//#region src/packages/StorageVectorsClient.ts\n/**\n*\n* @alpha\n*\n* Main client for interacting with S3 Vectors API\n* Provides access to bucket, index, and vector data operations\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*\n* **Usage Patterns:**\n*\n* ```typescript\n* const { data, error } = await supabase\n*  .storage\n*  .vectors\n*  .createBucket('embeddings-prod')\n*\n* // Access index operations via buckets\n* const bucket = supabase.storage.vectors.from('embeddings-prod')\n* await bucket.createIndex({\n*   indexName: 'documents',\n*   dataType: 'float32',\n*   dimension: 1536,\n*   distanceMetric: 'cosine'\n* })\n*\n* // Access vector operations via index\n* const index = bucket.index('documents')\n* await index.putVectors({\n*   vectors: [\n*     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n*   ]\n* })\n*\n* // Query similar vectors\n* const { data } = await index.queryVectors({\n*   queryVector: { float32: [...] },\n*   topK: 5,\n*   returnDistance: true\n* })\n* ```\n*/\nvar StorageVectorsClient = class extends VectorBucketApi {\n  /**\n  * @alpha\n  *\n  * Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param url - Base URL of the Storage Vectors REST API.\n  * @param options.headers - Optional headers (for example `Authorization`) applied to every request.\n  * @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\n  *\n  * @example\n  * ```typescript\n  * const client = new StorageVectorsClient(url, options)\n  * ```\n  */\n  constructor(url, options = {}) {\n    super(url, options.headers || {}, options.fetch);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Access operations for a specific vector bucket\n  * Returns a scoped client for index and vector operations within the bucket\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param vectorBucketName - Name of the vector bucket\n  * @returns Bucket-scoped client with index and vector operations\n  *\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * ```\n  */\n  from(vectorBucketName) {\n    return new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Creates a new vector bucket\n  * Vector buckets are containers for vector indexes and their data\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param vectorBucketName - Unique name for the vector bucket\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const { data, error } = await supabase\n  *   .storage\n  *   .vectors\n  *   .createBucket('embeddings-prod')\n  * ```\n  */\n  async createBucket(vectorBucketName) {\n    var _superprop_getCreateBucket = () => super.createBucket,\n      _this = this;\n    return _superprop_getCreateBucket().call(_this, vectorBucketName);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Retrieves metadata for a specific vector bucket\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param vectorBucketName - Name of the vector bucket\n  * @returns Promise with bucket metadata or error\n  *\n  * @example\n  * ```typescript\n  * const { data, error } = await supabase\n  *   .storage\n  *   .vectors\n  *   .getBucket('embeddings-prod')\n  *\n  * console.log('Bucket created:', data?.vectorBucket.creationTime)\n  * ```\n  */\n  async getBucket(vectorBucketName) {\n    var _superprop_getGetBucket = () => super.getBucket,\n      _this2 = this;\n    return _superprop_getGetBucket().call(_this2, vectorBucketName);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Lists all vector buckets with optional filtering and pagination\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Optional filters (prefix, maxResults, nextToken)\n  * @returns Promise with list of buckets or error\n  *\n  * @example\n  * ```typescript\n  * const { data, error } = await supabase\n  *   .storage\n  *   .vectors\n  *   .listBuckets({ prefix: 'embeddings-' })\n  *\n  * data?.vectorBuckets.forEach(bucket => {\n  *   console.log(bucket.vectorBucketName)\n  * })\n  * ```\n  */\n  async listBuckets(options = {}) {\n    var _superprop_getListBuckets = () => super.listBuckets,\n      _this3 = this;\n    return _superprop_getListBuckets().call(_this3, options);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Deletes a vector bucket (bucket must be empty)\n  * All indexes must be deleted before deleting the bucket\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param vectorBucketName - Name of the vector bucket to delete\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const { data, error } = await supabase\n  *   .storage\n  *   .vectors\n  *   .deleteBucket('embeddings-old')\n  * ```\n  */\n  async deleteBucket(vectorBucketName) {\n    var _superprop_getDeleteBucket = () => super.deleteBucket,\n      _this4 = this;\n    return _superprop_getDeleteBucket().call(_this4, vectorBucketName);\n  }\n};\n/**\n*\n* @alpha\n*\n* Scoped client for operations within a specific vector bucket\n* Provides index management and access to vector operations\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*/\nvar VectorBucketScope = class extends VectorIndexApi {\n  /**\n  * @alpha\n  *\n  * Creates a helper that automatically scopes all index operations to the provided bucket.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * ```\n  */\n  constructor(url, headers, vectorBucketName, fetch$1) {\n    super(url, headers, fetch$1);\n    this.vectorBucketName = vectorBucketName;\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Creates a new vector index in this bucket\n  * Convenience method that automatically includes the bucket name\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Index configuration (vectorBucketName is automatically set)\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * await bucket.createIndex({\n  *   indexName: 'documents-openai',\n  *   dataType: 'float32',\n  *   dimension: 1536,\n  *   distanceMetric: 'cosine',\n  *   metadataConfiguration: {\n  *     nonFilterableMetadataKeys: ['raw_text']\n  *   }\n  * })\n  * ```\n  */\n  async createIndex(options) {\n    var _superprop_getCreateIndex = () => super.createIndex,\n      _this5 = this;\n    return _superprop_getCreateIndex().call(_this5, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this5.vectorBucketName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Lists indexes in this bucket\n  * Convenience method that automatically includes the bucket name\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Listing options (vectorBucketName is automatically set)\n  * @returns Promise with response containing indexes array and pagination token or error\n  *\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * const { data } = await bucket.listIndexes({ prefix: 'documents-' })\n  * ```\n  */\n  async listIndexes(options = {}) {\n    var _superprop_getListIndexes = () => super.listIndexes,\n      _this6 = this;\n    return _superprop_getListIndexes().call(_this6, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this6.vectorBucketName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Retrieves metadata for a specific index in this bucket\n  * Convenience method that automatically includes the bucket name\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param indexName - Name of the index to retrieve\n  * @returns Promise with index metadata or error\n  *\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * const { data } = await bucket.getIndex('documents-openai')\n  * console.log('Dimension:', data?.index.dimension)\n  * ```\n  */\n  async getIndex(indexName) {\n    var _superprop_getGetIndex = () => super.getIndex,\n      _this7 = this;\n    return _superprop_getGetIndex().call(_this7, _this7.vectorBucketName, indexName);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Deletes an index from this bucket\n  * Convenience method that automatically includes the bucket name\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param indexName - Name of the index to delete\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const bucket = supabase.storage.vectors.from('embeddings-prod')\n  * await bucket.deleteIndex('old-index')\n  * ```\n  */\n  async deleteIndex(indexName) {\n    var _superprop_getDeleteIndex = () => super.deleteIndex,\n      _this8 = this;\n    return _superprop_getDeleteIndex().call(_this8, _this8.vectorBucketName, indexName);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Access operations for a specific index within this bucket\n  * Returns a scoped client for vector data operations\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param indexName - Name of the index\n  * @returns Index-scoped client with vector data operations\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  *\n  * // Insert vectors\n  * await index.putVectors({\n  *   vectors: [\n  *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n  *   ]\n  * })\n  *\n  * // Query similar vectors\n  * const { data } = await index.queryVectors({\n  *   queryVector: { float32: [...] },\n  *   topK: 5\n  * })\n  * ```\n  */\n  index(indexName) {\n    return new VectorIndexScope(this.url, this.headers, this.vectorBucketName, indexName, this.fetch);\n  }\n};\n/**\n*\n* @alpha\n*\n* Scoped client for operations within a specific vector index\n* Provides vector data operations (put, get, list, query, delete)\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*/\nvar VectorIndexScope = class extends VectorDataApi {\n  /**\n  *\n  * @alpha\n  *\n  * Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * ```\n  */\n  constructor(url, headers, vectorBucketName, indexName, fetch$1) {\n    super(url, headers, fetch$1);\n    this.vectorBucketName = vectorBucketName;\n    this.indexName = indexName;\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Inserts or updates vectors in this index\n  * Convenience method that automatically includes bucket and index names\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Vector insertion options (bucket and index names automatically set)\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * await index.putVectors({\n  *   vectors: [\n  *     {\n  *       key: 'doc-1',\n  *       data: { float32: [0.1, 0.2, ...] },\n  *       metadata: { title: 'Introduction', page: 1 }\n  *     }\n  *   ]\n  * })\n  * ```\n  */\n  async putVectors(options) {\n    var _superprop_getPutVectors = () => super.putVectors,\n      _this9 = this;\n    return _superprop_getPutVectors().call(_this9, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this9.vectorBucketName,\n      indexName: _this9.indexName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Retrieves vectors by keys from this index\n  * Convenience method that automatically includes bucket and index names\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Vector retrieval options (bucket and index names automatically set)\n  * @returns Promise with response containing vectors array or error\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * const { data } = await index.getVectors({\n  *   keys: ['doc-1', 'doc-2'],\n  *   returnMetadata: true\n  * })\n  * ```\n  */\n  async getVectors(options) {\n    var _superprop_getGetVectors = () => super.getVectors,\n      _this10 = this;\n    return _superprop_getGetVectors().call(_this10, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this10.vectorBucketName,\n      indexName: _this10.indexName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Lists vectors in this index with pagination\n  * Convenience method that automatically includes bucket and index names\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Listing options (bucket and index names automatically set)\n  * @returns Promise with response containing vectors array and pagination token or error\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * const { data } = await index.listVectors({\n  *   maxResults: 500,\n  *   returnMetadata: true\n  * })\n  * ```\n  */\n  async listVectors(options = {}) {\n    var _superprop_getListVectors = () => super.listVectors,\n      _this11 = this;\n    return _superprop_getListVectors().call(_this11, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this11.vectorBucketName,\n      indexName: _this11.indexName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Queries for similar vectors in this index\n  * Convenience method that automatically includes bucket and index names\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Query options (bucket and index names automatically set)\n  * @returns Promise with response containing matches array of similar vectors ordered by distance or error\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * const { data } = await index.queryVectors({\n  *   queryVector: { float32: [0.1, 0.2, ...] },\n  *   topK: 5,\n  *   filter: { category: 'technical' },\n  *   returnDistance: true,\n  *   returnMetadata: true\n  * })\n  * ```\n  */\n  async queryVectors(options) {\n    var _superprop_getQueryVectors = () => super.queryVectors,\n      _this12 = this;\n    return _superprop_getQueryVectors().call(_this12, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this12.vectorBucketName,\n      indexName: _this12.indexName\n    }));\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Deletes vectors by keys from this index\n  * Convenience method that automatically includes bucket and index names\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @param options - Deletion options (bucket and index names automatically set)\n  * @returns Promise with empty response on success or error\n  *\n  * @example\n  * ```typescript\n  * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n  * await index.deleteVectors({\n  *   keys: ['doc-1', 'doc-2', 'doc-3']\n  * })\n  * ```\n  */\n  async deleteVectors(options) {\n    var _superprop_getDeleteVectors = () => super.deleteVectors,\n      _this13 = this;\n    return _superprop_getDeleteVectors().call(_this13, _objectSpread2(_objectSpread2({}, options), {}, {\n      vectorBucketName: _this13.vectorBucketName,\n      indexName: _this13.indexName\n    }));\n  }\n};\n\n//#endregion\n//#region src/StorageClient.ts\nvar StorageClient = class extends StorageBucketApi {\n  /**\n  * Creates a client for Storage buckets, files, analytics, and vectors.\n  *\n  * @category File Buckets\n  * @example\n  * ```ts\n  * import { StorageClient } from '@supabase/storage-js'\n  *\n  * const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\n  *   apikey: 'public-anon-key',\n  * })\n  * const avatars = storage.from('avatars')\n  * ```\n  */\n  constructor(url, headers = {}, fetch$1, opts) {\n    super(url, headers, fetch$1, opts);\n  }\n  /**\n  * Perform file operation in a bucket.\n  *\n  * @category File Buckets\n  * @param id The bucket id to operate on.\n  *\n  * @example\n  * ```typescript\n  * const avatars = supabase.storage.from('avatars')\n  * ```\n  */\n  from(id) {\n    return new StorageFileApi(this.url, this.headers, id, this.fetch);\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Access vector storage operations.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Vector Buckets\n  * @returns A StorageVectorsClient instance configured with the current storage settings.\n  */\n  get vectors() {\n    return new StorageVectorsClient(this.url + \"/vector\", {\n      headers: this.headers,\n      fetch: this.fetch\n    });\n  }\n  /**\n  *\n  * @alpha\n  *\n  * Access analytics storage operations using Iceberg tables.\n  *\n  * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n  *\n  * @category Analytics Buckets\n  * @returns A StorageAnalyticsClient instance configured with the current storage settings.\n  */\n  get analytics() {\n    return new StorageAnalyticsClient(this.url + \"/iceberg\", this.headers, this.fetch);\n  }\n};\n\n//#endregion\nexport { StorageAnalyticsClient, StorageApiError, StorageClient, StorageError, StorageUnknownError, StorageVectorsApiError, StorageVectorsClient, StorageVectorsError, StorageVectorsErrorCode, StorageVectorsUnknownError, VectorBucketApi, VectorBucketScope, VectorDataApi, VectorIndexApi, VectorIndexScope, isStorageError, isStorageVectorsError };","map":{"version":3,"names":["StorageError","Error","constructor","message","namespace","status","statusCode","__isStorageError","name","isStorageError","error","StorageApiError","toJSON","StorageUnknownError","originalError","StorageVectorsError","isStorageVectorsError","StorageVectorsApiError","StorageVectorsUnknownError","StorageVectorsErrorCode","StorageVectorsErrorCode$1","resolveFetch","customFetch","args","fetch","isPlainObject","value","prototype","Object","getPrototypeOf","Symbol","toStringTag","iterator","recursiveToCamel","item","Array","isArray","map","el","result","entries","forEach","key","newKey","replace","c","toUpperCase","isValidBucketName","bucketName","length","trim","includes","test","_getErrorMessage","err","msg","error_description","_err$error","JSON","stringify","handleError","reject","options","noResolveJson","responseError","json","then","code","catch","statusText","_getRequestParams","method","parameters","body","params","headers","_objectSpread2","duplex","_handleRequest","fetcher","url","Promise","resolve","ok","contentType","get","data","createFetchApi","post","put","head","remove","defaultApi","vectorsApi","BaseApiClient","fetch$1","shouldThrowOnError","throwOnError","handleOperation","operation","_this","StreamDownloadBuilder","downloadFn","onfulfilled","onrejected","execute","BlobDownloadBuilder","promise","asStream","getPromise","finally","onfinally","blob","DEFAULT_SEARCH_OPTIONS","limit","offset","sortBy","column","order","DEFAULT_FILE_OPTIONS","cacheControl","upsert","StorageFileApi","bucketId","uploadOrUpdate","path","fileBody","fileOptions","String","metadata","Blob","FormData","append","encodeMetadata","has","toBase64","ReadableStream","pipe","cleanPath","_removeEmptyFolders","_path","_getFinalPath","id","Id","fullPath","Key","upload","uploadToSignedUrl","token","_this3","URL","searchParams","set","toString","createSignedUploadUrl","_this4","signedUrl","update","move","fromPath","toPath","_this6","sourceKey","destinationKey","destinationBucket","copy","_this7","createSignedUrl","expiresIn","_this8","transform","downloadQueryParam","download","encodeURI","signedURL","createSignedUrls","paths","_this9","datum","renderPath","transformationQuery","transformOptsToQueryString","queryString","info","_this10","exists","_this11","getPublicUrl","_queryString","push","join","publicUrl","_this12","prefixes","list","_this13","prefix","listV2","_this14","Buffer","from","btoa","width","height","resize","format","quality","version","DEFAULT_HEADERS","StorageBucketApi","opts","baseUrl","useNewHostname","hostname","finalUrl","href","finalHeaders","listBuckets","listBucketOptionsToQueryString","getBucket","_this2","createBucket","public","type","file_size_limit","fileSizeLimit","allowed_mime_types","allowedMimeTypes","updateBucket","emptyBucket","_this5","deleteBucket","search","sortColumn","sortOrder","keys","URLSearchParams","StorageAnalyticsClient","queryParams","catalog","IcebergRestCatalog","catalogName","auth","getHeaders","Proxy","target","prop","apply","VectorIndexApi","createIndex","getIndex","vectorBucketName","indexName","listIndexes","deleteIndex","VectorDataApi","putVectors","vectors","getVectors","listVectors","segmentCount","segmentIndex","queryVectors","deleteVectors","VectorBucketApi","StorageVectorsClient","VectorBucketScope","_superprop_getCreateBucket","call","_superprop_getGetBucket","_superprop_getListBuckets","_superprop_getDeleteBucket","_superprop_getCreateIndex","_superprop_getListIndexes","_superprop_getGetIndex","_superprop_getDeleteIndex","index","VectorIndexScope","_superprop_getPutVectors","_superprop_getGetVectors","_superprop_getListVectors","_superprop_getQueryVectors","_superprop_getDeleteVectors","StorageClient","analytics"],"sources":["/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/lib/common/errors.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/lib/common/helpers.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/lib/common/fetch.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/lib/common/BaseApiClient.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/packages/StreamDownloadBuilder.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/packages/BlobDownloadBuilder.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/packages/StorageFileApi.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/lib/version.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/lib/constants.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/packages/StorageBucketApi.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/packages/StorageAnalyticsClient.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/packages/VectorIndexApi.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/packages/VectorDataApi.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/packages/VectorBucketApi.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/packages/StorageVectorsClient.ts","/Users/stefano.foffano/Desktop/photo-portfolio claude/node_modules/@supabase/storage-js/src/StorageClient.ts"],"sourcesContent":["/**\n * Namespace type for error classes\n * Determines the error class names and type guards\n */\nexport type ErrorNamespace = 'storage' | 'vectors'\n\n/**\n * Base error class for all Storage errors\n * Supports both 'storage' and 'vectors' namespaces\n */\nexport class StorageError extends Error {\n  protected __isStorageError = true\n  protected namespace: ErrorNamespace\n  status?: number\n  statusCode?: string\n\n  constructor(\n    message: string,\n    namespace: ErrorNamespace = 'storage',\n    status?: number,\n    statusCode?: string\n  ) {\n    super(message)\n    this.namespace = namespace\n    this.name = namespace === 'vectors' ? 'StorageVectorsError' : 'StorageError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n}\n\n/**\n * Type guard to check if an error is a StorageError\n * @param error - The error to check\n * @returns True if the error is a StorageError\n */\nexport function isStorageError(error: unknown): error is StorageError {\n  return typeof error === 'object' && error !== null && '__isStorageError' in error\n}\n\n/**\n * API error returned from Storage service\n * Includes HTTP status code and service-specific error code\n */\nexport class StorageApiError extends StorageError {\n  override status: number\n  override statusCode: string\n\n  constructor(\n    message: string,\n    status: number,\n    statusCode: string,\n    namespace: ErrorNamespace = 'storage'\n  ) {\n    super(message, namespace, status, statusCode)\n    this.name = namespace === 'vectors' ? 'StorageVectorsApiError' : 'StorageApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\n/**\n * Unknown error that doesn't match expected error patterns\n * Wraps the original error for debugging\n */\nexport class StorageUnknownError extends StorageError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown, namespace: ErrorNamespace = 'storage') {\n    super(message, namespace)\n    this.name = namespace === 'vectors' ? 'StorageVectorsUnknownError' : 'StorageUnknownError'\n    this.originalError = originalError\n  }\n}\n\n// ============================================================================\n// Backward Compatibility Exports for Vectors\n// ============================================================================\n\n/**\n * @deprecated Use StorageError with namespace='vectors' instead\n * Alias for backward compatibility with existing vector storage code\n */\nexport class StorageVectorsError extends StorageError {\n  constructor(message: string) {\n    super(message, 'vectors')\n  }\n}\n\n/**\n * Type guard to check if an error is a StorageVectorsError\n * @param error - The error to check\n * @returns True if the error is a StorageVectorsError\n */\nexport function isStorageVectorsError(error: unknown): error is StorageVectorsError {\n  return isStorageError(error) && (error as StorageError)['namespace'] === 'vectors'\n}\n\n/**\n * @deprecated Use StorageApiError with namespace='vectors' instead\n * Alias for backward compatibility with existing vector storage code\n */\nexport class StorageVectorsApiError extends StorageApiError {\n  constructor(message: string, status: number, statusCode: string) {\n    super(message, status, statusCode, 'vectors')\n  }\n}\n\n/**\n * @deprecated Use StorageUnknownError with namespace='vectors' instead\n * Alias for backward compatibility with existing vector storage code\n */\nexport class StorageVectorsUnknownError extends StorageUnknownError {\n  constructor(message: string, originalError: unknown) {\n    super(message, originalError, 'vectors')\n  }\n}\n\n/**\n * Error codes specific to S3 Vectors API\n * Maps AWS service errors to application-friendly error codes\n */\nexport enum StorageVectorsErrorCode {\n  /** Internal server fault (HTTP 500) */\n  InternalError = 'InternalError',\n  /** Resource already exists / conflict (HTTP 409) */\n  S3VectorConflictException = 'S3VectorConflictException',\n  /** Resource not found (HTTP 404) */\n  S3VectorNotFoundException = 'S3VectorNotFoundException',\n  /** Delete bucket while not empty (HTTP 400) */\n  S3VectorBucketNotEmpty = 'S3VectorBucketNotEmpty',\n  /** Exceeds bucket quota/limit (HTTP 400) */\n  S3VectorMaxBucketsExceeded = 'S3VectorMaxBucketsExceeded',\n  /** Exceeds index quota/limit (HTTP 400) */\n  S3VectorMaxIndexesExceeded = 'S3VectorMaxIndexesExceeded',\n}\n","type Fetch = typeof fetch\n\n/**\n * Resolves the fetch implementation to use\n * Uses custom fetch if provided, otherwise uses native fetch\n *\n * @param customFetch - Optional custom fetch implementation\n * @returns Resolved fetch function\n */\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n\n/**\n * Resolves the Response constructor to use\n * Returns native Response constructor\n *\n * @returns Response constructor\n */\nexport const resolveResponse = (): typeof Response => {\n  return Response\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n *\n * @param value - Value to check\n * @returns True if value is a plain object\n * @source https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n\n/**\n * Recursively converts object keys from snake_case to camelCase\n * Used for normalizing API responses\n *\n * @param item - Object to convert\n * @returns Converted object with camelCase keys\n */\nexport const recursiveToCamel = (item: Record<string, any>): unknown => {\n  if (Array.isArray(item)) {\n    return item.map((el) => recursiveToCamel(el))\n  } else if (typeof item === 'function' || item !== Object(item)) {\n    return item\n  }\n\n  const result: Record<string, any> = {}\n  Object.entries(item).forEach(([key, value]) => {\n    const newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, ''))\n    result[newKey] = recursiveToCamel(value)\n  })\n\n  return result\n}\n\n/**\n * Validates if a given bucket name is valid according to Supabase Storage API rules\n * Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\n *\n * Rules:\n * - Length: 1-100 characters\n * - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\n * - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\n * - Forbidden: path separators (/, \\), path traversal (..), leading/trailing whitespace\n *\n * AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n *\n * @param bucketName - The bucket name to validate\n * @returns true if valid, false otherwise\n */\nexport const isValidBucketName = (bucketName: string): boolean => {\n  if (!bucketName || typeof bucketName !== 'string') {\n    return false\n  }\n\n  // Check length constraints (1-100 characters)\n  if (bucketName.length === 0 || bucketName.length > 100) {\n    return false\n  }\n\n  // Check for leading/trailing whitespace\n  if (bucketName.trim() !== bucketName) {\n    return false\n  }\n\n  // Explicitly reject path separators (security)\n  // Note: Consecutive periods (..) are allowed by backend - the AWS restriction\n  // on relative paths applies to object keys, not bucket names\n  if (bucketName.includes('/') || bucketName.includes('\\\\')) {\n    return false\n  }\n\n  // Validate against allowed character set\n  // Pattern matches backend regex: /^(\\w|!|-|\\.|\\*|'|\\(|\\)| |&|\\$|@|=|;|:|\\+|,|\\?)*$/\n  // This explicitly excludes path separators (/, \\) and other problematic characters\n  const bucketNameRegex = /^[\\w!.\\*'() &$@=;:+,?-]+$/\n  return bucketNameRegex.test(bucketName)\n}\n\n/**\n * Normalizes a number array to float32 format\n * Ensures all vector values are valid 32-bit floats\n *\n * @param values - Array of numbers to normalize\n * @returns Normalized float32 array\n */\nexport const normalizeToFloat32 = (values: number[]): number[] => {\n  // Use Float32Array to ensure proper precision\n  return Array.from(new Float32Array(values))\n}\n\n/**\n * Validates vector dimensions match expected dimension\n * Throws error if dimensions don't match\n *\n * @param vector - Vector data to validate\n * @param expectedDimension - Expected vector dimension\n * @throws Error if dimensions don't match\n */\nexport const validateVectorDimension = (\n  vector: { float32: number[] },\n  expectedDimension?: number\n): void => {\n  if (expectedDimension !== undefined && vector.float32.length !== expectedDimension) {\n    throw new Error(\n      `Vector dimension mismatch: expected ${expectedDimension}, got ${vector.float32.length}`\n    )\n  }\n}\n","import { StorageApiError, StorageUnknownError, ErrorNamespace } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { FetchParameters } from '../types'\n\nexport type Fetch = typeof fetch\n\n/**\n * Options for fetch requests\n */\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  duplex?: string\n  noResolveJson?: boolean\n}\n\n/**\n * HTTP methods supported by the API\n */\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE' | 'HEAD'\n\n/**\n * Extracts error message from various error response formats\n * @param err - Error object from API\n * @returns Human-readable error message\n */\nconst _getErrorMessage = (err: any): string =>\n  err.msg ||\n  err.message ||\n  err.error_description ||\n  (typeof err.error === 'string' ? err.error : err.error?.message) ||\n  JSON.stringify(err)\n\n/**\n * Handles fetch errors and converts them to Storage error types\n * @param error - The error caught from fetch\n * @param reject - Promise rejection function\n * @param options - Fetch options that may affect error handling\n * @param namespace - Error namespace ('storage' or 'vectors')\n */\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options: FetchOptions | undefined,\n  namespace: ErrorNamespace\n) => {\n  // Check if error is a Response-like object (has status and ok properties)\n  // This is more reliable than instanceof which can fail across realms\n  const isResponseLike =\n    error &&\n    typeof error === 'object' &&\n    'status' in error &&\n    'ok' in error &&\n    typeof (error as any).status === 'number'\n\n  if (isResponseLike && !options?.noResolveJson) {\n    const responseError = error as any\n    const status = responseError.status || 500\n\n    // Try to parse JSON body if available\n    if (typeof responseError.json === 'function') {\n      responseError\n        .json()\n        .then((err: any) => {\n          const statusCode = err?.statusCode || err?.code || status + ''\n          reject(new StorageApiError(_getErrorMessage(err), status, statusCode, namespace))\n        })\n        .catch(() => {\n          // If JSON parsing fails for vectors, create ApiError with HTTP status\n          if (namespace === 'vectors') {\n            const statusCode = status + ''\n            const message = responseError.statusText || `HTTP ${status} error`\n            reject(new StorageApiError(message, status, statusCode, namespace))\n          } else {\n            const statusCode = status + ''\n            const message = responseError.statusText || `HTTP ${status} error`\n            reject(new StorageApiError(message, status, statusCode, namespace))\n          }\n        })\n    } else {\n      // No json() method available, create error from status\n      const statusCode = status + ''\n      const message = responseError.statusText || `HTTP ${status} error`\n      reject(new StorageApiError(message, status, statusCode, namespace))\n    }\n  } else {\n    reject(new StorageUnknownError(_getErrorMessage(error), error, namespace))\n  }\n}\n\n/**\n * Builds request parameters for fetch calls\n * @param method - HTTP method\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters like AbortSignal\n * @param body - Request body (will be JSON stringified if plain object)\n * @returns Complete fetch request parameters\n */\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || method === 'HEAD' || !body) {\n    return { ...params, ...parameters }\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  if (options?.duplex) {\n    params.duplex = options.duplex\n  }\n\n  return { ...params, ...parameters }\n}\n\n/**\n * Internal request handler that wraps fetch with error handling\n * @param fetcher - Fetch function to use\n * @param method - HTTP method\n * @param url - Request URL\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @param body - Request body\n * @param namespace - Error namespace ('storage' or 'vectors')\n * @returns Promise with parsed response or error\n */\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options: FetchOptions | undefined,\n  parameters: FetchParameters | undefined,\n  body: object | undefined,\n  namespace: ErrorNamespace\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n\n        // AWS S3 Vectors API returns 200 OK with content-length: 0 for successful mutations\n        // (putVectors, deleteVectors) instead of 204 or JSON response. This is AWS's design choice\n        // for performance optimization of bulk operations (up to 500 vectors per request).\n        // We handle this to prevent \"Unexpected end of JSON input\" errors when calling result.json()\n        if (namespace === 'vectors') {\n          const contentType = result.headers.get('content-type')\n          const contentLength = result.headers.get('content-length')\n\n          // Return empty object for explicitly empty responses\n          if (contentLength === '0' || result.status === 204) {\n            return {}\n          }\n\n          // Return empty object if no JSON content type\n          if (!contentType || !contentType.includes('application/json')) {\n            return {}\n          }\n        }\n\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options, namespace))\n  })\n}\n\n/**\n * Creates a fetch API with the specified namespace\n * @param namespace - Error namespace ('storage' or 'vectors')\n * @returns Object with HTTP method functions\n */\nexport function createFetchApi(namespace: ErrorNamespace = 'storage') {\n  return {\n    /**\n     * Performs a GET request\n     * @param fetcher - Fetch function to use\n     * @param url - Request URL\n     * @param options - Custom fetch options\n     * @param parameters - Additional fetch parameters\n     * @returns Promise with parsed response\n     */\n    get: async (\n      fetcher: Fetch,\n      url: string,\n      options?: FetchOptions,\n      parameters?: FetchParameters\n    ): Promise<any> => {\n      return _handleRequest(fetcher, 'GET', url, options, parameters, undefined, namespace)\n    },\n\n    /**\n     * Performs a POST request\n     * @param fetcher - Fetch function to use\n     * @param url - Request URL\n     * @param body - Request body to be JSON stringified\n     * @param options - Custom fetch options\n     * @param parameters - Additional fetch parameters\n     * @returns Promise with parsed response\n     */\n    post: async (\n      fetcher: Fetch,\n      url: string,\n      body: object,\n      options?: FetchOptions,\n      parameters?: FetchParameters\n    ): Promise<any> => {\n      return _handleRequest(fetcher, 'POST', url, options, parameters, body, namespace)\n    },\n\n    /**\n     * Performs a PUT request\n     * @param fetcher - Fetch function to use\n     * @param url - Request URL\n     * @param body - Request body to be JSON stringified\n     * @param options - Custom fetch options\n     * @param parameters - Additional fetch parameters\n     * @returns Promise with parsed response\n     */\n    put: async (\n      fetcher: Fetch,\n      url: string,\n      body: object,\n      options?: FetchOptions,\n      parameters?: FetchParameters\n    ): Promise<any> => {\n      return _handleRequest(fetcher, 'PUT', url, options, parameters, body, namespace)\n    },\n\n    /**\n     * Performs a HEAD request\n     * @param fetcher - Fetch function to use\n     * @param url - Request URL\n     * @param options - Custom fetch options\n     * @param parameters - Additional fetch parameters\n     * @returns Promise with Response object (not JSON parsed)\n     */\n    head: async (\n      fetcher: Fetch,\n      url: string,\n      options?: FetchOptions,\n      parameters?: FetchParameters\n    ): Promise<any> => {\n      return _handleRequest(\n        fetcher,\n        'HEAD',\n        url,\n        {\n          ...options,\n          noResolveJson: true,\n        },\n        parameters,\n        undefined,\n        namespace\n      )\n    },\n\n    /**\n     * Performs a DELETE request\n     * @param fetcher - Fetch function to use\n     * @param url - Request URL\n     * @param body - Request body to be JSON stringified\n     * @param options - Custom fetch options\n     * @param parameters - Additional fetch parameters\n     * @returns Promise with parsed response\n     */\n    remove: async (\n      fetcher: Fetch,\n      url: string,\n      body: object,\n      options?: FetchOptions,\n      parameters?: FetchParameters\n    ): Promise<any> => {\n      return _handleRequest(fetcher, 'DELETE', url, options, parameters, body, namespace)\n    },\n  }\n}\n\n// Default exports for backward compatibility with 'storage' namespace\nconst defaultApi = createFetchApi('storage')\nexport const { get, post, put, head, remove } = defaultApi\n\n// Vectors API with 'vectors' namespace for proper error handling\nexport const vectorsApi = createFetchApi('vectors')\n","import { ErrorNamespace, isStorageError, StorageError } from './errors'\nimport { Fetch } from './fetch'\nimport { resolveFetch } from './helpers'\n\n/**\n * @ignore\n * Base API client class for all Storage API classes\n * Provides common infrastructure for error handling and configuration\n *\n * @typeParam TError - The error type (StorageError or subclass)\n */\nexport default abstract class BaseApiClient<TError extends StorageError = StorageError> {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n  protected namespace: ErrorNamespace\n\n  /**\n   * Creates a new BaseApiClient instance\n   * @param url - Base URL for API requests\n   * @param headers - Default headers for API requests\n   * @param fetch - Optional custom fetch implementation\n   * @param namespace - Error namespace ('storage' or 'vectors')\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    namespace: ErrorNamespace = 'storage'\n  ) {\n    this.url = url\n    this.headers = headers\n    this.fetch = resolveFetch(fetch)\n    this.namespace = namespace\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   * When enabled, errors are thrown instead of returned in { data, error } format.\n   *\n   * @returns this - For method chaining\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Handles API operation with standardized error handling\n   * Eliminates repetitive try-catch blocks across all API methods\n   *\n   * This wrapper:\n   * 1. Executes the operation\n   * 2. Returns { data, error: null } on success\n   * 3. Returns { data: null, error } on failure (if shouldThrowOnError is false)\n   * 4. Throws error on failure (if shouldThrowOnError is true)\n   *\n   * @typeParam T - The expected data type from the operation\n   * @param operation - Async function that performs the API call\n   * @returns Promise with { data, error } tuple\n   *\n   * @example\n   * ```typescript\n   * async listBuckets() {\n   *   return this.handleOperation(async () => {\n   *     return await get(this.fetch, `${this.url}/bucket`, {\n   *       headers: this.headers,\n   *     })\n   *   })\n   * }\n   * ```\n   */\n  protected async handleOperation<T>(\n    operation: () => Promise<T>\n  ): Promise<{ data: T; error: null } | { data: null; error: TError }> {\n    try {\n      const data = await operation()\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error: error as TError }\n      }\n      throw error\n    }\n  }\n}\n","import { isStorageError } from '../lib/common/errors'\nimport { DownloadResult } from '../lib/types'\n\nexport default class StreamDownloadBuilder implements PromiseLike<DownloadResult<ReadableStream>> {\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  then<TResult1 = DownloadResult<ReadableStream>, TResult2 = never>(\n    onfulfilled?:\n      | ((value: DownloadResult<ReadableStream>) => TResult1 | PromiseLike<TResult1>)\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.execute().then(onfulfilled, onrejected)\n  }\n\n  private async execute(): Promise<DownloadResult<ReadableStream>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: result.body as ReadableStream,\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import { isStorageError } from '../lib/common/errors'\nimport { DownloadResult } from '../lib/types'\nimport StreamDownloadBuilder from './StreamDownloadBuilder'\n\nexport default class BlobDownloadBuilder implements Promise<DownloadResult<Blob>> {\n  readonly [Symbol.toStringTag]: string = 'BlobDownloadBuilder'\n  private promise: Promise<DownloadResult<Blob>> | null = null\n\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  asStream(): StreamDownloadBuilder {\n    return new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError)\n  }\n\n  then<TResult1 = DownloadResult<Blob>, TResult2 = never>(\n    onfulfilled?: ((value: DownloadResult<Blob>) => TResult1 | PromiseLike<TResult1>) | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.getPromise().then(onfulfilled, onrejected)\n  }\n\n  catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | null\n  ): Promise<DownloadResult<Blob> | TResult> {\n    return this.getPromise().catch(onrejected)\n  }\n\n  finally(onfinally?: (() => void) | null): Promise<DownloadResult<Blob>> {\n    return this.getPromise().finally(onfinally)\n  }\n\n  private getPromise(): Promise<DownloadResult<Blob>> {\n    if (!this.promise) {\n      this.promise = this.execute()\n    }\n    return this.promise\n  }\n\n  private async execute(): Promise<DownloadResult<Blob>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: await result.blob(),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import { StorageError, StorageUnknownError, isStorageError } from '../lib/common/errors'\nimport { get, head, post, put, remove, Fetch } from '../lib/common/fetch'\nimport { recursiveToCamel } from '../lib/common/helpers'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport {\n  FileObject,\n  FileOptions,\n  SearchOptions,\n  FetchParameters,\n  TransformOptions,\n  DestinationOptions,\n  FileObjectV2,\n  Camelize,\n  SearchV2Options,\n  SearchV2Result,\n} from '../lib/types'\nimport BlobDownloadBuilder from './BlobDownloadBuilder'\n\nconst DEFAULT_SEARCH_OPTIONS = {\n  limit: 100,\n  offset: 0,\n  sortBy: {\n    column: 'name',\n    order: 'asc',\n  },\n}\n\nconst DEFAULT_FILE_OPTIONS: FileOptions = {\n  cacheControl: '3600',\n  contentType: 'text/plain;charset=UTF-8',\n  upsert: false,\n}\n\ntype FileBody =\n  | ArrayBuffer\n  | ArrayBufferView\n  | Blob\n  | Buffer\n  | File\n  | FormData\n  | NodeJS.ReadableStream\n  | ReadableStream<Uint8Array>\n  | URLSearchParams\n  | string\n\nexport default class StorageFileApi extends BaseApiClient<StorageError> {\n  protected bucketId?: string\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    bucketId?: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch, 'storage')\n    this.bucketId = bucketId\n  }\n\n  /**\n   * Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n   *\n   * @param method HTTP method.\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   */\n  private async uploadOrUpdate(\n    method: 'POST' | 'PUT',\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      let body\n      const options = { ...DEFAULT_FILE_OPTIONS, ...fileOptions }\n      let headers: Record<string, string> = {\n        ...this.headers,\n        ...(method === 'POST' && { 'x-upsert': String(options.upsert as boolean) }),\n      }\n\n      const metadata = options.metadata\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        if (metadata) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        // Only append if not already present\n        if (!body.has('cacheControl')) {\n          body.append('cacheControl', options.cacheControl as string)\n        }\n        if (metadata && !body.has('metadata')) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n\n        if (metadata) {\n          headers['x-metadata'] = this.toBase64(this.encodeMetadata(metadata))\n        }\n\n        // Node.js streams require duplex option for fetch in Node 20+\n        // Check for both web ReadableStream and Node.js streams\n        const isStream =\n          (typeof ReadableStream !== 'undefined' && body instanceof ReadableStream) ||\n          (body && typeof body === 'object' && 'pipe' in body && typeof body.pipe === 'function')\n\n        if (isStream && !options.duplex) {\n          options.duplex = 'half'\n        }\n      }\n\n      if (fileOptions?.headers) {\n        headers = { ...headers, ...fileOptions.headers }\n      }\n\n      const cleanPath = this._removeEmptyFolders(path)\n      const _path = this._getFinalPath(cleanPath)\n      const data = await (method == 'PUT' ? put : post)(\n        this.fetch,\n        `${this.url}/object/${_path}`,\n        body as object,\n        { headers, ...(options?.duplex ? { duplex: options.duplex } : {}) }\n      )\n\n      return { path: cleanPath, id: data.Id, fullPath: data.Key }\n    })\n  }\n\n  /**\n   * Uploads a file to an existing bucket.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Upload file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: false\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Upload file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import { decode } from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async upload(\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('POST', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Upload a file with a token generated from `createSignedUploadUrl`.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param token The token generated from `createSignedUploadUrl`\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions HTTP headers (cacheControl, contentType, etc.).\n   * **Note:** The `upsert` option has no effect here. To enable upsert behavior,\n   * pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\n   * @returns Promise with response containing file path and fullPath or error\n   *\n   * @example Upload to a signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"fullPath\": \"avatars/folder/cat.jpg\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async uploadToSignedUrl(\n    path: string,\n    token: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ) {\n    const cleanPath = this._removeEmptyFolders(path)\n    const _path = this._getFinalPath(cleanPath)\n\n    const url = new URL(this.url + `/object/upload/sign/${_path}`)\n    url.searchParams.set('token', token)\n\n    return this.handleOperation(async () => {\n      let body\n      const options = { upsert: DEFAULT_FILE_OPTIONS.upsert, ...fileOptions }\n      const headers: Record<string, string> = {\n        ...this.headers,\n        ...{ 'x-upsert': String(options.upsert as boolean) },\n      }\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        body.append('cacheControl', options.cacheControl as string)\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n      }\n\n      const data = await put(this.fetch, url.toString(), body as object, { headers })\n\n      return { path: cleanPath, fullPath: data.Key }\n    })\n  }\n\n  /**\n   * Creates a signed upload URL.\n   * Signed upload URLs can be used to upload files to the bucket without further authentication.\n   * They are valid for 2 hours.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n   * @returns Promise with response containing signed upload URL, token, and path or error\n   *\n   * @example Create Signed Upload URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUploadUrl('folder/cat.jpg')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\",\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"token\": \"<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUploadUrl(\n    path: string,\n    options?: { upsert: boolean }\n  ): Promise<\n    | {\n        data: { signedUrl: string; token: string; path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      let _path = this._getFinalPath(path)\n\n      const headers = { ...this.headers }\n\n      if (options?.upsert) {\n        headers['x-upsert'] = 'true'\n      }\n\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/upload/sign/${_path}`,\n        {},\n        { headers }\n      )\n\n      const url = new URL(this.url + data.url)\n\n      const token = url.searchParams.get('token')\n\n      if (!token) {\n        throw new StorageError('No token returned by API')\n      }\n\n      return { signedUrl: url.toString(), path, token }\n    })\n  }\n\n  /**\n   * Replaces an existing file at the specified path with a new one.\n   *\n   * @category File Buckets\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Update file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: true\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Update file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import {decode} from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async update(\n    path: string,\n    fileBody:\n      | ArrayBuffer\n      | ArrayBufferView\n      | Blob\n      | Buffer\n      | File\n      | FormData\n      | NodeJS.ReadableStream\n      | ReadableStream<Uint8Array>\n      | URLSearchParams\n      | string,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('PUT', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Moves an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Move file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .move('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully moved\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async move(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await post(\n        this.fetch,\n        `${this.url}/object/move`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /**\n   * Copies an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing copied file path or error\n   *\n   * @example Copy file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .copy('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"avatars/private/avatar2.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async copy(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/copy`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { path: data.Key }\n    })\n  }\n\n  /**\n   * Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Promise with response containing signed URL or error\n   *\n   * @example Create Signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Create a signed URL for an asset with transformations\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Create a signed URL which triggers the download of the asset\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     download: true,\n   *   })\n   * ```\n   */\n  async createSignedUrl(\n    path: string,\n    expiresIn: number,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): Promise<\n    | {\n        data: { signedUrl: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      let _path = this._getFinalPath(path)\n\n      let data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${_path}`,\n        { expiresIn, ...(options?.transform ? { transform: options.transform } : {}) },\n        { headers: this.headers }\n      )\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      const signedUrl = encodeURI(`${this.url}${data.signedURL}${downloadQueryParam}`)\n      return { signedUrl }\n    })\n  }\n\n  /**\n   * Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n   * @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @returns Promise with response containing array of objects with signedUrl, path, and error or error\n   *\n   * @example Create Signed URLs\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar1.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *     },\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar2.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUrls(\n    paths: string[],\n    expiresIn: number,\n    options?: { download: string | boolean }\n  ): Promise<\n    | {\n        data: { error: string | null; path: string | null; signedUrl: string }[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${this.bucketId}`,\n        { expiresIn, paths },\n        { headers: this.headers }\n      )\n\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      return data.map((datum: { signedURL: string }) => ({\n        ...datum,\n        signedUrl: datum.signedURL\n          ? encodeURI(`${this.url}${datum.signedURL}${downloadQueryParam}`)\n          : null,\n      }))\n    })\n  }\n\n  /**\n   * Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n   *\n   * @category File Buckets\n   * @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @param parameters Additional fetch parameters like signal for cancellation. Supports standard fetch options including cache control.\n   * @returns BlobDownloadBuilder instance for downloading the file\n   *\n   * @example Download file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": <BLOB>,\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Download file with transformations\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *       quality: 80\n   *     }\n   *   })\n   * ```\n   *\n   * @example Download with cache control (useful in Edge Functions)\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png', {}, { cache: 'no-store' })\n   * ```\n   *\n   * @example Download with abort signal\n   * ```js\n   * const controller = new AbortController()\n   * setTimeout(() => controller.abort(), 5000)\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png', {}, { signal: controller.signal })\n   * ```\n   */\n  download<Options extends { transform?: TransformOptions }>(\n    path: string,\n    options?: Options,\n    parameters?: FetchParameters\n  ): BlobDownloadBuilder {\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image/authenticated' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n    const queryString = transformationQuery ? `?${transformationQuery}` : ''\n    const _path = this._getFinalPath(path)\n    const downloadFn = () =>\n      get(\n        this.fetch,\n        `${this.url}/${renderPath}/${_path}${queryString}`,\n        {\n          headers: this.headers,\n          noResolveJson: true,\n        },\n        parameters\n      )\n    return new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError)\n  }\n\n  /**\n   * Retrieves the details of an existing file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing file metadata or error\n   *\n   * @example Get file info\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .info('folder/avatar1.png')\n   * ```\n   */\n  async info(path: string): Promise<\n    | {\n        data: Camelize<FileObjectV2>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    return this.handleOperation(async () => {\n      const data = await get(this.fetch, `${this.url}/object/info/${_path}`, {\n        headers: this.headers,\n      })\n\n      return recursiveToCamel(data) as Camelize<FileObjectV2>\n    })\n  }\n\n  /**\n   * Checks the existence of a file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing boolean indicating file existence or error\n   *\n   * @example Check file existence\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .exists('folder/avatar1.png')\n   * ```\n   */\n  async exists(path: string): Promise<\n    | {\n        data: boolean\n        error: null\n      }\n    | {\n        data: boolean\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      await head(this.fetch, `${this.url}/object/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: true, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error) && error instanceof StorageUnknownError) {\n        const originalError = error.originalError as unknown as { status: number }\n\n        if ([400, 404].includes(originalError?.status)) {\n          return { data: false, error }\n        }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n   * This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n   *\n   * @category File Buckets\n   * @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n   * @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Object with public URL\n   *\n   * @example Returns the URL for an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"publicUrl\": \"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\"\n   *   }\n   * }\n   * ```\n   *\n   * @example Returns the URL for an asset in a public bucket with transformations\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Returns the URL which triggers the download of an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     download: true,\n   *   })\n   * ```\n   */\n  getPublicUrl(\n    path: string,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): { data: { publicUrl: string } } {\n    const _path = this._getFinalPath(path)\n    const _queryString: string[] = []\n\n    const downloadQueryParam = options?.download\n      ? `download=${options.download === true ? '' : options.download}`\n      : ''\n\n    if (downloadQueryParam !== '') {\n      _queryString.push(downloadQueryParam)\n    }\n\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n\n    if (transformationQuery !== '') {\n      _queryString.push(transformationQuery)\n    }\n\n    let queryString = _queryString.join('&')\n    if (queryString !== '') {\n      queryString = `?${queryString}`\n    }\n\n    return {\n      data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) },\n    }\n  }\n\n  /**\n   * Deletes files within the same bucket\n   *\n   * @category File Buckets\n   * @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n   * @returns Promise with response containing array of deleted file objects or error\n   *\n   * @example Delete file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .remove(['folder/avatar1.png'])\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async remove(paths: string[]): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await remove(\n        this.fetch,\n        `${this.url}/object/${this.bucketId}`,\n        { prefixes: paths },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /**\n   * Get file metadata\n   * @param id the file id to retrieve metadata\n   */\n  // async getMetadata(\n  //   id: string\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await get(this.fetch, `${this.url}/metadata/${id}`, { headers: this.headers })\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Update file metadata\n   * @param id the file id to update metadata\n   * @param meta the new file metadata\n   */\n  // async updateMetadata(\n  //   id: string,\n  //   meta: Metadata\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await post(\n  //       this.fetch,\n  //       `${this.url}/metadata/${id}`,\n  //       { ...meta },\n  //       { headers: this.headers }\n  //     )\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Lists all the files and folders within a path of the bucket.\n   *\n   * @category File Buckets\n   * @param path The folder path.\n   * @param options Search options including limit (defaults to 100), offset, sortBy, and search\n   * @param parameters Optional fetch parameters including signal for cancellation\n   * @returns Promise with response containing array of files or error\n   *\n   * @example List files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"avatar1.png\",\n   *       \"id\": \"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\",\n   *       \"updated_at\": \"2024-05-22T23:06:05.580Z\",\n   *       \"created_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"last_accessed_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"metadata\": {\n   *         \"eTag\": \"\\\"c5e8c553235d9af30ef4f6e280790b92\\\"\",\n   *         \"size\": 32175,\n   *         \"mimetype\": \"image/png\",\n   *         \"cacheControl\": \"max-age=3600\",\n   *         \"lastModified\": \"2024-05-22T23:06:05.574Z\",\n   *         \"contentLength\": 32175,\n   *         \"httpStatusCode\": 200\n   *       }\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Search files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *     search: 'jon'\n   *   })\n   * ```\n   */\n  async list(\n    path?: string,\n    options?: SearchOptions,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      const body = { ...DEFAULT_SEARCH_OPTIONS, ...options, prefix: path || '' }\n      return await post(\n        this.fetch,\n        `${this.url}/object/list/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n    })\n  }\n\n  /**\n   * @experimental this method signature might change in the future\n   *\n   * @category File Buckets\n   * @param options search options\n   * @param parameters\n   */\n  async listV2(\n    options?: SearchV2Options,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: SearchV2Result\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      const body = { ...options }\n      return await post(\n        this.fetch,\n        `${this.url}/object/list-v2/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n    })\n  }\n\n  protected encodeMetadata(metadata: Record<string, any>) {\n    return JSON.stringify(metadata)\n  }\n\n  toBase64(data: string) {\n    if (typeof Buffer !== 'undefined') {\n      return Buffer.from(data).toString('base64')\n    }\n    return btoa(data)\n  }\n\n  private _getFinalPath(path: string) {\n    return `${this.bucketId}/${path.replace(/^\\/+/, '')}`\n  }\n\n  private _removeEmptyFolders(path: string) {\n    return path.replace(/^\\/|\\/$/g, '').replace(/\\/+/g, '/')\n  }\n\n  private transformOptsToQueryString(transform: TransformOptions) {\n    const params: string[] = []\n    if (transform.width) {\n      params.push(`width=${transform.width}`)\n    }\n\n    if (transform.height) {\n      params.push(`height=${transform.height}`)\n    }\n\n    if (transform.resize) {\n      params.push(`resize=${transform.resize}`)\n    }\n\n    if (transform.format) {\n      params.push(`format=${transform.format}`)\n    }\n\n    if (transform.quality) {\n      params.push(`quality=${transform.quality}`)\n    }\n\n    return params.join('&')\n  }\n}\n","// Generated automatically during releases by scripts/update-version-files.ts\n// This file provides runtime access to the package version for:\n// - HTTP request headers (e.g., X-Client-Info header for API requests)\n// - Debugging and support (identifying which version is running)\n// - Telemetry and logging (version reporting in errors/analytics)\n// - Ensuring build artifacts match the published package version\nexport const version = '2.95.3'\n","import { version } from './version'\nexport const DEFAULT_HEADERS = {\n  'X-Client-Info': `storage-js/${version}`,\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { StorageError } from '../lib/common/errors'\nimport { Fetch, get, post, put, remove } from '../lib/common/fetch'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport { Bucket, BucketType, ListBucketOptions } from '../lib/types'\nimport { StorageClientOptions } from '../StorageClient'\n\nexport default class StorageBucketApi extends BaseApiClient<StorageError> {\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    const baseUrl = new URL(url)\n\n    // if legacy uri is used, replace with new storage host (disables request buffering to allow > 50GB uploads)\n    // \"project-ref.supabase.co\" becomes \"project-ref.storage.supabase.co\"\n    if (opts?.useNewHostname) {\n      const isSupabaseHost = /supabase\\.(co|in|red)$/.test(baseUrl.hostname)\n      if (isSupabaseHost && !baseUrl.hostname.includes('storage.supabase.')) {\n        baseUrl.hostname = baseUrl.hostname.replace('supabase.', 'storage.supabase.')\n      }\n    }\n\n    const finalUrl = baseUrl.href.replace(/\\/$/, '')\n    const finalHeaders = { ...DEFAULT_HEADERS, ...headers }\n\n    super(finalUrl, finalHeaders, fetch, 'storage')\n  }\n\n  /**\n   * Retrieves the details of all Storage buckets within an existing project.\n   *\n   * @category File Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of buckets or error\n   *\n   * @example List buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets()\n   * ```\n   *\n   * @example List buckets with options\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc',\n   *     search: 'prod'\n   *   })\n   * ```\n   */\n  async listBuckets(options?: ListBucketOptions): Promise<\n    | {\n        data: Bucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      const queryString = this.listBucketOptionsToQueryString(options)\n      return await get(this.fetch, `${this.url}/bucket${queryString}`, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /**\n   * Retrieves the details of an existing Storage bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to retrieve.\n   * @returns Promise with response containing bucket details or error\n   *\n   * @example Get bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .getBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"id\": \"avatars\",\n   *     \"name\": \"avatars\",\n   *     \"owner\": \"\",\n   *     \"public\": false,\n   *     \"file_size_limit\": 1024,\n   *     \"allowed_mime_types\": [\n   *       \"image/png\"\n   *     ],\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async getBucket(id: string): Promise<\n    | {\n        data: Bucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await get(this.fetch, `${this.url}/bucket/${id}`, { headers: this.headers })\n    })\n  }\n\n  /**\n   * Creates a new Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are creating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n   *   - default bucket type is `STANDARD`\n   * @returns Promise with response containing newly created bucket name or error\n   *\n   * @example Create bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .createBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"avatars\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n      type?: BucketType\n    } = {\n      public: false,\n    }\n  ): Promise<\n    | {\n        data: Pick<Bucket, 'name'>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await post(\n        this.fetch,\n        `${this.url}/bucket`,\n        {\n          id,\n          name: id,\n          type: options.type,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /**\n   * Updates a Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are updating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Update bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .updateBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully updated\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async updateBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n    }\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await put(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {\n          id,\n          name: id,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /**\n   * Removes all objects inside a single bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to empty.\n   * @returns Promise with success message or error\n   *\n   * @example Empty bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .emptyBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully emptied\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async emptyBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await post(this.fetch, `${this.url}/bucket/${id}/empty`, {}, { headers: this.headers })\n    })\n  }\n\n  /**\n   * Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n   * You must first `empty()` the bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to delete.\n   * @returns Promise with success message or error\n   *\n   * @example Delete bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .deleteBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await remove(this.fetch, `${this.url}/bucket/${id}`, {}, { headers: this.headers })\n    })\n  }\n\n  private listBucketOptionsToQueryString(options?: ListBucketOptions): string {\n    const params: Record<string, string> = {}\n    if (options) {\n      if ('limit' in options) {\n        params.limit = String(options.limit)\n      }\n      if ('offset' in options) {\n        params.offset = String(options.offset)\n      }\n      if (options.search) {\n        params.search = options.search\n      }\n      if (options.sortColumn) {\n        params.sortColumn = options.sortColumn\n      }\n      if (options.sortOrder) {\n        params.sortOrder = options.sortOrder\n      }\n    }\n    return Object.keys(params).length > 0 ? '?' + new URLSearchParams(params).toString() : ''\n  }\n}\n","import { IcebergRestCatalog, IcebergError } from 'iceberg-js'\nimport { DEFAULT_HEADERS } from '../lib/constants'\nimport { StorageError } from '../lib/common/errors'\nimport { Fetch, get, post, remove } from '../lib/common/fetch'\nimport { isValidBucketName } from '../lib/common/helpers'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport { AnalyticBucket } from '../lib/types'\n\ntype WrapAsyncMethod<T> = T extends (...args: infer A) => Promise<infer R>\n  ? (...args: A) => Promise<{ data: R; error: null } | { data: null; error: IcebergError }>\n  : T\n\nexport type WrappedIcebergRestCatalog = {\n  [K in keyof IcebergRestCatalog]: WrapAsyncMethod<IcebergRestCatalog[K]>\n}\n\n/**\n * Client class for managing Analytics Buckets using Iceberg tables\n * Provides methods for creating, listing, and deleting analytics buckets\n */\nexport default class StorageAnalyticsClient extends BaseApiClient<StorageError> {\n  /**\n   * @alpha\n   *\n   * Creates a new StorageAnalyticsClient instance\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param url - The base URL for the storage API\n   * @param headers - HTTP headers to include in requests\n   * @param fetch - Optional custom fetch implementation\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageAnalyticsClient(url, headers)\n   * ```\n   */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    const finalUrl = url.replace(/\\/$/, '')\n    const finalHeaders = { ...DEFAULT_HEADERS, ...headers }\n    super(finalUrl, finalHeaders, fetch, 'storage')\n  }\n\n  /**\n   * @alpha\n   *\n   * Creates a new analytics bucket using Iceberg tables\n   * Analytics buckets are optimized for analytical queries and data processing\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param name A unique name for the bucket you are creating\n   * @returns Promise with response containing newly created analytics bucket or error\n   *\n   * @example Create analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"analytics-data\",\n   *     \"type\": \"ANALYTICS\",\n   *     \"format\": \"iceberg\",\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(name: string): Promise<\n    | {\n        data: AnalyticBucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await post(this.fetch, `${this.url}/bucket`, { name }, { headers: this.headers })\n    })\n  }\n\n  /**\n   * @alpha\n   *\n   * Retrieves the details of all Analytics Storage buckets within an existing project\n   * Only returns buckets of type 'ANALYTICS'\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of analytics buckets or error\n   *\n   * @example List analytics buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc'\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"analytics-data\",\n   *       \"type\": \"ANALYTICS\",\n   *       \"format\": \"iceberg\",\n   *       \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *       \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async listBuckets(options?: {\n    limit?: number\n    offset?: number\n    sortColumn?: 'name' | 'created_at' | 'updated_at'\n    sortOrder?: 'asc' | 'desc'\n    search?: string\n  }): Promise<\n    | {\n        data: AnalyticBucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      // Build query string from options\n      const queryParams = new URLSearchParams()\n      if (options?.limit !== undefined) queryParams.set('limit', options.limit.toString())\n      if (options?.offset !== undefined) queryParams.set('offset', options.offset.toString())\n      if (options?.sortColumn) queryParams.set('sortColumn', options.sortColumn)\n      if (options?.sortOrder) queryParams.set('sortOrder', options.sortOrder)\n      if (options?.search) queryParams.set('search', options.search)\n\n      const queryString = queryParams.toString()\n      const url = queryString ? `${this.url}/bucket?${queryString}` : `${this.url}/bucket`\n\n      return await get(this.fetch, url, { headers: this.headers })\n    })\n  }\n\n  /**\n   * @alpha\n   *\n   * Deletes an existing analytics bucket\n   * A bucket can't be deleted with existing objects inside it\n   * You must first empty the bucket before deletion\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName The unique identifier of the bucket you would like to delete\n   * @returns Promise with response containing success message or error\n   *\n   * @example Delete analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .deleteBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(bucketName: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.handleOperation(async () => {\n      return await remove(\n        this.fetch,\n        `${this.url}/bucket/${bucketName}`,\n        {},\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /**\n   * @alpha\n   *\n   * Get an Iceberg REST Catalog client configured for a specific analytics bucket\n   * Use this to perform advanced table and namespace operations within the bucket\n   * The returned client provides full access to the Apache Iceberg REST Catalog API\n   * with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName - The name of the analytics bucket (warehouse) to connect to\n   * @returns The wrapped Iceberg catalog client\n   * @throws {StorageError} If the bucket name is invalid\n   *\n   * @example Get catalog and create table\n   * ```js\n   * // First, create an analytics bucket\n   * const { data: bucket, error: bucketError } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   *\n   * // Get the Iceberg catalog for that bucket\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Create a namespace\n   * const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\n   *\n   * // Create a table with schema\n   * const { data: tableMetadata, error: tableError } = await catalog.createTable(\n   *   { namespace: ['default'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\n   *         { id: 3, name: 'user_id', type: 'string', required: false }\n   *       ],\n   *       'schema-id': 0,\n   *       'identifier-field-ids': [1]\n   *     },\n   *     'partition-spec': {\n   *       'spec-id': 0,\n   *       fields: []\n   *     },\n   *     'write-order': {\n   *       'order-id': 0,\n   *       fields: []\n   *     },\n   *     properties: {\n   *       'write.format.default': 'parquet'\n   *     }\n   *   }\n   * )\n   * ```\n   *\n   * @example List tables in namespace\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all tables in the default namespace\n   * const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\n   * if (listError) {\n   *   if (listError.isNotFound()) {\n   *     console.log('Namespace not found')\n   *   }\n   *   return\n   * }\n   * console.log(tables) // [{ namespace: ['default'], name: 'events' }]\n   * ```\n   *\n   * @example Working with namespaces\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all namespaces\n   * const { data: namespaces } = await catalog.listNamespaces()\n   *\n   * // Create namespace with properties\n   * await catalog.createNamespace(\n   *   { namespace: ['production'] },\n   *   { properties: { owner: 'data-team', env: 'prod' } }\n   * )\n   * ```\n   *\n   * @example Cleanup operations\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Drop table with purge option (removes all data)\n   * const { error: dropError } = await catalog.dropTable(\n   *   { namespace: ['default'], name: 'events' },\n   *   { purge: true }\n   * )\n   *\n   * if (dropError?.isNotFound()) {\n   *   console.log('Table does not exist')\n   * }\n   *\n   * // Drop namespace (must be empty)\n   * await catalog.dropNamespace({ namespace: ['default'] })\n   * ```\n   *\n   * @remarks\n   * This method provides a bridge between Supabase's bucket management and the standard\n   * Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\n   * All authentication and configuration is handled automatically using your Supabase credentials.\n   *\n   * **Error Handling**: Invalid bucket names throw immediately. All catalog\n   * operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\n   * Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\n   * Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\n   *\n   * **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\n   * deletes all table data. Without it, the table is marked as deleted but data remains.\n   *\n   * **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\n   * For complete API documentation and advanced usage, refer to the\n   * [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\n   */\n  from(bucketName: string): WrappedIcebergRestCatalog {\n    // Validate bucket name using same rules as Supabase Storage API backend\n    if (!isValidBucketName(bucketName)) {\n      throw new StorageError(\n        'Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines ' +\n          'and should avoid the use of any other characters.'\n      )\n    }\n\n    // Construct the Iceberg REST Catalog URL\n    // The base URL is /storage/v1/iceberg\n    // Note: IcebergRestCatalog from iceberg-js automatically adds /v1/ prefix to API paths\n    // so we should NOT append /v1 here (it would cause double /v1/v1/ in the URL)\n    const catalog = new IcebergRestCatalog({\n      baseUrl: this.url,\n      catalogName: bucketName, // Maps to the warehouse parameter in Supabase's implementation\n      auth: {\n        type: 'custom',\n        getHeaders: async () => this.headers,\n      },\n      fetch: this.fetch,\n    })\n\n    const shouldThrowOnError = this.shouldThrowOnError\n\n    const wrappedCatalog = new Proxy(catalog, {\n      get(target, prop: keyof IcebergRestCatalog) {\n        const value = target[prop]\n        if (typeof value !== 'function') {\n          return value\n        }\n\n        return async (...args: unknown[]) => {\n          try {\n            const data = await (value as Function).apply(target, args)\n            return { data, error: null }\n          } catch (error) {\n            if (shouldThrowOnError) {\n              throw error\n            }\n            return { data: null, error: error as IcebergError }\n          }\n        }\n      },\n    }) as unknown as WrappedIcebergRestCatalog\n\n    return wrappedCatalog\n  }\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { StorageError } from '../lib/common/errors'\nimport { Fetch, vectorsApi } from '../lib/common/fetch'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport {\n  ApiResponse,\n  VectorIndex,\n  ListIndexesOptions,\n  ListIndexesResponse,\n  VectorDataType,\n  DistanceMetric,\n  MetadataConfiguration,\n} from '../lib/types'\n\n/**\n * @alpha\n *\n * Options for creating a vector index\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface CreateIndexOptions {\n  vectorBucketName: string\n  indexName: string\n  dataType: VectorDataType\n  dimension: number\n  distanceMetric: DistanceMetric\n  metadataConfiguration?: MetadataConfiguration\n}\n\n/**\n * @hidden\n * Base implementation for vector index operations.\n * Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\n */\nexport default class VectorIndexApi extends BaseApiClient<StorageError> {\n  /** Creates a new VectorIndexApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    const finalUrl = url.replace(/\\/$/, '')\n    const finalHeaders = { ...DEFAULT_HEADERS, 'Content-Type': 'application/json', ...headers }\n    super(finalUrl, finalHeaders, fetch, 'vectors')\n  }\n\n  /** Creates a new vector index within a bucket */\n  async createIndex(options: CreateIndexOptions): Promise<ApiResponse<undefined>> {\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(this.fetch, `${this.url}/CreateIndex`, options, {\n        headers: this.headers,\n      })\n      return data || {}\n    })\n  }\n\n  /** Retrieves metadata for a specific vector index */\n  async getIndex(\n    vectorBucketName: string,\n    indexName: string\n  ): Promise<ApiResponse<{ index: VectorIndex }>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(\n        this.fetch,\n        `${this.url}/GetIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /** Lists vector indexes within a bucket with optional filtering and pagination */\n  async listIndexes(options: ListIndexesOptions): Promise<ApiResponse<ListIndexesResponse>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(this.fetch, `${this.url}/ListIndexes`, options, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /** Deletes a vector index and all its data */\n  async deleteIndex(vectorBucketName: string, indexName: string): Promise<ApiResponse<undefined>> {\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(\n        this.fetch,\n        `${this.url}/DeleteIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n      return data || {}\n    })\n  }\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { StorageError } from '../lib/common/errors'\nimport { Fetch, vectorsApi } from '../lib/common/fetch'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport {\n  ApiResponse,\n  PutVectorsOptions,\n  GetVectorsOptions,\n  GetVectorsResponse,\n  DeleteVectorsOptions,\n  ListVectorsOptions,\n  ListVectorsResponse,\n  QueryVectorsOptions,\n  QueryVectorsResponse,\n} from '../lib/types'\n\n/**\n * @hidden\n * Base implementation for vector data operations.\n * Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\n */\nexport default class VectorDataApi extends BaseApiClient<StorageError> {\n  /** Creates a new VectorDataApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    const finalUrl = url.replace(/\\/$/, '')\n    const finalHeaders = { ...DEFAULT_HEADERS, 'Content-Type': 'application/json', ...headers }\n    super(finalUrl, finalHeaders, fetch, 'vectors')\n  }\n\n  /** Inserts or updates vectors in batch (1-500 per request) */\n  async putVectors(options: PutVectorsOptions): Promise<ApiResponse<undefined>> {\n    // Validate batch size\n    if (options.vectors.length < 1 || options.vectors.length > 500) {\n      throw new Error('Vector batch size must be between 1 and 500 items')\n    }\n\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(this.fetch, `${this.url}/PutVectors`, options, {\n        headers: this.headers,\n      })\n      return data || {}\n    })\n  }\n\n  /** Retrieves vectors by their keys in batch */\n  async getVectors(options: GetVectorsOptions): Promise<ApiResponse<GetVectorsResponse>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(this.fetch, `${this.url}/GetVectors`, options, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /** Lists vectors in an index with pagination */\n  async listVectors(options: ListVectorsOptions): Promise<ApiResponse<ListVectorsResponse>> {\n    // Validate segment configuration\n    if (options.segmentCount !== undefined) {\n      if (options.segmentCount < 1 || options.segmentCount > 16) {\n        throw new Error('segmentCount must be between 1 and 16')\n      }\n      if (options.segmentIndex !== undefined) {\n        if (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) {\n          throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`)\n        }\n      }\n    }\n\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(this.fetch, `${this.url}/ListVectors`, options, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /** Queries for similar vectors using approximate nearest neighbor search */\n  async queryVectors(options: QueryVectorsOptions): Promise<ApiResponse<QueryVectorsResponse>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(this.fetch, `${this.url}/QueryVectors`, options, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /** Deletes vectors by their keys in batch (1-500 per request) */\n  async deleteVectors(options: DeleteVectorsOptions): Promise<ApiResponse<undefined>> {\n    // Validate batch size\n    if (options.keys.length < 1 || options.keys.length > 500) {\n      throw new Error('Keys batch size must be between 1 and 500 items')\n    }\n\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(this.fetch, `${this.url}/DeleteVectors`, options, {\n        headers: this.headers,\n      })\n      return data || {}\n    })\n  }\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { StorageError } from '../lib/common/errors'\nimport { Fetch, vectorsApi } from '../lib/common/fetch'\nimport BaseApiClient from '../lib/common/BaseApiClient'\nimport {\n  ApiResponse,\n  VectorBucket,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n} from '../lib/types'\n\n/**\n * @hidden\n * Base implementation for vector bucket operations.\n * Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\n */\nexport default class VectorBucketApi extends BaseApiClient<StorageError> {\n  /** Creates a new VectorBucketApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    const finalUrl = url.replace(/\\/$/, '')\n    const finalHeaders = { ...DEFAULT_HEADERS, 'Content-Type': 'application/json', ...headers }\n    super(finalUrl, finalHeaders, fetch, 'vectors')\n  }\n\n  /** Creates a new vector bucket */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(\n        this.fetch,\n        `${this.url}/CreateVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return data || {}\n    })\n  }\n\n  /** Retrieves metadata for a specific vector bucket */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(\n        this.fetch,\n        `${this.url}/GetVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n    })\n  }\n\n  /** Lists vector buckets with optional filtering and pagination */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    return this.handleOperation(async () => {\n      return await vectorsApi.post(this.fetch, `${this.url}/ListVectorBuckets`, options, {\n        headers: this.headers,\n      })\n    })\n  }\n\n  /** Deletes a vector bucket (must be empty first) */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return this.handleOperation(async () => {\n      const data = await vectorsApi.post(\n        this.fetch,\n        `${this.url}/DeleteVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return data || {}\n    })\n  }\n}\n","import VectorIndexApi, { CreateIndexOptions } from './VectorIndexApi'\nimport VectorDataApi from './VectorDataApi'\nimport { Fetch } from '../lib/common/fetch'\nimport VectorBucketApi from './VectorBucketApi'\nimport {\n  ApiResponse,\n  DeleteVectorsOptions,\n  GetVectorsOptions,\n  ListIndexesOptions,\n  ListVectorsOptions,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n  PutVectorsOptions,\n  QueryVectorsOptions,\n  VectorBucket,\n} from '../lib/types'\n\n/**\n *\n * @alpha\n *\n * Configuration options for the Storage Vectors client\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface StorageVectorsClientOptions {\n  /**\n   * Custom headers to include in all requests\n   */\n  headers?: { [key: string]: string }\n  /**\n   * Custom fetch implementation (optional)\n   * Useful for testing or custom request handling\n   */\n  fetch?: Fetch\n}\n\n/**\n *\n * @alpha\n *\n * Main client for interacting with S3 Vectors API\n * Provides access to bucket, index, and vector data operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n *\n * **Usage Patterns:**\n *\n * ```typescript\n * const { data, error } = await supabase\n *  .storage\n *  .vectors\n *  .createBucket('embeddings-prod')\n *\n * // Access index operations via buckets\n * const bucket = supabase.storage.vectors.from('embeddings-prod')\n * await bucket.createIndex({\n *   indexName: 'documents',\n *   dataType: 'float32',\n *   dimension: 1536,\n *   distanceMetric: 'cosine'\n * })\n *\n * // Access vector operations via index\n * const index = bucket.index('documents')\n * await index.putVectors({\n *   vectors: [\n *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n *   ]\n * })\n *\n * // Query similar vectors\n * const { data } = await index.queryVectors({\n *   queryVector: { float32: [...] },\n *   topK: 5,\n *   returnDistance: true\n * })\n * ```\n */\nexport class StorageVectorsClient extends VectorBucketApi {\n  /**\n   * @alpha\n   *\n   * Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param url - Base URL of the Storage Vectors REST API.\n   * @param options.headers - Optional headers (for example `Authorization`) applied to every request.\n   * @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageVectorsClient(url, options)\n   * ```\n   */\n  constructor(url: string, options: StorageVectorsClientOptions = {}) {\n    super(url, options.headers || {}, options.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific vector bucket\n   * Returns a scoped client for index and vector operations within the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Bucket-scoped client with index and vector operations\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  from(vectorBucketName: string): VectorBucketScope {\n    return new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector bucket\n   * Vector buckets are containers for vector indexes and their data\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Unique name for the vector bucket\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .createBucket('embeddings-prod')\n   * ```\n   */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.createBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific vector bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Promise with bucket metadata or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .getBucket('embeddings-prod')\n   *\n   * console.log('Bucket created:', data?.vectorBucket.creationTime)\n   * ```\n   */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    return super.getBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists all vector buckets with optional filtering and pagination\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Optional filters (prefix, maxResults, nextToken)\n   * @returns Promise with list of buckets or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .listBuckets({ prefix: 'embeddings-' })\n   *\n   * data?.vectorBuckets.forEach(bucket => {\n   *   console.log(bucket.vectorBucketName)\n   * })\n   * ```\n   */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    return super.listBuckets(options)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes a vector bucket (bucket must be empty)\n   * All indexes must be deleted before deleting the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .deleteBucket('embeddings-old')\n   * ```\n   */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.deleteBucket(vectorBucketName)\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector bucket\n * Provides index management and access to vector operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorBucketScope extends VectorIndexApi {\n  private vectorBucketName: string\n\n  /**\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all index operations to the provided bucket.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Index configuration (vectorBucketName is automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.createIndex({\n   *   indexName: 'documents-openai',\n   *   dataType: 'float32',\n   *   dimension: 1536,\n   *   distanceMetric: 'cosine',\n   *   metadataConfiguration: {\n   *     nonFilterableMetadataKeys: ['raw_text']\n   *   }\n   * })\n   * ```\n   */\n  override async createIndex(options: Omit<CreateIndexOptions, 'vectorBucketName'>) {\n    return super.createIndex({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists indexes in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (vectorBucketName is automatically set)\n   * @returns Promise with response containing indexes array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.listIndexes({ prefix: 'documents-' })\n   * ```\n   */\n  override async listIndexes(options: Omit<ListIndexesOptions, 'vectorBucketName'> = {}) {\n    return super.listIndexes({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to retrieve\n   * @returns Promise with index metadata or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.getIndex('documents-openai')\n   * console.log('Dimension:', data?.index.dimension)\n   * ```\n   */\n  override async getIndex(indexName: string) {\n    return super.getIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes an index from this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.deleteIndex('old-index')\n   * ```\n   */\n  override async deleteIndex(indexName: string) {\n    return super.deleteIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific index within this bucket\n   * Returns a scoped client for vector data operations\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index\n   * @returns Index-scoped client with vector data operations\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   *\n   * // Insert vectors\n   * await index.putVectors({\n   *   vectors: [\n   *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n   *   ]\n   * })\n   *\n   * // Query similar vectors\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [...] },\n   *   topK: 5\n   * })\n   * ```\n   */\n  index(indexName: string): VectorIndexScope {\n    return new VectorIndexScope(\n      this.url,\n      this.headers,\n      this.vectorBucketName,\n      indexName,\n      this.fetch\n    )\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector index\n * Provides vector data operations (put, get, list, query, delete)\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorIndexScope extends VectorDataApi {\n  private vectorBucketName: string\n  private indexName: string\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    indexName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n    this.indexName = indexName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Inserts or updates vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector insertion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.putVectors({\n   *   vectors: [\n   *     {\n   *       key: 'doc-1',\n   *       data: { float32: [0.1, 0.2, ...] },\n   *       metadata: { title: 'Introduction', page: 1 }\n   *     }\n   *   ]\n   * })\n   * ```\n   */\n  override async putVectors(options: Omit<PutVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.putVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector retrieval options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.getVectors({\n   *   keys: ['doc-1', 'doc-2'],\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async getVectors(options: Omit<GetVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.getVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists vectors in this index with pagination\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.listVectors({\n   *   maxResults: 500,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async listVectors(\n    options: Omit<ListVectorsOptions, 'vectorBucketName' | 'indexName'> = {}\n  ) {\n    return super.listVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Queries for similar vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Query options (bucket and index names automatically set)\n   * @returns Promise with response containing matches array of similar vectors ordered by distance or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [0.1, 0.2, ...] },\n   *   topK: 5,\n   *   filter: { category: 'technical' },\n   *   returnDistance: true,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async queryVectors(\n    options: Omit<QueryVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.queryVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Deletion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.deleteVectors({\n   *   keys: ['doc-1', 'doc-2', 'doc-3']\n   * })\n   * ```\n   */\n  override async deleteVectors(\n    options: Omit<DeleteVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.deleteVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n}\n","import StorageFileApi from './packages/StorageFileApi'\nimport StorageBucketApi from './packages/StorageBucketApi'\nimport StorageAnalyticsClient from './packages/StorageAnalyticsClient'\nimport { Fetch } from './lib/common/fetch'\nimport { StorageVectorsClient } from './packages/StorageVectorsClient'\n\nexport interface StorageClientOptions {\n  useNewHostname?: boolean\n}\n\nexport class StorageClient extends StorageBucketApi {\n  /**\n   * Creates a client for Storage buckets, files, analytics, and vectors.\n   *\n   * @category File Buckets\n   * @example\n   * ```ts\n   * import { StorageClient } from '@supabase/storage-js'\n   *\n   * const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\n   *   apikey: 'public-anon-key',\n   * })\n   * const avatars = storage.from('avatars')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    super(url, headers, fetch, opts)\n  }\n\n  /**\n   * Perform file operation in a bucket.\n   *\n   * @category File Buckets\n   * @param id The bucket id to operate on.\n   *\n   * @example\n   * ```typescript\n   * const avatars = supabase.storage.from('avatars')\n   * ```\n   */\n  from(id: string): StorageFileApi {\n    return new StorageFileApi(this.url, this.headers, id, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access vector storage operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @returns A StorageVectorsClient instance configured with the current storage settings.\n   */\n  get vectors(): StorageVectorsClient {\n    return new StorageVectorsClient(this.url + '/vector', {\n      headers: this.headers,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access analytics storage operations using Iceberg tables.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @returns A StorageAnalyticsClient instance configured with the current storage settings.\n   */\n  get analytics(): StorageAnalyticsClient {\n    return new StorageAnalyticsClient(this.url + '/iceberg', this.headers, this.fetch)\n  }\n}\n"],"mappings":";;;;;;;AAUA,IAAaA,YAAA,GAAb,cAAkCC,KAAA,CAAM;EAMtCC,YACEC,OAAA,EACAC,SAAA,GAA4B,WAC5BC,MAAA,EACAC,UAAA,EACA;IACA,MAAMH,OAAA,CAAQ;SAXNI,gBAAA,GAAmB;IAY3B,KAAKH,SAAA,GAAYA,SAAA;IACjB,KAAKI,IAAA,GAAOJ,SAAA,KAAc,YAAY,wBAAwB;IAC9D,KAAKC,MAAA,GAASA,MAAA;IACd,KAAKC,UAAA,GAAaA,UAAA;;;;;;;;AAStB,SAAgBG,eAAeC,KAAA,EAAuC;EACpE,OAAO,OAAOA,KAAA,KAAU,YAAYA,KAAA,KAAU,QAAQ,sBAAsBA,KAAA;;;;;;AAO9E,IAAaC,eAAA,GAAb,cAAqCX,YAAA,CAAa;EAIhDE,YACEC,OAAA,EACAE,MAAA,EACAC,UAAA,EACAF,SAAA,GAA4B,WAC5B;IACA,MAAMD,OAAA,EAASC,SAAA,EAAWC,MAAA,EAAQC,UAAA,CAAW;IAC7C,KAAKE,IAAA,GAAOJ,SAAA,KAAc,YAAY,2BAA2B;IACjE,KAAKC,MAAA,GAASA,MAAA;IACd,KAAKC,UAAA,GAAaA,UAAA;;EAGpBM,OAAA,EAAS;IACP,OAAO;MACLJ,IAAA,EAAM,KAAKA,IAAA;MACXL,OAAA,EAAS,KAAKA,OAAA;MACdE,MAAA,EAAQ,KAAKA,MAAA;MACbC,UAAA,EAAY,KAAKA;KAClB;;;;;;;AAQL,IAAaO,mBAAA,GAAb,cAAyCb,YAAA,CAAa;EAGpDE,YAAYC,OAAA,EAAiBW,aAAA,EAAwBV,SAAA,GAA4B,WAAW;IAC1F,MAAMD,OAAA,EAASC,SAAA,CAAU;IACzB,KAAKI,IAAA,GAAOJ,SAAA,KAAc,YAAY,+BAA+B;IACrE,KAAKU,aAAA,GAAgBA,aAAA;;;;;;;AAYzB,IAAaC,mBAAA,GAAb,cAAyCf,YAAA,CAAa;EACpDE,YAAYC,OAAA,EAAiB;IAC3B,MAAMA,OAAA,EAAS,UAAU;;;;;;;;AAS7B,SAAgBa,sBAAsBN,KAAA,EAA8C;EAClF,OAAOD,cAAA,CAAeC,KAAA,CAAM,IAAKA,KAAA,CAAuB,iBAAiB;;;;;;AAO3E,IAAaO,sBAAA,GAAb,cAA4CN,eAAA,CAAgB;EAC1DT,YAAYC,OAAA,EAAiBE,MAAA,EAAgBC,UAAA,EAAoB;IAC/D,MAAMH,OAAA,EAASE,MAAA,EAAQC,UAAA,EAAY,UAAU;;;;;;;AAQjD,IAAaY,0BAAA,GAAb,cAAgDL,mBAAA,CAAoB;EAClEX,YAAYC,OAAA,EAAiBW,aAAA,EAAwB;IACnD,MAAMX,OAAA,EAASW,aAAA,EAAe,UAAU;;;;;;;AAQ5C,IAAYK,uBAAA,4BAAAC,yBAAA,EAAL;;EAELA,yBAAA;;EAEAA,yBAAA;;EAEAA,yBAAA;;EAEAA,yBAAA;;EAEAA,yBAAA;;EAEAA,yBAAA;;;;;;;;;;;;;ACrIF,MAAaC,YAAA,GAAgBC,WAAA,IAA+B;EAC1D,IAAIA,WAAA,EACF,QAAQ,GAAGC,IAAA,KAASD,WAAA,CAAY,GAAGC,IAAA,CAAK;EAE1C,QAAQ,GAAGA,IAAA,KAASC,KAAA,CAAM,GAAGD,IAAA,CAAK;;;;;;;;;;AAqBpC,MAAaE,aAAA,GAAiBC,KAAA,IAA2B;EACvD,IAAI,OAAOA,KAAA,KAAU,YAAYA,KAAA,KAAU,MACzC,OAAO;EAGT,MAAMC,SAAA,GAAYC,MAAA,CAAOC,cAAA,CAAeH,KAAA,CAAM;EAC9C,QACGC,SAAA,KAAc,QACbA,SAAA,KAAcC,MAAA,CAAOD,SAAA,IACrBC,MAAA,CAAOC,cAAA,CAAeF,SAAA,CAAU,KAAK,SACvC,EAAEG,MAAA,CAAOC,WAAA,IAAeL,KAAA,KACxB,EAAEI,MAAA,CAAOE,QAAA,IAAYN,KAAA;;;;;;;;;AAWzB,MAAaO,gBAAA,GAAoBC,IAAA,IAAuC;EACtE,IAAIC,KAAA,CAAMC,OAAA,CAAQF,IAAA,CAAK,EACrB,OAAOA,IAAA,CAAKG,GAAA,CAAKC,EAAA,IAAOL,gBAAA,CAAiBK,EAAA,CAAG,CAAC,M,IACpC,OAAOJ,IAAA,KAAS,cAAcA,IAAA,KAASN,MAAA,CAAOM,IAAA,CAAK,EAC5D,OAAOA,IAAA;EAGT,MAAMK,MAAA,GAA8B,EAAE;EACtCX,MAAA,CAAOY,OAAA,CAAQN,IAAA,CAAK,CAACO,OAAA,EAAS,CAACC,GAAA,EAAKhB,KAAA,MAAW;IAC7C,MAAMiB,MAAA,GAASD,GAAA,CAAIE,OAAA,CAAQ,iBAAkBC,CAAA,IAAMA,CAAA,CAAEC,WAAA,EAAa,CAACF,OAAA,CAAQ,SAAS,GAAG,CAAC;IACxFL,MAAA,CAAOI,MAAA,IAAUV,gBAAA,CAAiBP,KAAA,CAAM;IACxC;EAEF,OAAOa,MAAA;;;;;;;;;;;;;;;;;AAkBT,MAAaQ,iBAAA,GAAqBC,UAAA,IAAgC;EAChE,IAAI,CAACA,UAAA,IAAc,OAAOA,UAAA,KAAe,UACvC,OAAO;EAIT,IAAIA,UAAA,CAAWC,MAAA,KAAW,KAAKD,UAAA,CAAWC,MAAA,GAAS,KACjD,OAAO;EAIT,IAAID,UAAA,CAAWE,IAAA,EAAM,KAAKF,UAAA,EACxB,OAAO;EAMT,IAAIA,UAAA,CAAWG,QAAA,CAAS,IAAI,IAAIH,UAAA,CAAWG,QAAA,CAAS,KAAK,EACvD,OAAO;EAOT,OADwB,4BACDC,IAAA,CAAKJ,UAAA,CAAW;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtFzC,MAAMK,gBAAA,GAAoBC,GAAA,IACxB;;aAAIC,GAAA,IACJD,GAAA,CAAInD,OAAA,IACJmD,GAAA,CAAIE,iBAAA,KACH,OAAOF,GAAA,CAAI5C,KAAA,KAAU,WAAW4C,GAAA,CAAI5C,KAAA,IAAA+C,UAAA,GAAQH,GAAA,CAAI5C,KAAA,cAAA+C,UAAA,uBAAAA,UAAA,CAAOtD,OAAA,KACxDuD,IAAA,CAAKC,SAAA,CAAUL,GAAA,CAAI;;;;;;;;;AASrB,MAAMM,WAAA,GAAc,MAAAA,CAClBlD,KAAA,EACAmD,MAAA,EACAC,OAAA,EACA1D,SAAA,KACG;EAUH,IANEM,KAAA,IACA,OAAOA,KAAA,KAAU,YACjB,YAAYA,KAAA,IACZ,QAAQA,KAAA,IACR,OAAQA,KAAA,CAAcL,MAAA,KAAW,YAEb,EAAAyD,OAAA,aAAAA,OAAA,uBAACA,OAAA,CAASC,aAAA,GAAe;IAC7C,MAAMC,aAAA,GAAgBtD,KAAA;IACtB,MAAML,MAAA,GAAS2D,aAAA,CAAc3D,MAAA,IAAU;IAGvC,IAAI,OAAO2D,aAAA,CAAcC,IAAA,KAAS,YAChCD,aAAA,CACGC,IAAA,EAAM,CACNC,IAAA,CAAMZ,GAAA,IAAa;MAClB,MAAMhD,UAAA,IAAAgD,GAAA,aAAAA,GAAA,uBAAaA,GAAA,CAAKhD,UAAA,MAAAgD,GAAA,aAAAA,GAAA,uBAAcA,GAAA,CAAKa,IAAA,KAAQ9D,MAAA,GAAS;MAC5DwD,MAAA,CAAO,IAAIlD,eAAA,CAAgB0C,gBAAA,CAAiBC,GAAA,CAAI,EAAEjD,MAAA,EAAQC,UAAA,EAAYF,SAAA,CAAU,CAAC;MACjF,CACDgE,KAAA,OAAY;MAEX,IAAIhE,SAAA,KAAc,WAAW;QAC3B,MAAME,UAAA,GAAaD,MAAA,GAAS;QAE5BwD,MAAA,CAAO,IAAIlD,eAAA,CADKqD,aAAA,CAAcK,UAAA,IAAc,QAAQhE,MAAA,QAAO,EACvBA,MAAA,EAAQC,UAAA,EAAYF,SAAA,CAAU,CAAC;aAC9D;QACL,MAAME,UAAA,GAAaD,MAAA,GAAS;QAE5BwD,MAAA,CAAO,IAAIlD,eAAA,CADKqD,aAAA,CAAcK,UAAA,IAAc,QAAQhE,MAAA,QAAO,EACvBA,MAAA,EAAQC,UAAA,EAAYF,SAAA,CAAU,CAAC;;MAErE,MACC;MAEL,MAAME,UAAA,GAAaD,MAAA,GAAS;MAE5BwD,MAAA,CAAO,IAAIlD,eAAA,CADKqD,aAAA,CAAcK,UAAA,IAAc,QAAQhE,MAAA,QAAO,EACvBA,MAAA,EAAQC,UAAA,EAAYF,SAAA,CAAU,CAAC;;SAGrEyD,MAAA,CAAO,IAAIhD,mBAAA,CAAoBwC,gBAAA,CAAiB3C,KAAA,CAAM,EAAEA,KAAA,EAAON,SAAA,CAAU,CAAC;;;;;;;;;;AAY9E,MAAMkE,iBAAA,GAAAA,CACJC,MAAA,EACAT,OAAA,EACAU,UAAA,EACAC,IAAA,KACG;EACH,MAAMC,MAAA,GAA+B;IAAEH,MAAA;IAAQI,OAAA,GAAAb,OAAA,aAAAA,OAAA,uBAASA,OAAA,CAASa,OAAA,KAAW;GAAI;EAEhF,IAAIJ,MAAA,KAAW,SAASA,MAAA,KAAW,UAAU,CAACE,IAAA,EAC5C,OAAAG,cAAA,CAAAA,cAAA,KAAYF,MAAA,GAAWF,UAAA;EAGzB,IAAI/C,aAAA,CAAcgD,IAAA,CAAK,EAAE;IACvBC,MAAA,CAAOC,OAAA,GAAAC,cAAA;MAAY,gBAAgB;IAAA,GAAAd,OAAA,aAAAA,OAAA,uBAAuBA,OAAA,CAASa,OAAA;IACnED,MAAA,CAAOD,IAAA,GAAOf,IAAA,CAAKC,SAAA,CAAUc,IAAA,CAAK;SAElCC,MAAA,CAAOD,IAAA,GAAOA,IAAA;EAGhB,IAAAX,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASe,MAAA,EACXH,MAAA,CAAOG,MAAA,GAASf,OAAA,CAAQe,MAAA;EAG1B,OAAAD,cAAA,CAAAA,cAAA,KAAYF,MAAA,GAAWF,UAAA;;;;;;;;;;;;;AAczB,eAAeM,eACbC,OAAA,EACAR,MAAA,EACAS,GAAA,EACAlB,OAAA,EACAU,UAAA,EACAC,IAAA,EACArE,SAAA,EACc;EACd,OAAO,IAAI6E,OAAA,EAASC,OAAA,EAASrB,MAAA,KAAW;IACtCkB,OAAA,CAAQC,GAAA,EAAKV,iBAAA,CAAkBC,MAAA,EAAQT,OAAA,EAASU,UAAA,EAAYC,IAAA,CAAK,CAAC,CAC/DP,IAAA,CAAM3B,MAAA,IAAW;MAChB,IAAI,CAACA,MAAA,CAAO4C,EAAA,EAAI,MAAM5C,MAAA;MACtB,IAAAuB,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASC,aAAA,EAAe,OAAOxB,MAAA;MAMnC,IAAInC,SAAA,KAAc,WAAW;QAC3B,MAAMgF,WAAA,GAAc7C,MAAA,CAAOoC,OAAA,CAAQU,GAAA,CAAI,eAAe;QAItD,IAHsB9C,MAAA,CAAOoC,OAAA,CAAQU,GAAA,CAAI,iBAAiB,KAGpC,OAAO9C,MAAA,CAAOlC,MAAA,KAAW,KAC7C,OAAO,EAAE;QAIX,IAAI,CAAC+E,WAAA,IAAe,CAACA,WAAA,CAAYjC,QAAA,CAAS,mBAAmB,EAC3D,OAAO,EAAE;;MAIb,OAAOZ,MAAA,CAAO0B,IAAA,EAAM;MACpB,CACDC,IAAA,CAAMoB,IAAA,IAASJ,OAAA,CAAQI,IAAA,CAAK,CAAC,CAC7BlB,KAAA,CAAO1D,KAAA,IAAUkD,WAAA,CAAYlD,KAAA,EAAOmD,MAAA,EAAQC,OAAA,EAAS1D,SAAA,CAAU,CAAC;IACnE;;;;;;;AAQJ,SAAgBmF,eAAenF,SAAA,GAA4B,WAAW;EACpE,OAAO;IASLiF,GAAA,EAAK,MAAAA,CACHN,OAAA,EACAC,GAAA,EACAlB,OAAA,EACAU,UAAA,KACiB;MACjB,OAAOM,cAAA,CAAeC,OAAA,EAAS,OAAOC,GAAA,EAAKlB,OAAA,EAASU,UAAA,EAAY,QAAWpE,SAAA,CAAU;;IAYvFoF,IAAA,EAAM,MAAAA,CACJT,OAAA,EACAC,GAAA,EACAP,IAAA,EACAX,OAAA,EACAU,UAAA,KACiB;MACjB,OAAOM,cAAA,CAAeC,OAAA,EAAS,QAAQC,GAAA,EAAKlB,OAAA,EAASU,UAAA,EAAYC,IAAA,EAAMrE,SAAA,CAAU;;IAYnFqF,GAAA,EAAK,MAAAA,CACHV,OAAA,EACAC,GAAA,EACAP,IAAA,EACAX,OAAA,EACAU,UAAA,KACiB;MACjB,OAAOM,cAAA,CAAeC,OAAA,EAAS,OAAOC,GAAA,EAAKlB,OAAA,EAASU,UAAA,EAAYC,IAAA,EAAMrE,SAAA,CAAU;;IAWlFsF,IAAA,EAAM,MAAAA,CACJX,OAAA,EACAC,GAAA,EACAlB,OAAA,EACAU,UAAA,KACiB;MACjB,OAAOM,cAAA,CACLC,OAAA,EACA,QACAC,GAAA,EAAAJ,cAAA,CAAAA,cAAA,KAEKd,OAAA;QACHC,aAAA,EAAe;MAAA,IAEjBS,UAAA,EACA,QACApE,SAAA,CACD;;IAYHuF,MAAA,EAAQ,MAAAA,CACNZ,OAAA,EACAC,GAAA,EACAP,IAAA,EACAX,OAAA,EACAU,UAAA,KACiB;MACjB,OAAOM,cAAA,CAAeC,OAAA,EAAS,UAAUC,GAAA,EAAKlB,OAAA,EAASU,UAAA,EAAYC,IAAA,EAAMrE,SAAA,CAAU;;GAEtF;;AAIH,MAAMwF,UAAA,GAAaL,cAAA,CAAe,UAAU;AAC5C,MAAa;EAAEF,GAAA;EAAKG,IAAA;EAAMC,GAAA;EAAKC,IAAA;EAAMC;AAAA,IAAWC,UAAA;AAGhD,MAAaC,UAAA,GAAaN,cAAA,CAAe,UAAU;;;;;;;;;;;AC1RnD,IAA8BO,aAAA,GAA9B,MAAwF;;;;;;;;EActF5F,YACE8E,GAAA,EACAL,OAAA,GAAqC,EAAE,EACvCoB,OAAA,EACA3F,SAAA,GAA4B,WAC5B;SAfQ4F,kBAAA,GAAqB;IAgB7B,KAAKhB,GAAA,GAAMA,GAAA;IACX,KAAKL,OAAA,GAAUA,OAAA;IACf,KAAKnD,KAAA,GAAQH,YAAA,CAAa0E,OAAA,CAAM;IAChC,KAAK3F,SAAA,GAAYA,SAAA;;;;;;;;EASnB6F,YAAOA,CAAA,EAAqB;IAC1B,KAAKD,kBAAA,GAAqB;IAC1B,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4BT,MAAgBE,gBACdC,SAAA,EACmE;;IACnE,IAAI;MAEF,OAAO;QAAEb,IAAA,EADI,MAAMa,SAAA,EAAW;QACfzF,KAAA,EAAO;OAAM;aACrBA,KAAA,EAAO;MACd,IAAI0F,KAAA,CAAKJ,kBAAA,EACP,MAAMtF,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAE4E,IAAA,EAAM;QAAa5E;OAAiB;MAE/C,MAAMA,KAAA;;;;;;;ACnFZ,IAAqB2F,qBAAA,GAArB,MAAkG;EAChGnG,YACEoG,UAAQ,EACRN,kBAAQ,EACR;IAFQ,KAAAM,UAAA,GAAAA,UAAA;IACA,KAAAN,kBAAA,GAAAA,kBAAA;;EAGV9B,KACEqC,WAAA,EAGAC,UAAA,EAC8B;IAC9B,OAAO,KAAKC,OAAA,EAAS,CAACvC,IAAA,CAAKqC,WAAA,EAAaC,UAAA,CAAW;;EAGrD,MAAcC,QAAA,EAAmD;;IAC/D,IAAI;MAGF,OAAO;QACLnB,IAAA,GAHa,MAAMc,KAAA,CAAKE,UAAA,EAAY,EAGvB7B,IAAA;QACb/D,KAAA,EAAO;OACR;aACMA,KAAA,EAAO;MACd,IAAI0F,KAAA,CAAKJ,kBAAA,EACP,MAAMtF,KAAA;MAGR,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAE4E,IAAA,EAAM;QAAM5E;OAAO;MAG9B,MAAMA,KAAA;;;;;;;;sBC9BAoB,MAAA,CAAOC,WAAA;AADnB,IAAqB2E,mBAAA,GAArB,MAAkF;EAIhFxG,YACEoG,UAAQ,EACRN,kBAAQ,EACR;IAFQ,KAAAM,UAAA,GAAAA,UAAA;IACA,KAAAN,kBAAA,GAAAA,kBAAA;gCAL8B;SAChCW,OAAA,GAAgD;;EAOxDC,SAAA,EAAkC;IAChC,OAAO,IAAIP,qBAAA,CAAsB,KAAKC,UAAA,EAAY,KAAKN,kBAAA,CAAmB;;EAG5E9B,KACEqC,WAAA,EACAC,UAAA,EAC8B;IAC9B,OAAO,KAAKK,UAAA,EAAY,CAAC3C,IAAA,CAAKqC,WAAA,EAAaC,UAAA,CAAW;;EAGxDpC,MACEoC,UAAA,EACyC;IACzC,OAAO,KAAKK,UAAA,EAAY,CAACzC,KAAA,CAAMoC,UAAA,CAAW;;EAG5CM,QAAQC,SAAA,EAAgE;IACtE,OAAO,KAAKF,UAAA,EAAY,CAACC,OAAA,CAAQC,SAAA,CAAU;;EAG7CF,UAAQA,CAAA,EAA4C;IAClD,IAAI,CAAC,KAAKF,OAAA,EACR,KAAKA,OAAA,GAAU,KAAKF,OAAA,EAAS;IAE/B,OAAO,KAAKE,OAAA;;EAGd,MAAcF,QAAA,EAAyC;;IACrD,IAAI;MAGF,OAAO;QACLnB,IAAA,EAAM,OAHO,MAAMc,KAAA,CAAKE,UAAA,EAAY,EAGjBU,IAAA,EAAM;QACzBtG,KAAA,EAAO;OACR;aACMA,KAAA,EAAO;MACd,IAAI0F,KAAA,CAAKJ,kBAAA,EACP,MAAMtF,KAAA;MAGR,IAAID,cAAA,CAAeC,KAAA,CAAM,EACvB,OAAO;QAAE4E,IAAA,EAAM;QAAM5E;OAAO;MAG9B,MAAMA,KAAA;;;;;;;ACxCZ,MAAMuG,sBAAA,GAAyB;EAC7BC,KAAA,EAAO;EACPC,MAAA,EAAQ;EACRC,MAAA,EAAQ;IACNC,MAAA,EAAQ;IACRC,KAAA,EAAO;;CAEV;AAED,MAAMC,oBAAA,GAAoC;EACxCC,YAAA,EAAc;EACdpC,WAAA,EAAa;EACbqC,MAAA,EAAQ;CACT;AAcD,IAAqBC,cAAA,GAArB,cAA4C5B,aAAA,CAA4B;EAGtE5F,YACE8E,GAAA,EACAL,OAAA,GAAqC,EAAE,EACvCgD,QAAA,EACA5B,OAAA,EACA;IACA,MAAMf,GAAA,EAAKL,OAAA,EAASoB,OAAA,EAAO,UAAU;IACrC,KAAK4B,QAAA,GAAWA,QAAA;;;;;;;;;EAUlB,MAAcC,eACZrD,MAAA,EACAsD,IAAA,EACAC,QAAA,EACAC,WAAA,EAUA;;IACA,OAAO3B,KAAA,CAAKF,eAAA,CAAgB,YAAY;MACtC,IAAIzB,IAAA;MACJ,MAAMX,OAAA,GAAAc,cAAA,CAAAA,cAAA,KAAe2C,oBAAA,GAAyBQ,WAAA;MAC9C,IAAIpD,OAAA,GAAAC,cAAA,CAAAA,cAAA,KACCwB,KAAA,CAAKzB,OAAA,GACJJ,MAAA,KAAW,UAAU;QAAE,YAAYyD,MAAA,CAAOlE,OAAA,CAAQ2D,MAAA;MAAkB,CAAE;MAG5E,MAAMQ,QAAA,GAAWnE,OAAA,CAAQmE,QAAA;MAEzB,IAAI,OAAOC,IAAA,KAAS,eAAeJ,QAAA,YAAoBI,IAAA,EAAM;QAC3DzD,IAAA,GAAO,IAAI0D,QAAA,EAAU;QACrB1D,IAAA,CAAK2D,MAAA,CAAO,gBAAgBtE,OAAA,CAAQ0D,YAAA,CAAuB;QAC3D,IAAIS,QAAA,EACFxD,IAAA,CAAK2D,MAAA,CAAO,YAAYhC,KAAA,CAAKiC,cAAA,CAAeJ,QAAA,CAAS,CAAC;QAExDxD,IAAA,CAAK2D,MAAA,CAAO,IAAIN,QAAA,CAAS;iBAChB,OAAOK,QAAA,KAAa,eAAeL,QAAA,YAAoBK,QAAA,EAAU;QAC1E1D,IAAA,GAAOqD,QAAA;QAEP,IAAI,CAACrD,IAAA,CAAK6D,GAAA,CAAI,eAAe,EAC3B7D,IAAA,CAAK2D,MAAA,CAAO,gBAAgBtE,OAAA,CAAQ0D,YAAA,CAAuB;QAE7D,IAAIS,QAAA,IAAY,CAACxD,IAAA,CAAK6D,GAAA,CAAI,WAAW,EACnC7D,IAAA,CAAK2D,MAAA,CAAO,YAAYhC,KAAA,CAAKiC,cAAA,CAAeJ,QAAA,CAAS,CAAC;aAEnD;QACLxD,IAAA,GAAOqD,QAAA;QACPnD,OAAA,CAAQ,mBAAmB,WAAWb,OAAA,CAAQ0D,YAAA;QAC9C7C,OAAA,CAAQ,kBAAkBb,OAAA,CAAQsB,WAAA;QAElC,IAAI6C,QAAA,EACFtD,OAAA,CAAQ,gBAAgByB,KAAA,CAAKmC,QAAA,CAASnC,KAAA,CAAKiC,cAAA,CAAeJ,QAAA,CAAS,CAAC;QAStE,KAHG,OAAOO,cAAA,KAAmB,eAAe/D,IAAA,YAAgB+D,cAAA,IACzD/D,IAAA,IAAQ,OAAOA,IAAA,KAAS,YAAY,UAAUA,IAAA,IAAQ,OAAOA,IAAA,CAAKgE,IAAA,KAAS,eAE9D,CAAC3E,OAAA,CAAQe,MAAA,EACvBf,OAAA,CAAQe,MAAA,GAAS;;MAIrB,IAAAkD,WAAA,aAAAA,WAAA,uBAAIA,WAAA,CAAapD,OAAA,EACfA,OAAA,GAAAC,cAAA,CAAAA,cAAA,KAAeD,OAAA,GAAYoD,WAAA,CAAYpD,OAAA;MAGzC,MAAM+D,SAAA,GAAYtC,KAAA,CAAKuC,mBAAA,CAAoBd,IAAA,CAAK;MAChD,MAAMe,KAAA,GAAQxC,KAAA,CAAKyC,aAAA,CAAcH,SAAA,CAAU;MAC3C,MAAMpD,IAAA,GAAO,OAAOf,MAAA,IAAU,QAAQkB,GAAA,GAAMD,IAAA,EAC1CY,KAAA,CAAK5E,KAAA,EACL,GAAG4E,KAAA,CAAKpB,GAAA,WAAc4D,KAAA,IACtBnE,IAAA,EAAAG,cAAA;QACED;MAAA,IAAAb,OAAA,aAAAA,OAAA,uBAAaA,OAAA,CAASe,MAAA,IAAS;QAAEA,MAAA,EAAQf,OAAA,CAAQe;MAAA,CAAQ,GAAG,EAAE,EACjE;MAED,OAAO;QAAEgD,IAAA,EAAMa,SAAA;QAAWI,EAAA,EAAIxD,IAAA,CAAKyD,EAAA;QAAIC,QAAA,EAAU1D,IAAA,CAAK2D;OAAK;MAC3D;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA+CJ,MAAMC,OACJrB,IAAA,EACAC,QAAA,EACAC,WAAA,EAUA;IACA,YAAYH,cAAA,CAAe,QAAQC,IAAA,EAAMC,QAAA,EAAUC,WAAA,CAAY;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAkCjE,MAAMoB,kBACJtB,IAAA,EACAuB,KAAA,EACAtB,QAAA,EACAC,WAAA,EACA;;IACA,MAAMW,SAAA,GAAYW,MAAA,CAAKV,mBAAA,CAAoBd,IAAA,CAAK;IAChD,MAAMe,KAAA,GAAQS,MAAA,CAAKR,aAAA,CAAcH,SAAA,CAAU;IAE3C,MAAM1D,GAAA,GAAM,IAAIsE,GAAA,CAAID,MAAA,CAAKrE,GAAA,GAAM,uBAAuB4D,KAAA,GAAQ;IAC9D5D,GAAA,CAAIuE,YAAA,CAAaC,GAAA,CAAI,SAASJ,KAAA,CAAM;IAEpC,OAAOC,MAAA,CAAKnD,eAAA,CAAgB,YAAY;MACtC,IAAIzB,IAAA;MACJ,MAAMX,OAAA,GAAAc,cAAA;QAAY6C,MAAA,EAAQF,oBAAA,CAAqBE;MAAA,GAAWM,WAAA;MAC1D,MAAMpD,OAAA,GAAAC,cAAA,CAAAA,cAAA,KACDyE,MAAA,CAAK1E,OAAA,GACL;QAAE,YAAYqD,MAAA,CAAOlE,OAAA,CAAQ2D,MAAA;MAAkB,CAAE;MAGtD,IAAI,OAAOS,IAAA,KAAS,eAAeJ,QAAA,YAAoBI,IAAA,EAAM;QAC3DzD,IAAA,GAAO,IAAI0D,QAAA,EAAU;QACrB1D,IAAA,CAAK2D,MAAA,CAAO,gBAAgBtE,OAAA,CAAQ0D,YAAA,CAAuB;QAC3D/C,IAAA,CAAK2D,MAAA,CAAO,IAAIN,QAAA,CAAS;iBAChB,OAAOK,QAAA,KAAa,eAAeL,QAAA,YAAoBK,QAAA,EAAU;QAC1E1D,IAAA,GAAOqD,QAAA;QACPrD,IAAA,CAAK2D,MAAA,CAAO,gBAAgBtE,OAAA,CAAQ0D,YAAA,CAAuB;aACtD;QACL/C,IAAA,GAAOqD,QAAA;QACPnD,OAAA,CAAQ,mBAAmB,WAAWb,OAAA,CAAQ0D,YAAA;QAC9C7C,OAAA,CAAQ,kBAAkBb,OAAA,CAAQsB,WAAA;;MAKpC,OAAO;QAAEyC,IAAA,EAAMa,SAAA;QAAWM,QAAA,GAFb,MAAMvD,GAAA,CAAI4D,MAAA,CAAK7H,KAAA,EAAOwD,GAAA,CAAIyE,QAAA,EAAU,EAAEhF,IAAA,EAAgB;UAAEE;QAAA,CAAS,CAAC,EAEtCsE;OAAK;MAC9C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAiCJ,MAAMS,sBACJ7B,IAAA,EACA/D,OAAA,EAUA;;IACA,OAAO6F,MAAA,CAAKzD,eAAA,CAAgB,YAAY;MACtC,IAAI0C,KAAA,GAAQe,MAAA,CAAKd,aAAA,CAAchB,IAAA,CAAK;MAEpC,MAAMlD,OAAA,GAAAC,cAAA,KAAe+E,MAAA,CAAKhF,OAAA;MAE1B,IAAAb,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAAS2D,MAAA,EACX9C,OAAA,CAAQ,cAAc;MAGxB,MAAMW,IAAA,GAAO,MAAME,IAAA,CACjBmE,MAAA,CAAKnI,KAAA,EACL,GAAGmI,MAAA,CAAK3E,GAAA,uBAA0B4D,KAAA,IAClC,EAAE,EACF;QAAEjE;MAAA,CAAS,CACZ;MAED,MAAMK,GAAA,GAAM,IAAIsE,GAAA,CAAIK,MAAA,CAAK3E,GAAA,GAAMM,IAAA,CAAKN,GAAA,CAAI;MAExC,MAAMoE,KAAA,GAAQpE,GAAA,CAAIuE,YAAA,CAAalE,GAAA,CAAI,QAAQ;MAE3C,IAAI,CAAC+D,KAAA,EACH,MAAM,IAAIpJ,YAAA,CAAa,2BAA2B;MAGpD,OAAO;QAAE4J,SAAA,EAAW5E,GAAA,CAAIyE,QAAA,EAAU;QAAE5B,IAAA;QAAMuB;OAAO;MACjD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA+CJ,MAAMS,OACJhC,IAAA,EACAC,QAAA,EAWAC,WAAA,EAUA;IACA,YAAYH,cAAA,CAAe,OAAOC,IAAA,EAAMC,QAAA,EAAUC,WAAA,CAAY;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8BhE,MAAM+B,KACJC,QAAA,EACAC,MAAA,EACAlG,OAAA,EAUA;;IACA,OAAOmG,MAAA,CAAK/D,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAMV,IAAA,CACXyE,MAAA,CAAKzI,KAAA,EACL,GAAGyI,MAAA,CAAKjF,GAAA,cAAI,EACZ;QACE2C,QAAA,EAAUsC,MAAA,CAAKtC,QAAA;QACfuC,SAAA,EAAWH,QAAA;QACXI,cAAA,EAAgBH,MAAA;QAChBI,iBAAA,EAAAtG,OAAA,aAAAA,OAAA,uBAAmBA,OAAA,CAASsG;OAC7B,EACD;QAAEzF,OAAA,EAASsF,MAAA,CAAKtF;MAAA,CAAS,CAC1B;MACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8BJ,MAAM0F,KACJN,QAAA,EACAC,MAAA,EACAlG,OAAA,EAUA;;IACA,OAAOwG,MAAA,CAAKpE,eAAA,CAAgB,YAAY;MAYtC,OAAO;QAAE2B,IAAA,GAXI,MAAMrC,IAAA,CACjB8E,MAAA,CAAK9I,KAAA,EACL,GAAG8I,MAAA,CAAKtF,GAAA,cAAI,EACZ;UACE2C,QAAA,EAAU2C,MAAA,CAAK3C,QAAA;UACfuC,SAAA,EAAWH,QAAA;UACXI,cAAA,EAAgBH,MAAA;UAChBI,iBAAA,EAAAtG,OAAA,aAAAA,OAAA,uBAAmBA,OAAA,CAASsG;SAC7B,EACD;UAAEzF,OAAA,EAAS2F,MAAA,CAAK3F;QAAA,CAAS,CAC1B,EACmBsE;MAAA,CAAK;MACzB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAsDJ,MAAMsB,gBACJ1C,IAAA,EACA2C,SAAA,EACA1G,OAAA,EAUA;;IACA,OAAO2G,MAAA,CAAKvE,eAAA,CAAgB,YAAY;MACtC,IAAI0C,KAAA,GAAQ6B,MAAA,CAAK5B,aAAA,CAAchB,IAAA,CAAK;MAEpC,IAAIvC,IAAA,GAAO,MAAME,IAAA,CACfiF,MAAA,CAAKjJ,KAAA,EACL,GAAGiJ,MAAA,CAAKzF,GAAA,gBAAmB4D,KAAA,IAAAhE,cAAA;QACzB4F;MAAA,IAAA1G,OAAA,aAAAA,OAAA,uBAAeA,OAAA,CAAS4G,SAAA,IAAY;QAAEA,SAAA,EAAW5G,OAAA,CAAQ4G;MAAA,CAAW,GAAG,EAAE,GAC3E;QAAE/F,OAAA,EAAS8F,MAAA,CAAK9F;MAAA,CAAS,CAC1B;MACD,MAAMgG,kBAAA,IAAA7G,OAAA,aAAAA,OAAA,uBAAqBA,OAAA,CAAS8G,QAAA,IAChC,aAAa9G,OAAA,CAAQ8G,QAAA,KAAa,OAAO,KAAK9G,OAAA,CAAQ8G,QAAA,KACtD;MAEJ,OAAO;QAAEhB,SAAA,EADSiB,SAAA,CAAU,GAAGJ,MAAA,CAAKzF,GAAA,GAAMM,IAAA,CAAKwF,SAAA,GAAYH,kBAAA;MAAqB,CAC5D;MACpB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAyCJ,MAAMI,iBACJC,KAAA,EACAR,SAAA,EACA1G,OAAA,EAUA;;IACA,OAAOmH,MAAA,CAAK/E,eAAA,CAAgB,YAAY;MACtC,MAAMZ,IAAA,GAAO,MAAME,IAAA,CACjByF,MAAA,CAAKzJ,KAAA,EACL,GAAGyJ,MAAA,CAAKjG,GAAA,gBAAmBiG,MAAA,CAAKtD,QAAA,IAChC;QAAE6C,SAAA;QAAWQ;OAAO,EACpB;QAAErG,OAAA,EAASsG,MAAA,CAAKtG;MAAA,CAAS,CAC1B;MAED,MAAMgG,kBAAA,IAAA7G,OAAA,aAAAA,OAAA,uBAAqBA,OAAA,CAAS8G,QAAA,IAChC,aAAa9G,OAAA,CAAQ8G,QAAA,KAAa,OAAO,KAAK9G,OAAA,CAAQ8G,QAAA,KACtD;MACJ,OAAOtF,IAAA,CAAKjD,GAAA,CAAK6I,KAAA,IAAAtG,cAAA,CAAAA,cAAA,KACZsG,KAAA;QACHtB,SAAA,EAAWsB,KAAA,CAAMJ,SAAA,GACbD,SAAA,CAAU,GAAGI,MAAA,CAAKjG,GAAA,GAAMkG,KAAA,CAAMJ,SAAA,GAAYH,kBAAA,GAAqB,GAC/D;MAAA,GACH;MACH;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA6DJC,SACE/C,IAAA,EACA/D,OAAA,EACAU,UAAA,EACqB;IAErB,MAAM2G,UAAA,GADsB,QAAArH,OAAA,aAAAA,OAAA,uBAAOA,OAAA,CAAS4G,SAAA,MAAc,cACjB,+BAA+B;IACxE,MAAMU,mBAAA,GAAsB,KAAKC,0BAAA,EAAAvH,OAAA,aAAAA,OAAA,uBAA2BA,OAAA,CAAS4G,SAAA,KAAa,EAAE,CAAC;IACrF,MAAMY,WAAA,GAAcF,mBAAA,GAAsB,IAAIA,mBAAA,KAAwB;IACtE,MAAMxC,KAAA,GAAQ,KAAKC,aAAA,CAAchB,IAAA,CAAK;IACtC,MAAMvB,UAAA,GAAAA,CAAA,KACJjB,GAAA,CACE,KAAK7D,KAAA,EACL,GAAG,KAAKwD,GAAA,IAAOmG,UAAA,IAAcvC,KAAA,GAAQ0C,WAAA,IACrC;MACE3G,OAAA,EAAS,KAAKA,OAAA;MACdZ,aAAA,EAAe;KAChB,EACDS,UAAA,CACD;IACH,OAAO,IAAIkC,mBAAA,CAAoBJ,UAAA,EAAY,KAAKN,kBAAA,CAAmB;;;;;;;;;;;;;;;;;EAkBrE,MAAMuF,KAAK1D,IAAA,EAST;;IACA,MAAMe,KAAA,GAAQ4C,OAAA,CAAK3C,aAAA,CAAchB,IAAA,CAAK;IAEtC,OAAO2D,OAAA,CAAKtF,eAAA,CAAgB,YAAY;MAKtC,OAAOjE,gBAAA,CAJM,MAAMoD,GAAA,CAAImG,OAAA,CAAKhK,KAAA,EAAO,GAAGgK,OAAA,CAAKxG,GAAA,gBAAmB4D,KAAA,IAAS;QACrEjE,OAAA,EAAS6G,OAAA,CAAK7G;MAAA,CACf,CAAC,CAE2B;MAC7B;;;;;;;;;;;;;;;;;EAkBJ,MAAM8G,OAAO5D,IAAA,EASX;;IACA,MAAMe,KAAA,GAAQ8C,OAAA,CAAK7C,aAAA,CAAchB,IAAA,CAAK;IAEtC,IAAI;MACF,MAAMnC,IAAA,CAAKgG,OAAA,CAAKlK,KAAA,EAAO,GAAGkK,OAAA,CAAK1G,GAAA,WAAc4D,KAAA,IAAS;QACpDjE,OAAA,EAAS+G,OAAA,CAAK/G;MAAA,CACf,CAAC;MAEF,OAAO;QAAEW,IAAA,EAAM;QAAM5E,KAAA,EAAO;OAAM;aAC3BA,KAAA,EAAO;MACd,IAAIgL,OAAA,CAAK1F,kBAAA,EACP,MAAMtF,KAAA;MAER,IAAID,cAAA,CAAeC,KAAA,CAAM,IAAIA,KAAA,YAAiBG,mBAAA,EAAqB;QACjE,MAAMC,aAAA,GAAgBJ,KAAA,CAAMI,aAAA;QAE5B,IAAI,CAAC,KAAK,IAAI,CAACqC,QAAA,CAAArC,aAAA,aAAAA,aAAA,uBAASA,aAAA,CAAeT,MAAA,CAAO,EAC5C,OAAO;UAAEiF,IAAA,EAAM;UAAO5E;SAAO;;MAIjC,MAAMA,KAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAsDViL,aACE9D,IAAA,EACA/D,OAAA,EACiC;IACjC,MAAM8E,KAAA,GAAQ,KAAKC,aAAA,CAAchB,IAAA,CAAK;IACtC,MAAM+D,YAAA,GAAyB,EAAE;IAEjC,MAAMjB,kBAAA,IAAA7G,OAAA,aAAAA,OAAA,uBAAqBA,OAAA,CAAS8G,QAAA,IAChC,YAAY9G,OAAA,CAAQ8G,QAAA,KAAa,OAAO,KAAK9G,OAAA,CAAQ8G,QAAA,KACrD;IAEJ,IAAID,kBAAA,KAAuB,IACzBiB,YAAA,CAAaC,IAAA,CAAKlB,kBAAA,CAAmB;IAIvC,MAAMQ,UAAA,GADsB,QAAArH,OAAA,aAAAA,OAAA,uBAAOA,OAAA,CAAS4G,SAAA,MAAc,cACjB,iBAAiB;IAC1D,MAAMU,mBAAA,GAAsB,KAAKC,0BAAA,EAAAvH,OAAA,aAAAA,OAAA,uBAA2BA,OAAA,CAAS4G,SAAA,KAAa,EAAE,CAAC;IAErF,IAAIU,mBAAA,KAAwB,IAC1BQ,YAAA,CAAaC,IAAA,CAAKT,mBAAA,CAAoB;IAGxC,IAAIE,WAAA,GAAcM,YAAA,CAAaE,IAAA,CAAK,IAAI;IACxC,IAAIR,WAAA,KAAgB,IAClBA,WAAA,GAAc,IAAIA,WAAA;IAGpB,OAAO;MACLhG,IAAA,EAAM;QAAEyG,SAAA,EAAWlB,SAAA,CAAU,GAAG,KAAK7F,GAAA,IAAOmG,UAAA,WAAqBvC,KAAA,GAAQ0C,WAAA;MAAc;IAAE,CAC1F;;;;;;;;;;;;;;;;;;;;;;;;;EA0BH,MAAM3F,OAAOqF,KAAA,EASX;;IACA,OAAOgB,OAAA,CAAK9F,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAMP,MAAA,CACXqG,OAAA,CAAKxK,KAAA,EACL,GAAGwK,OAAA,CAAKhH,GAAA,WAAcgH,OAAA,CAAKrE,QAAA,IAC3B;QAAEsE,QAAA,EAAUjB;MAAA,CAAO,EACnB;QAAErG,OAAA,EAASqH,OAAA,CAAKrH;MAAA,CAAS,CAC1B;MACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA6HJ,MAAMuH,KACJrE,IAAA,EACA/D,OAAA,EACAU,UAAA,EAUA;;IACA,OAAO2H,OAAA,CAAKjG,eAAA,CAAgB,YAAY;MACtC,MAAMzB,IAAA,GAAAG,cAAA,CAAAA,cAAA,CAAAA,cAAA,KAAYqC,sBAAA,GAA2BnD,OAAA;QAASsI,MAAA,EAAQvE,IAAA,IAAQ;MAAA;MACtE,OAAO,MAAMrC,IAAA,CACX2G,OAAA,CAAK3K,KAAA,EACL,GAAG2K,OAAA,CAAKnH,GAAA,gBAAmBmH,OAAA,CAAKxE,QAAA,IAChClD,IAAA,EACA;QAAEE,OAAA,EAASwH,OAAA,CAAKxH;MAAA,CAAS,EACzBH,UAAA,CACD;MACD;;;;;;;;;EAUJ,MAAM6H,OACJvI,OAAA,EACAU,UAAA,EAUA;;IACA,OAAO8H,OAAA,CAAKpG,eAAA,CAAgB,YAAY;MACtC,MAAMzB,IAAA,GAAAG,cAAA,KAAYd,OAAA;MAClB,OAAO,MAAM0B,IAAA,CACX8G,OAAA,CAAK9K,KAAA,EACL,GAAG8K,OAAA,CAAKtH,GAAA,mBAAsBsH,OAAA,CAAK3E,QAAA,IACnClD,IAAA,EACA;QAAEE,OAAA,EAAS2H,OAAA,CAAK3H;MAAA,CAAS,EACzBH,UAAA,CACD;MACD;;EAGJ6D,cAAUA,CAAeJ,QAAA,EAA+B;IACtD,OAAOvE,IAAA,CAAKC,SAAA,CAAUsE,QAAA,CAAS;;EAGjCM,SAASjD,IAAA,EAAc;IACrB,IAAI,OAAOiH,MAAA,KAAW,aACpB,OAAOA,MAAA,CAAOC,IAAA,CAAKlH,IAAA,CAAK,CAACmE,QAAA,CAAS,SAAS;IAE7C,OAAOgD,IAAA,CAAKnH,IAAA,CAAK;;EAGnBuD,aAAQA,CAAchB,IAAA,EAAc;IAClC,OAAO,GAAG,KAAKF,QAAA,IAAYE,IAAA,CAAKjF,OAAA,CAAQ,QAAQ,GAAG;;EAGrD+F,mBAAQA,CAAoBd,IAAA,EAAc;IACxC,OAAOA,IAAA,CAAKjF,OAAA,CAAQ,YAAY,GAAG,CAACA,OAAA,CAAQ,QAAQ,IAAI;;EAG1DyI,0BAAQA,CAA2BX,SAAA,EAA6B;IAC9D,MAAMhG,MAAA,GAAmB,EAAE;IAC3B,IAAIgG,SAAA,CAAUgC,KAAA,EACZhI,MAAA,CAAOmH,IAAA,CAAK,SAASnB,SAAA,CAAUgC,KAAA,GAAQ;IAGzC,IAAIhC,SAAA,CAAUiC,MAAA,EACZjI,MAAA,CAAOmH,IAAA,CAAK,UAAUnB,SAAA,CAAUiC,MAAA,GAAS;IAG3C,IAAIjC,SAAA,CAAUkC,MAAA,EACZlI,MAAA,CAAOmH,IAAA,CAAK,UAAUnB,SAAA,CAAUkC,MAAA,GAAS;IAG3C,IAAIlC,SAAA,CAAUmC,MAAA,EACZnI,MAAA,CAAOmH,IAAA,CAAK,UAAUnB,SAAA,CAAUmC,MAAA,GAAS;IAG3C,IAAInC,SAAA,CAAUoC,OAAA,EACZpI,MAAA,CAAOmH,IAAA,CAAK,WAAWnB,SAAA,CAAUoC,OAAA,GAAU;IAG7C,OAAOpI,MAAA,CAAOoH,IAAA,CAAK,IAAI;;;;;;ACtqC3B,MAAaiB,OAAA,GAAU;;;;ACLvB,MAAaC,eAAA,GAAkB;EAC7B,iBAAiB,cAAcD,OAAA;AAAA,CAChC;;;;ACID,IAAqBE,gBAAA,GAArB,cAA8CnH,aAAA,CAA4B;EACxE5F,YACE8E,GAAA,EACAL,OAAA,GAAqC,EAAE,EACvCoB,OAAA,EACAmH,IAAA,EACA;IACA,MAAMC,OAAA,GAAU,IAAI7D,GAAA,CAAItE,GAAA,CAAI;IAI5B,IAAAkI,IAAA,aAAAA,IAAA,uBAAIA,IAAA,CAAME,cAAA,EAER;UADuB,yBAAyBhK,IAAA,CAAK+J,OAAA,CAAQE,QAAA,CAAS,IAChD,CAACF,OAAA,CAAQE,QAAA,CAASlK,QAAA,CAAS,oBAAoB,EACnEgK,OAAA,CAAQE,QAAA,GAAWF,OAAA,CAAQE,QAAA,CAASzK,OAAA,CAAQ,aAAa,oBAAoB;;IAIjF,MAAM0K,QAAA,GAAWH,OAAA,CAAQI,IAAA,CAAK3K,OAAA,CAAQ,OAAO,GAAG;IAChD,MAAM4K,YAAA,GAAA5I,cAAA,CAAAA,cAAA,KAAoBoI,eAAA,GAAoBrI,OAAA;IAE9C,MAAM2I,QAAA,EAAUE,YAAA,EAAczH,OAAA,EAAO,UAAU;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAmCjD,MAAM0H,YAAY3J,OAAA,EAShB;;IACA,OAAOsC,KAAA,CAAKF,eAAA,CAAgB,YAAY;MACtC,MAAMoF,WAAA,GAAclF,KAAA,CAAKsH,8BAAA,CAA+B5J,OAAA,CAAQ;MAChE,OAAO,MAAMuB,GAAA,CAAIe,KAAA,CAAK5E,KAAA,EAAO,GAAG4E,KAAA,CAAKpB,GAAA,UAAasG,WAAA,IAAe;QAC/D3G,OAAA,EAASyB,KAAA,CAAKzB;MAAA,CACf,CAAC;MACF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAoCJ,MAAMgJ,UAAU7E,EAAA,EASd;;IACA,OAAO8E,MAAA,CAAK1H,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAMb,GAAA,CAAIuI,MAAA,CAAKpM,KAAA,EAAO,GAAGoM,MAAA,CAAK5I,GAAA,WAAc8D,EAAA,IAAM;QAAEnE,OAAA,EAASiJ,MAAA,CAAKjJ;MAAA,CAAS,CAAC;MACnF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAwCJ,MAAMkJ,aACJ/E,EAAA,EACAhF,OAAA,GAKI;IACFgK,MAAA,EAAQ;EAAA,CACT,EAUD;;IACA,OAAOzE,MAAA,CAAKnD,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAMV,IAAA,CACX6D,MAAA,CAAK7H,KAAA,EACL,GAAG6H,MAAA,CAAKrE,GAAA,SAAI,EACZ;QACE8D,EAAA;QACAtI,IAAA,EAAMsI,EAAA;QACNiF,IAAA,EAAMjK,OAAA,CAAQiK,IAAA;QACdD,MAAA,EAAQhK,OAAA,CAAQgK,MAAA;QAChBE,eAAA,EAAiBlK,OAAA,CAAQmK,aAAA;QACzBC,kBAAA,EAAoBpK,OAAA,CAAQqK;OAC7B,EACD;QAAExJ,OAAA,EAAS0E,MAAA,CAAK1E;MAAA,CAAS,CAC1B;MACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAsCJ,MAAMyJ,aACJtF,EAAA,EACAhF,OAAA,EAcA;;IACA,OAAO6F,MAAA,CAAKzD,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAMT,GAAA,CACXkE,MAAA,CAAKnI,KAAA,EACL,GAAGmI,MAAA,CAAK3E,GAAA,WAAc8D,EAAA,IACtB;QACEA,EAAA;QACAtI,IAAA,EAAMsI,EAAA;QACNgF,MAAA,EAAQhK,OAAA,CAAQgK,MAAA;QAChBE,eAAA,EAAiBlK,OAAA,CAAQmK,aAAA;QACzBC,kBAAA,EAAoBpK,OAAA,CAAQqK;OAC7B,EACD;QAAExJ,OAAA,EAASgF,MAAA,CAAKhF;MAAA,CAAS,CAC1B;MACD;;;;;;;;;;;;;;;;;;;;;;;;;;EA2BJ,MAAM0J,YAAYvF,EAAA,EAShB;;IACA,OAAOwF,MAAA,CAAKpI,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAMV,IAAA,CAAK8I,MAAA,CAAK9M,KAAA,EAAO,GAAG8M,MAAA,CAAKtJ,GAAA,WAAc8D,EAAA,QAAG,EAAS,EAAE,EAAE;QAAEnE,OAAA,EAAS2J,MAAA,CAAK3J;MAAA,CAAS,CAAC;MAC9F;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4BJ,MAAM4J,aAAazF,EAAA,EASjB;;IACA,OAAOmB,MAAA,CAAK/D,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAMP,MAAA,CAAOsE,MAAA,CAAKzI,KAAA,EAAO,GAAGyI,MAAA,CAAKjF,GAAA,WAAc8D,EAAA,IAAM,EAAE,EAAE;QAAEnE,OAAA,EAASsF,MAAA,CAAKtF;MAAA,CAAS,CAAC;MAC1F;;EAGJ+I,8BAAQA,CAA+B5J,OAAA,EAAqC;IAC1E,MAAMY,MAAA,GAAiC,EAAE;IACzC,IAAIZ,OAAA,EAAS;MACX,IAAI,WAAWA,OAAA,EACbY,MAAA,CAAOwC,KAAA,GAAQc,MAAA,CAAOlE,OAAA,CAAQoD,KAAA,CAAM;MAEtC,IAAI,YAAYpD,OAAA,EACdY,MAAA,CAAOyC,MAAA,GAASa,MAAA,CAAOlE,OAAA,CAAQqD,MAAA,CAAO;MAExC,IAAIrD,OAAA,CAAQ0K,MAAA,EACV9J,MAAA,CAAO8J,MAAA,GAAS1K,OAAA,CAAQ0K,MAAA;MAE1B,IAAI1K,OAAA,CAAQ2K,UAAA,EACV/J,MAAA,CAAO+J,UAAA,GAAa3K,OAAA,CAAQ2K,UAAA;MAE9B,IAAI3K,OAAA,CAAQ4K,SAAA,EACVhK,MAAA,CAAOgK,SAAA,GAAY5K,OAAA,CAAQ4K,SAAA;;IAG/B,OAAO9M,MAAA,CAAO+M,IAAA,CAAKjK,MAAA,CAAO,CAACzB,MAAA,GAAS,IAAI,MAAM,IAAI2L,eAAA,CAAgBlK,MAAA,CAAO,CAAC+E,QAAA,EAAU,GAAG;;;;;;;;;;AC7V3F,IAAqBoF,sBAAA,GAArB,cAAoD/I,aAAA,CAA4B;;;;;;;;;;;;;;;;;;EAkB9E5F,YAAY8E,GAAA,EAAaL,OAAA,GAAqC,EAAE,EAAEoB,OAAA,EAAe;IAC/E,MAAMuH,QAAA,GAAWtI,GAAA,CAAIpC,OAAA,CAAQ,OAAO,GAAG;IACvC,MAAM4K,YAAA,GAAA5I,cAAA,CAAAA,cAAA,KAAoBoI,eAAA,GAAoBrI,OAAA;IAC9C,MAAM2I,QAAA,EAAUE,YAAA,EAAczH,OAAA,EAAO,UAAU;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAqCjD,MAAM8H,aAAarN,IAAA,EASjB;;IACA,OAAO4F,KAAA,CAAKF,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAMV,IAAA,CAAKY,KAAA,CAAK5E,KAAA,EAAO,GAAG4E,KAAA,CAAKpB,GAAA,SAAI,EAAU;QAAExE;MAAA,CAAM,EAAE;QAAEmE,OAAA,EAASyB,KAAA,CAAKzB;MAAA,CAAS,CAAC;MACxF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAiDJ,MAAM8I,YAAY3J,OAAA,EAehB;;IACA,OAAO8J,MAAA,CAAK1H,eAAA,CAAgB,YAAY;MAEtC,MAAM4I,WAAA,GAAc,IAAIF,eAAA,EAAiB;MACzC,KAAA9K,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASoD,KAAA,MAAU,QAAW4H,WAAA,CAAYtF,GAAA,CAAI,SAAS1F,OAAA,CAAQoD,KAAA,CAAMuC,QAAA,EAAU,CAAC;MACpF,KAAA3F,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAASqD,MAAA,MAAW,QAAW2H,WAAA,CAAYtF,GAAA,CAAI,UAAU1F,OAAA,CAAQqD,MAAA,CAAOsC,QAAA,EAAU,CAAC;MACvF,IAAA3F,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAAS2K,UAAA,EAAYK,WAAA,CAAYtF,GAAA,CAAI,cAAc1F,OAAA,CAAQ2K,UAAA,CAAW;MAC1E,IAAA3K,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAAS4K,SAAA,EAAWI,WAAA,CAAYtF,GAAA,CAAI,aAAa1F,OAAA,CAAQ4K,SAAA,CAAU;MACvE,IAAA5K,OAAA,aAAAA,OAAA,uBAAIA,OAAA,CAAS0K,MAAA,EAAQM,WAAA,CAAYtF,GAAA,CAAI,UAAU1F,OAAA,CAAQ0K,MAAA,CAAO;MAE9D,MAAMlD,WAAA,GAAcwD,WAAA,CAAYrF,QAAA,EAAU;MAC1C,MAAMzE,GAAA,GAAMsG,WAAA,GAAc,GAAGsC,MAAA,CAAK5I,GAAA,WAAcsG,WAAA,KAAgB,GAAGsC,MAAA,CAAK5I,GAAA,SAAI;MAE5E,OAAO,MAAMK,GAAA,CAAIuI,MAAA,CAAKpM,KAAA,EAAOwD,GAAA,EAAK;QAAEL,OAAA,EAASiJ,MAAA,CAAKjJ;MAAA,CAAS,CAAC;MAC5D;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAkCJ,MAAM4J,aAAavL,UAAA,EASjB;;IACA,OAAOqG,MAAA,CAAKnD,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAMP,MAAA,CACX0D,MAAA,CAAK7H,KAAA,EACL,GAAG6H,MAAA,CAAKrE,GAAA,WAAchC,UAAA,IACtB,EAAE,EACF;QAAE2B,OAAA,EAAS0E,MAAA,CAAK1E;MAAA,CAAS,CAC1B;MACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8HJ6H,KAAKxJ,UAAA,EAA+C;;IAElD,IAAI,CAACD,iBAAA,CAAkBC,UAAA,CAAW,EAChC,MAAM,IAAIhD,YAAA,CACR,qJAED;IAOH,MAAM+O,OAAA,GAAU,IAAIC,kBAAA,CAAmB;MACrC7B,OAAA,EAAS,KAAKnI,GAAA;MACdiK,WAAA,EAAajM,UAAA;MACbkM,IAAA,EAAM;QACJnB,IAAA,EAAM;QACNoB,UAAA,EAAY,MAAAA,CAAA,KAAYxF,MAAA,CAAKhF;OAC9B;MACDnD,KAAA,EAAO,KAAKA;KACb,CAAC;IAEF,MAAMwE,kBAAA,GAAqB,KAAKA,kBAAA;IAuBhC,OArBuB,IAAIoJ,KAAA,CAAML,OAAA,EAAS;MACxC1J,IAAIgK,MAAA,EAAQC,IAAA,EAAgC;QAC1C,MAAM5N,KAAA,GAAQ2N,MAAA,CAAOC,IAAA;QACrB,IAAI,OAAO5N,KAAA,KAAU,YACnB,OAAOA,KAAA;QAGT,OAAO,OAAO,GAAGH,IAAA,KAAoB;UACnC,IAAI;YAEF,OAAO;cAAE+D,IAAA,EADI,MAAO5D,KAAA,CAAmB6N,KAAA,CAAMF,MAAA,EAAQ9N,IAAA,CAAK;cAC3Cb,KAAA,EAAO;aAAM;mBACrBA,KAAA,EAAO;YACd,IAAIsF,kBAAA,EACF,MAAMtF,KAAA;YAER,OAAO;cAAE4E,IAAA,EAAM;cAAa5E;aAAuB;;;;KAI1D,CAAC;;;;;;;;;;;AClWN,IAAqB8O,cAAA,GAArB,cAA4C1J,aAAA,CAA4B;;EAEtE5F,YAAY8E,GAAA,EAAaL,OAAA,GAAqC,EAAE,EAAEoB,OAAA,EAAe;IAC/E,MAAMuH,QAAA,GAAWtI,GAAA,CAAIpC,OAAA,CAAQ,OAAO,GAAG;IACvC,MAAM4K,YAAA,GAAA5I,cAAA,CAAAA,cAAA,KAAoBoI,eAAA;MAAiB,gBAAgB;IAAA,GAAuBrI,OAAA;IAClF,MAAM2I,QAAA,EAAUE,YAAA,EAAczH,OAAA,EAAO,UAAU;;;EAIjD,MAAM0J,YAAY3L,OAAA,EAA8D;;IAC9E,OAAOsC,KAAA,CAAKF,eAAA,CAAgB,YAAY;MAItC,OAHa,OAAML,UAAA,CAAWL,IAAA,CAAKY,KAAA,CAAK5E,KAAA,EAAO,GAAG4E,KAAA,CAAKpB,GAAA,cAAI,EAAelB,OAAA,EAAS;QACjFa,OAAA,EAASyB,KAAA,CAAKzB;MAAA,CACf,CAAC,KACa,EAAE;MACjB;;;EAIJ,MAAM+K,SACJC,gBAAA,EACAC,SAAA,EAC8C;;IAC9C,OAAOhC,MAAA,CAAK1H,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAML,UAAA,CAAWL,IAAA,CACtBoI,MAAA,CAAKpM,KAAA,EACL,GAAGoM,MAAA,CAAK5I,GAAA,WAAI,EACZ;QAAE2K,gBAAA;QAAkBC;OAAW,EAC/B;QAAEjL,OAAA,EAASiJ,MAAA,CAAKjJ;MAAA,CAAS,CAC1B;MACD;;;EAIJ,MAAMkL,YAAY/L,OAAA,EAAwE;;IACxF,OAAOuF,MAAA,CAAKnD,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAML,UAAA,CAAWL,IAAA,CAAK6D,MAAA,CAAK7H,KAAA,EAAO,GAAG6H,MAAA,CAAKrE,GAAA,cAAI,EAAelB,OAAA,EAAS;QAC3Ea,OAAA,EAAS0E,MAAA,CAAK1E;MAAA,CACf,CAAC;MACF;;;EAIJ,MAAMmL,YAAYH,gBAAA,EAA0BC,SAAA,EAAoD;;IAC9F,OAAOjG,MAAA,CAAKzD,eAAA,CAAgB,YAAY;MAOtC,OANa,OAAML,UAAA,CAAWL,IAAA,CAC5BmE,MAAA,CAAKnI,KAAA,EACL,GAAGmI,MAAA,CAAK3E,GAAA,cAAI,EACZ;QAAE2K,gBAAA;QAAkBC;OAAW,EAC/B;QAAEjL,OAAA,EAASgF,MAAA,CAAKhF;MAAA,CAAS,CAC1B,KACc,EAAE;MACjB;;;;;;;;;;;AClEN,IAAqBoL,aAAA,GAArB,cAA2CjK,aAAA,CAA4B;;EAErE5F,YAAY8E,GAAA,EAAaL,OAAA,GAAqC,EAAE,EAAEoB,OAAA,EAAe;IAC/E,MAAMuH,QAAA,GAAWtI,GAAA,CAAIpC,OAAA,CAAQ,OAAO,GAAG;IACvC,MAAM4K,YAAA,GAAA5I,cAAA,CAAAA,cAAA,KAAoBoI,eAAA;MAAiB,gBAAgB;IAAA,GAAuBrI,OAAA;IAClF,MAAM2I,QAAA,EAAUE,YAAA,EAAczH,OAAA,EAAO,UAAU;;;EAIjD,MAAMiK,WAAWlM,OAAA,EAA6D;;IAE5E,IAAIA,OAAA,CAAQmM,OAAA,CAAQhN,MAAA,GAAS,KAAKa,OAAA,CAAQmM,OAAA,CAAQhN,MAAA,GAAS,KACzD,MAAM,IAAIhD,KAAA,CAAM,oDAAoD;IAGtE,OAAOmG,KAAA,CAAKF,eAAA,CAAgB,YAAY;MAItC,OAHa,OAAML,UAAA,CAAWL,IAAA,CAAKY,KAAA,CAAK5E,KAAA,EAAO,GAAG4E,KAAA,CAAKpB,GAAA,aAAI,EAAclB,OAAA,EAAS;QAChFa,OAAA,EAASyB,KAAA,CAAKzB;MAAA,CACf,CAAC,KACa,EAAE;MACjB;;;EAIJ,MAAMuL,WAAWpM,OAAA,EAAsE;;IACrF,OAAO8J,MAAA,CAAK1H,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAML,UAAA,CAAWL,IAAA,CAAKoI,MAAA,CAAKpM,KAAA,EAAO,GAAGoM,MAAA,CAAK5I,GAAA,aAAI,EAAclB,OAAA,EAAS;QAC1Ea,OAAA,EAASiJ,MAAA,CAAKjJ;MAAA,CACf,CAAC;MACF;;;EAIJ,MAAMwL,YAAYrM,OAAA,EAAwE;;IAExF,IAAIA,OAAA,CAAQsM,YAAA,KAAiB,QAAW;MACtC,IAAItM,OAAA,CAAQsM,YAAA,GAAe,KAAKtM,OAAA,CAAQsM,YAAA,GAAe,IACrD,MAAM,IAAInQ,KAAA,CAAM,wCAAwC;MAE1D,IAAI6D,OAAA,CAAQuM,YAAA,KAAiB,QAC3B;YAAIvM,OAAA,CAAQuM,YAAA,GAAe,KAAKvM,OAAA,CAAQuM,YAAA,IAAgBvM,OAAA,CAAQsM,YAAA,EAC9D,MAAM,IAAInQ,KAAA,CAAM,sCAAsC6D,OAAA,CAAQsM,YAAA,GAAe,IAAI;;;IAKvF,OAAO/G,MAAA,CAAKnD,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAML,UAAA,CAAWL,IAAA,CAAK6D,MAAA,CAAK7H,KAAA,EAAO,GAAG6H,MAAA,CAAKrE,GAAA,cAAI,EAAelB,OAAA,EAAS;QAC3Ea,OAAA,EAAS0E,MAAA,CAAK1E;MAAA,CACf,CAAC;MACF;;;EAIJ,MAAM2L,aAAaxM,OAAA,EAA0E;;IAC3F,OAAO6F,MAAA,CAAKzD,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAML,UAAA,CAAWL,IAAA,CAAKmE,MAAA,CAAKnI,KAAA,EAAO,GAAGmI,MAAA,CAAK3E,GAAA,eAAI,EAAgBlB,OAAA,EAAS;QAC5Ea,OAAA,EAASgF,MAAA,CAAKhF;MAAA,CACf,CAAC;MACF;;;EAIJ,MAAM4L,cAAczM,OAAA,EAAgE;;IAElF,IAAIA,OAAA,CAAQ6K,IAAA,CAAK1L,MAAA,GAAS,KAAKa,OAAA,CAAQ6K,IAAA,CAAK1L,MAAA,GAAS,KACnD,MAAM,IAAIhD,KAAA,CAAM,kDAAkD;IAGpE,OAAOqO,MAAA,CAAKpI,eAAA,CAAgB,YAAY;MAItC,OAHa,OAAML,UAAA,CAAWL,IAAA,CAAK8I,MAAA,CAAK9M,KAAA,EAAO,GAAG8M,MAAA,CAAKtJ,GAAA,gBAAI,EAAiBlB,OAAA,EAAS;QACnFa,OAAA,EAAS2J,MAAA,CAAK3J;MAAA,CACf,CAAC,KACa,EAAE;MACjB;;;;;;;;;;;AC/EN,IAAqB6L,eAAA,GAArB,cAA6C1K,aAAA,CAA4B;;EAEvE5F,YAAY8E,GAAA,EAAaL,OAAA,GAAqC,EAAE,EAAEoB,OAAA,EAAe;IAC/E,MAAMuH,QAAA,GAAWtI,GAAA,CAAIpC,OAAA,CAAQ,OAAO,GAAG;IACvC,MAAM4K,YAAA,GAAA5I,cAAA,CAAAA,cAAA,KAAoBoI,eAAA;MAAiB,gBAAgB;IAAA,GAAuBrI,OAAA;IAClF,MAAM2I,QAAA,EAAUE,YAAA,EAAczH,OAAA,EAAO,UAAU;;;EAIjD,MAAM8H,aAAa8B,gBAAA,EAA2D;;IAC5E,OAAOvJ,KAAA,CAAKF,eAAA,CAAgB,YAAY;MAOtC,OANa,OAAML,UAAA,CAAWL,IAAA,CAC5BY,KAAA,CAAK5E,KAAA,EACL,GAAG4E,KAAA,CAAKpB,GAAA,qBAAI,EACZ;QAAE2K;MAAA,CAAkB,EACpB;QAAEhL,OAAA,EAASyB,KAAA,CAAKzB;MAAA,CAAS,CAC1B,KACc,EAAE;MACjB;;;EAIJ,MAAMgJ,UAAUgC,gBAAA,EAAgF;;IAC9F,OAAO/B,MAAA,CAAK1H,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAML,UAAA,CAAWL,IAAA,CACtBoI,MAAA,CAAKpM,KAAA,EACL,GAAGoM,MAAA,CAAK5I,GAAA,kBAAI,EACZ;QAAE2K;MAAA,CAAkB,EACpB;QAAEhL,OAAA,EAASiJ,MAAA,CAAKjJ;MAAA,CAAS,CAC1B;MACD;;;EAIJ,MAAM8I,YACJ3J,OAAA,GAAoC,EAAE,EACW;;IACjD,OAAOuF,MAAA,CAAKnD,eAAA,CAAgB,YAAY;MACtC,OAAO,MAAML,UAAA,CAAWL,IAAA,CAAK6D,MAAA,CAAK7H,KAAA,EAAO,GAAG6H,MAAA,CAAKrE,GAAA,oBAAI,EAAqBlB,OAAA,EAAS;QACjFa,OAAA,EAAS0E,MAAA,CAAK1E;MAAA,CACf,CAAC;MACF;;;EAIJ,MAAM4J,aAAaoB,gBAAA,EAA2D;;IAC5E,OAAOhG,MAAA,CAAKzD,eAAA,CAAgB,YAAY;MAOtC,OANa,OAAML,UAAA,CAAWL,IAAA,CAC5BmE,MAAA,CAAKnI,KAAA,EACL,GAAGmI,MAAA,CAAK3E,GAAA,qBAAI,EACZ;QAAE2K;MAAA,CAAkB,EACpB;QAAEhL,OAAA,EAASgF,MAAA,CAAKhF;MAAA,CAAS,CAC1B,KACc,EAAE;MACjB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACSN,IAAa8L,oBAAA,GAAb,cAA0CD,eAAA,CAAgB;;;;;;;;;;;;;;;;;;EAkBxDtQ,YAAY8E,GAAA,EAAalB,OAAA,GAAuC,EAAE,EAAE;IAClE,MAAMkB,GAAA,EAAKlB,OAAA,CAAQa,OAAA,IAAW,EAAE,EAAEb,OAAA,CAAQtC,KAAA,CAAM;;;;;;;;;;;;;;;;;;;;EAqBlDgL,KAAKmD,gBAAA,EAA6C;IAChD,OAAO,IAAIe,iBAAA,CAAkB,KAAK1L,GAAA,EAAK,KAAKL,OAAA,EAASgL,gBAAA,EAAkB,KAAKnO,KAAA,CAAM;;;;;;;;;;;;;;;;;;;;;;;EAwBpF,MAAMqM,aAAa8B,gBAAA,EAA2D;2CACrE,MAAM9B,YAAA;MAAAzH,KAAA;IAAb,OAAAuK,0BAAA,GAAAC,IAAA,CAAAxK,KAAA,EAA0BuJ,gBAAA;;;;;;;;;;;;;;;;;;;;;;;;EAyB5B,MAAMhC,UAAUgC,gBAAA,EAAgF;wCACvF,MAAMhC,SAAA;MAAAC,MAAA;IAAb,OAAAiD,uBAAA,GAAAD,IAAA,CAAAhD,MAAA,EAAuB+B,gBAAA;;;;;;;;;;;;;;;;;;;;;;;;;;EA2BzB,MAAMlC,YACJ3J,OAAA,GAAoC,EAAE,EACW;0CAC1C,MAAM2J,WAAA;MAAApE,MAAA;IAAb,OAAAyH,yBAAA,GAAAF,IAAA,CAAAvH,MAAA,EAAyBvF,OAAA;;;;;;;;;;;;;;;;;;;;;;;EAwB3B,MAAMyK,aAAaoB,gBAAA,EAA2D;2CACrE,MAAMpB,YAAA;MAAA5E,MAAA;IAAb,OAAAoH,0BAAA,GAAAH,IAAA,CAAAjH,MAAA,EAA0BgG,gBAAA;;;;;;;;;;;;AAa9B,IAAae,iBAAA,GAAb,cAAuClB,cAAA,CAAe;;;;;;;;;;;;;;EAgBpDtP,YACE8E,GAAA,EACAL,OAAA,EACAgL,gBAAA,EACA5J,OAAA,EACA;IACA,MAAMf,GAAA,EAAKL,OAAA,EAASoB,OAAA,CAAM;IAC1B,KAAK4J,gBAAA,GAAmBA,gBAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8B1B,MAAeF,YAAY3L,OAAA,EAAuD;0CACzE,MAAM2L,WAAA;MAAAnB,MAAA;IAAb,OAAA0C,yBAAA,GAAAJ,IAAA,CAAAtC,MAAA,EAAA1J,cAAA,CAAAA,cAAA,KACKd,OAAA;MACH6L,gBAAA,EAAkBrB,MAAA,CAAKqB;IAAA;;;;;;;;;;;;;;;;;;;;;EAuB3B,MAAeE,YAAY/L,OAAA,GAAwD,EAAE,EAAE;0CAC9E,MAAM+L,WAAA;MAAA5F,MAAA;IAAb,OAAAgH,yBAAA,GAAAL,IAAA,CAAA3G,MAAA,EAAArF,cAAA,CAAAA,cAAA,KACKd,OAAA;MACH6L,gBAAA,EAAkB1F,MAAA,CAAK0F;IAAA;;;;;;;;;;;;;;;;;;;;;;EAwB3B,MAAeD,SAASE,SAAA,EAAmB;uCAClC,MAAMF,QAAA;MAAApF,MAAA;IAAb,OAAA4G,sBAAA,GAAAN,IAAA,CAAAtG,MAAA,EAAsBA,MAAA,CAAKqF,gBAAA,EAAkBC,SAAA;;;;;;;;;;;;;;;;;;;;;EAsB/C,MAAeE,YAAYF,SAAA,EAAmB;0CACrC,MAAME,WAAA;MAAArF,MAAA;IAAb,OAAA0G,yBAAA,GAAAP,IAAA,CAAAnG,MAAA,EAAyBA,MAAA,CAAKkF,gBAAA,EAAkBC,SAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAkClDwB,MAAMxB,SAAA,EAAqC;IACzC,OAAO,IAAIyB,gBAAA,CACT,KAAKrM,GAAA,EACL,KAAKL,OAAA,EACL,KAAKgL,gBAAA,EACLC,SAAA,EACA,KAAKpO,KAAA,CACN;;;;;;;;;;;;AAaL,IAAa6P,gBAAA,GAAb,cAAsCtB,aAAA,CAAc;;;;;;;;;;;;;;;EAkBlD7P,YACE8E,GAAA,EACAL,OAAA,EACAgL,gBAAA,EACAC,SAAA,EACA7J,OAAA,EACA;IACA,MAAMf,GAAA,EAAKL,OAAA,EAASoB,OAAA,CAAM;IAC1B,KAAK4J,gBAAA,GAAmBA,gBAAA;IACxB,KAAKC,SAAA,GAAYA,SAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8BnB,MAAeI,WAAWlM,OAAA,EAAoE;yCACrF,MAAMkM,UAAA;MAAA/E,MAAA;IAAb,OAAAqG,wBAAA,GAAAV,IAAA,CAAA3F,MAAA,EAAArG,cAAA,CAAAA,cAAA,KACKd,OAAA;MACH6L,gBAAA,EAAkB1E,MAAA,CAAK0E,gBAAA;MACvBC,SAAA,EAAW3E,MAAA,CAAK2E;;;;;;;;;;;;;;;;;;;;;;;;;EA0BpB,MAAeM,WAAWpM,OAAA,EAAoE;yCACrF,MAAMoM,UAAA;MAAA1E,OAAA;IAAb,OAAA+F,wBAAA,GAAAX,IAAA,CAAApF,OAAA,EAAA5G,cAAA,CAAAA,cAAA,KACKd,OAAA;MACH6L,gBAAA,EAAkBnE,OAAA,CAAKmE,gBAAA;MACvBC,SAAA,EAAWpE,OAAA,CAAKoE;;;;;;;;;;;;;;;;;;;;;;;;;EA0BpB,MAAeO,YACbrM,OAAA,GAAsE,EAAE,EACxE;0CACO,MAAMqM,WAAA;MAAAzE,OAAA;IAAb,OAAA8F,yBAAA,GAAAZ,IAAA,CAAAlF,OAAA,EAAA9G,cAAA,CAAAA,cAAA,KACKd,OAAA;MACH6L,gBAAA,EAAkBjE,OAAA,CAAKiE,gBAAA;MACvBC,SAAA,EAAWlE,OAAA,CAAKkE;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA6BpB,MAAeU,aACbxM,OAAA,EACA;2CACO,MAAMwM,YAAA;MAAAtE,OAAA;IAAb,OAAAyF,0BAAA,GAAAb,IAAA,CAAA5E,OAAA,EAAApH,cAAA,CAAAA,cAAA,KACKd,OAAA;MACH6L,gBAAA,EAAkB3D,OAAA,CAAK2D,gBAAA;MACvBC,SAAA,EAAW5D,OAAA,CAAK4D;;;;;;;;;;;;;;;;;;;;;;;;EAyBpB,MAAeW,cACbzM,OAAA,EACA;4CACO,MAAMyM,aAAA;MAAApE,OAAA;IAAb,OAAAuF,2BAAA,GAAAd,IAAA,CAAAzE,OAAA,EAAAvH,cAAA,CAAAA,cAAA,KACKd,OAAA;MACH6L,gBAAA,EAAkBxD,OAAA,CAAKwD,gBAAA;MACvBC,SAAA,EAAWzD,OAAA,CAAKyD;;;;;;;AC1lBtB,IAAa+B,aAAA,GAAb,cAAmC1E,gBAAA,CAAiB;;;;;;;;;;;;;;;EAelD/M,YACE8E,GAAA,EACAL,OAAA,GAAqC,EAAE,EACvCoB,OAAA,EACAmH,IAAA,EACA;IACA,MAAMlI,GAAA,EAAKL,OAAA,EAASoB,OAAA,EAAOmH,IAAA,CAAK;;;;;;;;;;;;;EAclCV,KAAK1D,EAAA,EAA4B;IAC/B,OAAO,IAAIpB,cAAA,CAAe,KAAK1C,GAAA,EAAK,KAAKL,OAAA,EAASmE,EAAA,EAAI,KAAKtH,KAAA,CAAM;;;;;;;;;;;;;EAcnE,IAAIyO,QAAA,EAAgC;IAClC,OAAO,IAAIQ,oBAAA,CAAqB,KAAKzL,GAAA,GAAM,WAAW;MACpDL,OAAA,EAAS,KAAKA,OAAA;MACdnD,KAAA,EAAO,KAAKA;KACb,CAAC;;;;;;;;;;;;;EAcJ,IAAIoQ,UAAA,EAAoC;IACtC,OAAO,IAAI/C,sBAAA,CAAuB,KAAK7J,GAAA,GAAM,YAAY,KAAKL,OAAA,EAAS,KAAKnD,KAAA,CAAM","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}